<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FireDucks â€“ Benchmarks</title><link>https://fireducks-dev.github.io/docs/benchmarks/</link><description>Recent content in Benchmarks on FireDucks</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 05 Jun 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://fireducks-dev.github.io/docs/benchmarks/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Benchmark Archive</title><link>https://fireducks-dev.github.io/docs/benchmarks/archive/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/docs/benchmarks/archive/</guid><description>
&lt;h2 id="20250204">2025/02/04&lt;/h2>
&lt;p>Server specification (AWS EC2 m7i.8xlarge):&lt;/p>
&lt;ul>
&lt;li>cpu: INTEL(R) XEON(R) GOLD 6526Y (32cores)&lt;/li>
&lt;li>main memory: 512GB&lt;/li>
&lt;li>cpufreq-governor: powersave&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/fireducks-dev/polars-tpch/tree/fireducks_20250204">source code of the benchmark&lt;/a>&lt;/p>
&lt;p>The following graph compares four data frame libraries
(&lt;a href="https://pandas.pydata.org/">pandas&lt;/a>,
&lt;a href="https://duckdb.org/">DuckDB&lt;/a>, &lt;a href="https://pola.rs/">Polars&lt;/a>,
and FireDucks) on 22 different queries included in the benchmark. The vertical
axis shows how many times faster compared to pandas on a logarithmic scale,
where anything greater than 1 indicates that it is faster than pandas. &lt;strong>The
Scale Factor, which represents the data size is 10 (dataset of about 10 GB),
the time spent on each query was measured excluding I/O (RUN_IO_TYPE=skip, the
upper graph) and including I/O (RUN_IO_TYPE=parquet, the lower graph), and the
input data is generated using pyarrow (instead of polars) for better
performance for all libraries.&lt;/strong> Please refer to the procedure mentioned in
&lt;a href="https://github.com/fireducks-dev/polars-tpch/blob/fireducks_20250204/README.md">README&lt;/a>
to reproduce the evaluation result.&lt;/p>
&lt;p>The average speedup over pandas for 22 queries:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th style="text-align:center">Excluding I/O&lt;/th>
&lt;th style="text-align:center">Including I/O&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>DuckDB&lt;/td>
&lt;td style="text-align:center">63x&lt;/td>
&lt;td style="text-align:center">&lt;strong>43x&lt;/strong>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Polars&lt;/td>
&lt;td style="text-align:center">39x&lt;/td>
&lt;td style="text-align:center">32x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FireDucks&lt;/td>
&lt;td style="text-align:center">&lt;strong>78x&lt;/strong>&lt;/td>
&lt;td style="text-align:center">38x&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="excluding-io">Excluding I/O&lt;/h3>
&lt;p>&lt;img src="../20250204/polars-tpch-sf10-skip_20250204.webp" alt="polars-tpch-sf10-skip">&lt;/p>
&lt;h3 id="including-io">Including I/O&lt;/h3>
&lt;p>&lt;img src="../20250204/polars-tpch-sf10-parquet_20250204.webp" alt="polars-tpch-sf10-parquet">&lt;/p>
&lt;p>The versions of the libraries used were as follows (the latest versions at the time of the measurements).&lt;/p>
&lt;ul>
&lt;li>pandas: 2.2.3&lt;/li>
&lt;li>DuckDB: 1.1.3&lt;/li>
&lt;li>Polars: 1.21.0&lt;/li>
&lt;li>FireDucks: 1.2.0&lt;/li>
&lt;/ul>
&lt;h3 id="about-the-benchmark-code">About the benchmark code&lt;/h3>
&lt;p>This benchmark is originally from
&lt;a href="https://github.com/pola-rs/tpch">polars/tpch&lt;/a>. Because this repository
includes all 22 queries for polars but not all for pandas, we have implemented
all 22 queries using pandas, and then executed those using FireDucks by &lt;a href="https://fireducks-dev.github.io/docs/get-started/#import-hook">import hook&lt;/a>. These queries have been developed as
per the implementation in polars queries, so that the &lt;strong>apple-to-apple performance
comparison can be made on these two libraries&lt;/strong>. Since polars has different APIs
from pandas, there are minor differences in the implementation, but we kept the
number of time consuming operations like join/merge, filter, groupby etc. as
similar to that in polars implementation.&lt;/p>
&lt;h2 id="2024-12-06">2024-12-06&lt;/h2>
&lt;p>Server specification (AWS EC2 m7i.8xlarge):&lt;/p>
&lt;ul>
&lt;li>cpu: Intel(R) Xeon(R) Platinum 8488C (32cores)&lt;/li>
&lt;li>main memory: 128GB&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/fireducks-dev/polars-tpch/tree/fireducks_20241206">source code of the benchmark&lt;/a>&lt;/p>
&lt;p>The following graph compares four data frame libraries
(&lt;a href="https://pandas.pydata.org/">pandas&lt;/a>,
&lt;a href="https://github.com/modin-project/modin">modin&lt;/a>, &lt;a href="https://pola.rs/">polars&lt;/a>,
and fireducks) on 22 different queries included in the benchmark. The vertical
axis shows how many times faster compared to pandas on a logarithmic scale,
where anything greater than 1 indicates that it is faster than pandas. &lt;strong>The
Scale Factor, which represents the data size is 10 (dataset of about 10 GB),
the time spent on each query was measured excluding I/O (RUN_IO_TYPE=skip),
and the input data is generated using pyarrow (instead of polars) for a fair
comparison.&lt;/strong> Please refer to the procedure mentioned in
&lt;a href="https://github.com/fireducks-dev/polars-tpch/blob/fireducks/README.md">README&lt;/a>
to reproduce the evaluation result.&lt;/p>
&lt;p>The average speedup over pandas for 22 queries was 1.0x for Modin, 57x for
Polars, and &lt;strong>125x for FireDucks&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="../20241206/polars-tpch-sf10_20241205.webp" alt="polars-tpch-sf10">&lt;/p>
&lt;p>The versions of the libraries used were as follows (the latest versions at the time of the measurements).&lt;/p>
&lt;ul>
&lt;li>pandas: 2.2.3&lt;/li>
&lt;li>Modin: 0.32.0&lt;/li>
&lt;li>Polars: 1.6.0&lt;/li>
&lt;li>FireDucks: 1.1.2&lt;/li>
&lt;/ul>
&lt;h3 id="about-the-benchmark-code-1">About the benchmark code&lt;/h3>
&lt;p>This benchmark is originally from
&lt;a href="https://github.com/pola-rs/tpch">polars/tpch&lt;/a>. Because this repository
includes all 22 queries for polars but not all for pandas, we have implemented
all 22 queries using pandas, and then executed those using FireDucks by &lt;a href="https://fireducks-dev.github.io/docs/get-started/#import-hook">import hook&lt;/a>. These queries have been developed as
per the implementation in polars queries, so that the &lt;strong>apple-to-apple performance
comparison can be made on these two libraries&lt;/strong>. Since polars has different APIs
from pandas, there are minor differences in the implementation, but we kept the
number of time consuming operations like join/merge, filter, groupby etc. as
similar to that in polars implementation.&lt;/p>
&lt;h2 id="2024-09-09">2024-09-09&lt;/h2>
&lt;p>Server specification:&lt;/p>
&lt;ul>
&lt;li>cpu: intel(r) xeon(r) gold 5317 cpu @ 3.00ghz x 2sockets (48hw threads total)&lt;/li>
&lt;li>main memory: 256GB&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/fireducks-dev/polars-tpch/tree/fireducks">source code of the benchmark&lt;/a>&lt;/p>
&lt;p>The following graph compares four data frame libraries
(&lt;a href="https://pandas.pydata.org/">pandas&lt;/a>,
&lt;a href="https://github.com/modin-project/modin">modin&lt;/a>, &lt;a href="https://pola.rs/">polars&lt;/a>,
and fireducks) on 22 different queries included in the benchmark. The vertical
axis shows how many times faster compared to pandas on a logarithmic scale,
where anything greater than 1 indicates that it is faster than pandas. &lt;strong>The
Scale Factor, which represents the data size is 10 (dataset of about 10 GB),
the time spent on each query was measured excluding I/O (RUN_IO_TYPE=skip),
and the input data is generated using pyarrow (instead of polars) for a fair
comparison.&lt;/strong> Please refer to the procedure mentioned in
&lt;a href="https://github.com/fireducks-dev/polars-tpch/blob/fireducks/README.md">README&lt;/a>
to reproduce the evaluation result.&lt;/p>
&lt;p>The average speedup over pandas for 22 queries was 0.89x for Modin, 39x for
Polars, and &lt;strong>50x for FireDucks&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="../20240909/polars-tpch-sf10_20240909.webp" alt="polars-tpch-sf10">&lt;/p>
&lt;p>The versions of the libraries used were as follows (the latest versions at the time of the measurements).&lt;/p>
&lt;ul>
&lt;li>pandas: 2.2.2&lt;/li>
&lt;li>Modin: 0.31.0&lt;/li>
&lt;li>Polars: 1.6.0&lt;/li>
&lt;li>FireDucks: 1.0.3&lt;/li>
&lt;/ul>
&lt;p>The following chart shows the comparison between Polars and FireDucks with
larger dataset, Scale Factor 10, 20 and 50. The vertical axis shows how many
times faster FireDucks is compared to Polars. On average, &lt;strong>FireDucks is 1.3
times (sf=10), 1.3 times (sf=20), and 1.5 times (sf=50) faster than Polars&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="../20240909/polars-tpch_20240909.webp" alt="polars-tpch">&lt;/p>
&lt;h2 id="2024-06-05">2024-06-05&lt;/h2>
&lt;p>server specs&lt;/p>
&lt;ul>
&lt;li>cpu: intel(r) xeon(r) gold 5317 cpu @ 3.00ghz x 2sockets (48hw threads total)&lt;/li>
&lt;li>main memory: 256gb&lt;/li>
&lt;/ul>
&lt;h3 id="comparison-of-dataframe-libraries-using-tpc-h">comparison of dataframe libraries using tpc-h&lt;/h3>
&lt;p>&lt;a href="https://github.com/fireducks-dev/polars-tpch/tree/fireducks_20240605">source code of the benchmark&lt;/a>&lt;/p>
&lt;p>The following graph compares four data frame libraries
(&lt;a href="https://pandas.pydata.org/">pandas&lt;/a>,
&lt;a href="https://github.com/modin-project/modin">modin&lt;/a>, &lt;a href="https://pola.rs/">polars&lt;/a>,
and fireducks) on 22 different queries included in the benchmark. The vertical
axis shows how many times faster compared to pandas on a logarithmic scale,
where anything greater than 1 indicates that it is faster than pandas. The
Scale Factor, which represents the data size, is 10 (dataset of about 10 GB),
and the time spent on non-file IO was measured.&lt;/p>
&lt;p>The average speedup over pandas for 22 queries was 1.2x for Modin, 16x for
Polars, and &lt;strong>27x for FireDucks&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="../20240605/polars-tpch-sf10_20240605.webp" alt="polars-tpch-sf10">&lt;/p>
&lt;p>The versions of the libraries used were as follows (the latest versions at the time of the measurements).&lt;/p>
&lt;ul>
&lt;li>pandas: 2.2.2&lt;/li>
&lt;li>Modin: 0.30.0&lt;/li>
&lt;li>Polars: 0.20.29&lt;/li>
&lt;li>FireDucks: 0.11.4&lt;/li>
&lt;/ul>
&lt;p>The following chart shows the comparison between Polars and FireDucks with
larger dataset, Scale Factor 10, 20 and 50. The vertical axis shows how many
times faster FireDucks is compared to Polars. On average, &lt;strong>FireDucks is 1.7
times (sf=10), 1.7 times (sf=20), and 1.8 times (sf=50) faster than Polars&lt;/strong>.&lt;/p>
&lt;p>&lt;img src="../20240605/polars-tpch_20240605.webp" alt="polars-tpch">&lt;/p>
&lt;h3 id="about-the-benchmark-code-2">About the benchmark code&lt;/h3>
&lt;p>This benchmark is originally from
&lt;a href="https://github.com/pola-rs/tpch">polars/tpch&lt;/a>. Because this repository
includes all 22 queries for polars but not all for pandas and Modin, we have
implemented all 22 queries using pandas then run those with FireDucks by
&lt;a href="https://fireducks-dev.github.io/docs/get-started/#import-hook">import hook&lt;/a>. Those queries were
also used with pandas and modin for the queries. All code for the queries is
available at
&lt;a href="https://github.com/fireducks-dev/polars-tpch/tree/fireducks_20240605">fireducks-dev/polars-tpch&lt;/a>&lt;/p>
&lt;p>&lt;strong>NOTE&lt;/strong>: Our pandas/modin/fireducks version of queries are implemented keeping two simple things in mind:&lt;/p>
&lt;ol>
&lt;li>the outcome of each query should match with the expected result.&lt;/li>
&lt;li>the code should look cleaner with the best possible usage of the chained methods, as there are several ways of implementing the same thing in pandas.&lt;/li>
&lt;/ol>
&lt;p>The queries for polars seem to be implemented with the different rule as described
&lt;a href="https://pola.rs/posts/benchmarks/#adjusting-for-dataframe-front-ends">here&lt;/a>.
Thus for the performance comparison with polars, someone might say the evaluation is not apple-to-apple
(as in DuckDB, polars which have more similar APIs to that of SQL). As far as the result is same and written in
most understandable format (with the best usage of the APIs), the benchmark can be accepted.&lt;/p>
&lt;h2 id="2024-02-06">2024-02-06&lt;/h2>
&lt;p>Server Specs&lt;/p>
&lt;ul>
&lt;li>CPU: Intel(R) Xeon(R) Gold 5317 CPU @ 3.00GHz x 2sockets (48HW threads total)&lt;/li>
&lt;li>Main memory: 256GB&lt;/li>
&lt;/ul>
&lt;h3 id="comparison-of-dataframe-libraries-using-tpc-h-1">Comparison of DataFrame libraries using TPC-H&lt;/h3>
&lt;p>&lt;a href="https://github.com/fireducks-dev/polars-tpch/tree/fireducks">Source code of the benchmark&lt;/a>&lt;/p>
&lt;p>The following graph compares four data frame libraries (&lt;a href="https://pandas.pydata.org/">pandas&lt;/a>, &lt;a href="https://github.com/modin-project/modin">modin&lt;/a>, &lt;a href="https://pola.rs/">polars&lt;/a>, and fireducks) on 22 different queries included in the benchmark. The vertical axis shows how many times faster compared to pandas on a logarithmic scale, where anything greater than 1 indicates that it is faster than pandas. The Scale Factor, which represents the data size, is 10 (dataset of about 10 GB), and the time spent on non-file IO was measured.&lt;/p>
&lt;p>The average speedup over pandas for 22 queries was 1.3x for Modin, 13x for Polars, and 18x for FireDucks.&lt;/p>
&lt;p>&lt;img src="../20240206/polars-tpch-sf10.webp" alt="polars-tpch-sf10">&lt;/p>
&lt;p>The versions of the libraries used were as follows (the latest versions at the time of the measurements).&lt;/p>
&lt;ul>
&lt;li>pandas: 2.2.0&lt;/li>
&lt;li>Modin: 0.26.1&lt;/li>
&lt;li>Polars: 0.20.7&lt;/li>
&lt;li>FireDucks: 0.9.8&lt;/li>
&lt;/ul>
&lt;p>The following chart shows the comparison results between Polars and FireDucks with larger dataset, Scalar Factor 10, 20 and 50. The vertical axis shows how many times faster FireDucks is compared to Polars. On average, FireDucks is 1.3 times (sf=10), 1.3 times (sf=20), and 1.7 times (sf=50) faster than Polars.&lt;/p>
&lt;p>&lt;img src="../20240206/polars-tpch_20240206.webp" alt="polars-tpch">&lt;/p>
&lt;h3 id="about-the-benchmark-code-3">About the benchmark code&lt;/h3>
&lt;p>This benchmark is originally from &lt;a href="https://github.com/pola-rs/tpch">polars/tpch&lt;/a>. Because this repository includes all 22 queries for polars but not all for pandas, we have implemented all 22 queries using pandas then run those with FireDucks by &lt;a href="https://fireducks-dev.github.io/docs/get-started/#import-hook">import hook&lt;/a>. Those queries were also used with pandas and modin for the queries polars/tpch does not provide. All code for the queries is available at &lt;a href="https://github.com/fireducks-dev/polars-tpch/commit/c5b148731bf3ee79f07d898c0d70d2ac8276ef7b">fireducks-dev/polars-tpch&lt;/a>.&lt;/p>
&lt;h2 id="2024-01-12">2024-01-12&lt;/h2>
&lt;p>Server Specs&lt;/p>
&lt;ul>
&lt;li>CPU: Intel(R) Xeon(R) Gold 5317 CPU @ 3.00GHz x 2sockets (48HW threads total)&lt;/li>
&lt;li>Main memory: 256GB&lt;/li>
&lt;/ul>
&lt;h3 id="comparison-of-dataframe-libraries-using-tpc-h-2">Comparison of DataFrame libraries using TPC-H&lt;/h3>
&lt;p>The following graph compares four data frame libraries (&lt;a href="https://pandas.pydata.org/">pandas&lt;/a>, &lt;a href="https://github.com/modin-project/modin">modin&lt;/a>, &lt;a href="https://pola.rs/">polars&lt;/a>, and fireducks) on 22 different queries included in the benchmark. The vertical axis shows how many times faster compared to pandas on a logarithmic scale, where anything greater than 1 indicates that it is faster than pandas. The Scale Factor, which represents the data size, is 10 (data set of about 10 GB), and the time spent on non-file IO is measured.&lt;/p>
&lt;p>The average speedup over pandas for 22 queries was 1.8x for Modin, 12x for Polars, and 17x for FireDucks.&lt;/p>
&lt;p>&lt;img src="../20240112/polars-tpch1.webp" alt="polars-tpch1">&lt;/p>
&lt;p>The versions of the libraries used were as follows (the latest versions at the time of the measurements).&lt;/p>
&lt;ul>
&lt;li>pandas: 2.1.4&lt;/li>
&lt;li>Modin: 0.26.0&lt;/li>
&lt;li>Polars: 0.20.2&lt;/li>
&lt;li>FireDucks: 0.9.3&lt;/li>
&lt;/ul>
&lt;p>For each query, the FireDucks development team implemented the program using pandas for pandas, modin, and FireDucks, and used it for modin and FireDucks with changing import statement. &lt;a href="https://github.com/pola-rs/tpch">polars/tpch&lt;/a> was used for Polars.&lt;/p>
&lt;p>The following chart shows the comparison results between Polars and FireDucks with larger dataset, Scalar Factor 10, 20 and 50. The vertical axis shows how many times faster FireDucks is compared to Polars. On average, FireDucks is 1.4 times (sf=10), 1.4 times (sf=20), and 1.6 times (sf=50) faster than Polars.&lt;/p>
&lt;p>&lt;img src="../20240112/polars-tpch2.webp" alt="polars-tpch2">&lt;/p></description></item></channel></rss>