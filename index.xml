<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FireDucks â€“ FireDucks</title><link>https://fireducks-dev.github.io/</link><description>Recent content on FireDucks</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 31 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://fireducks-dev.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Posts: Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3</title><link>https://fireducks-dev.github.io/posts/data_flow_optimization/</link><pubDate>Fri, 31 Jan 2025 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/data_flow_optimization/</guid><description>
&lt;p>In the previous &lt;a href="../efficient_caching">article&lt;/a>, we have talked about how FireDucks lazy-execution can take care of the
caching for the intermediate results in order to avoid recomputation of an expensive operation.
In today&amp;rsquo;s article, we will focus on the &lt;strong>efficient data flow optimization&lt;/strong> by its JIT compiler.
We will first try to understand some best practices when performing large-scale data analysis in pandas
and then discuss how those can be automatically taken care by FireDucks lazy execution model.&lt;/p>
&lt;h2 id="challenge-1">Challenge #1&lt;/h2>
&lt;p>Let&amp;rsquo;s consider the following two queries solving the same problem: &lt;em>Find top 2 &amp;ldquo;A&amp;rdquo; based on the &amp;ldquo;B&amp;rdquo; column&lt;/em>.&lt;/p>
&lt;p>ðŸ‘‰ &lt;strong>Can you guess which one is better from performance point of view?&lt;/strong>&lt;/p>
&lt;p>(1) version 1&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>res &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>sort_values(by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>(2) version 2&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>tmp &lt;span style="color:#f92672">=&lt;/span> df[[&lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res &lt;span style="color:#f92672">=&lt;/span> tmp&lt;span style="color:#f92672">.&lt;/span>sort_values(by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Well, when we conducted this quiz in one of the recent Data Science events,
45% of the participants answered the first one is more efficient, while the remaining 55% answered the second one is more efficient.&lt;/p>
&lt;p>Congratulations, if your answer is (2) as well. ðŸ‘&lt;/p>
&lt;p>In real world situation the target data might have many columns and when we invoked sort operation on &lt;code>df&lt;/code> instance,
it performed sorting the entire data involving a significant cost in terms of memory and computational power.&lt;/p>
&lt;p>As depicted in the following diagram, if the data have columns from &amp;lsquo;a&amp;rsquo; to &amp;lsquo;j&amp;rsquo;, when performing the first query,
it also sorts the column &amp;lsquo;c&amp;rsquo; to &amp;lsquo;j&amp;rsquo; that is not of our interest. Hence, it is a wise call to create a view of
the part of data that is of our interest (as shown in the following figure) before performing an computationally intensive operation
like sort, groupby, join etc. At this we can save significant amount of runtime memory and computational time.
Such optimization is typically known as &lt;code>projection pushdown&lt;/code>.
&lt;img src="pushdown_projection.png" alt="projection pushdown example">&lt;/p>
&lt;h2 id="challenge-2">Challenge #2&lt;/h2>
&lt;p>Let&amp;rsquo;s now consider another example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#f92672">=&lt;/span> employee&lt;span style="color:#f92672">.&lt;/span>merge(country, on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;C_Code&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f &lt;span style="color:#f92672">=&lt;/span> m[m[&lt;span style="color:#e6db74">&amp;#34;Gender&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Male&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;C_Name&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;E_Name&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>count()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The following diagram illustrates the operations that takes place while executing the query above:
&lt;img src="illustration1.png" alt="country-wise count of male employees">&lt;/p>
&lt;p>ðŸ‘‰ &lt;strong>Can you guess the performance bottleneck involved in the above query?&lt;/strong>&lt;/p>
&lt;p>Probably you guessed it correct!!&lt;/p>
&lt;p>The query wants to analyze only the &lt;code>male&lt;/code> employees.
Then why to include all the employees at the very first step while joining the two dataframes &lt;code>employee&lt;/code> and &lt;code>country&lt;/code>?
We could simply filter only the male employees from the &lt;code>employee&lt;/code> data and
perform the rest of the operations like merge, groupby etc. on the filtered result as shown below.
At this we could save significant execution time and memory during the expensive merge operation.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>f &lt;span style="color:#f92672">=&lt;/span> employee[employee[&lt;span style="color:#e6db74">&amp;#34;Gender&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Male&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>m &lt;span style="color:#f92672">=&lt;/span> f&lt;span style="color:#f92672">.&lt;/span>merge(country, on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;C_Code&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r &lt;span style="color:#f92672">=&lt;/span> m&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;C_Name&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;E_Name&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>count()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Such optimization is typically known as &lt;code>predicate pushdown&lt;/code>.
&lt;img src="predicate_pushdown.png" alt="predicate pushdown example">&lt;/p>
&lt;h2 id="lets-follow-these-best-practices">Let&amp;rsquo;s follow these best practices&lt;/h2>
&lt;p>When dealing with large-scale data, sometime we might not be interested on all part of the data.
Hence, its always the best practice to reduce the scope of your data before applying an
expensive operation on it to reduce a significant amount of runtime memory and computational time.&lt;/p>
&lt;ul>
&lt;li>When it is known that you are going to perform an operation that involves only some of the columns,
it is recommended to project the target columns first to reduce it in the horizontal direction.&lt;/li>
&lt;li>Again, if your operation targets only some selected rows of the data,
it is recommended to filter the target rows before performing the operation to reduce it further in the vertical direction.&lt;/li>
&lt;/ul>
&lt;p>For example, let&amp;rsquo;s consider the below example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>sort_values(&lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>query(&lt;span style="color:#e6db74">&amp;#34;B &amp;gt; 1&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;E&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s consider the data with following color codes, where the expected sorted order is: &lt;strong>yellow, red, green, blue.&lt;/strong>&lt;/p>
&lt;p>Also, let&amp;rsquo;s assume B=1 for darker shade and B=2 for lighter shade.
The flow of the above operation will be as follows:
&lt;img src="illustration2.png" alt="sample data flow">&lt;/p>
&lt;p>As you can see the columns &lt;code>C&lt;/code> and &lt;code>D&lt;/code> have been used in all the first three steps, but they have never been required in the final result.
Also, the sort operation is performed on all the rows of the data, whereas we are only interested in the data of the lighter shades.&lt;/p>
&lt;p>Hence, the optimized data flow could be as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>loc[:, [&lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;B&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;E&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>query(&lt;span style="color:#e6db74">&amp;#34;B &amp;gt; 1&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values(&lt;span style="color:#e6db74">&amp;#34;A&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;E&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It efficiently reduces the data in the horizontal (applying projection pushdown) and vertical (applying predicate pushdown) direction,
before applying the expensive sort operation as depicted follows:
&lt;img src="illustration3.png" alt="sample optimized data flow">&lt;/p>
&lt;h2 id="case-study">Case Study&lt;/h2>
&lt;p>Now let&amp;rsquo;s understand how such optimization can be useful in real world situations.&lt;/p>
&lt;p>The &lt;a href="https://www.tpc.org/tpch/">TPC-H&lt;/a> is a decision support benchmark that consists of a suite of business-oriented ad-hoc queries and concurrent data modifications.
We will use &lt;a href="https://www.tpc.org/TPC_Documents_Current_Versions/pdf/TPC-H_v3.0.1.pdf#page=33">Query-3&lt;/a> as an example in this demonstration that deals with three large tables,
namely &lt;code>lineitem&lt;/code>, &lt;code>customer&lt;/code>, and &lt;code>orders&lt;/code> with complex join, groupby, sort etc.&lt;/p>
&lt;p>The original query was written in SQL. We can realize the following pandas equaivalent of the same query:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">q3&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;customer.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;orders.parquet&amp;#34;&lt;/span>), left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;lineitem.parquet&amp;#34;&lt;/span>), left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;BUILDING&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;&lt;/span> datetime&lt;span style="color:#f92672">.&lt;/span>date(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> datetime&lt;span style="color:#f92672">.&lt;/span>date(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>assign(revenue&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[&lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>], as_index&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>agg({&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;sum&amp;#34;&lt;/span>})[[&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values([&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>], ascending&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#66d9ef">True&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>reset_index(drop&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>to_parquet(&lt;span style="color:#e6db74">&amp;#34;result.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The above implementation doesn&amp;rsquo;t take care of the &amp;ldquo;best practices&amp;rdquo;.
It loads the entire data from all the three tables and directly merge them to construct a large table
before performing rest of the filter, groupby etc. operations as required for the query.&lt;/p>
&lt;p>When we executed the above program in pandas, it &lt;strong>took around 203 seconds and the memory consumption was around 60 GB&lt;/strong>.
&lt;img src="q3_pandas.png" alt="pandas q3 metrics">&lt;/p>
&lt;p>Let&amp;rsquo;s now implement the best-practices discussed in the previous section to manually optimize the query as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">optimized_q3&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># load only required columns from respective tables&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> req_customer_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># (2/8)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> req_lineitem_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>] &lt;span style="color:#75715e">#(4/16)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> req_orders_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>] &lt;span style="color:#75715e">#(4/9)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> customer &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;customer.parquet&amp;#34;&lt;/span>, columns &lt;span style="color:#f92672">=&lt;/span> req_customer_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lineitem &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;lineitem.parquet&amp;#34;&lt;/span>, columns &lt;span style="color:#f92672">=&lt;/span> req_lineitem_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> orders &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;orders.parquet&amp;#34;&lt;/span>, columns &lt;span style="color:#f92672">=&lt;/span> req_orders_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œcustomerâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f_cust &lt;span style="color:#f92672">=&lt;/span> customer[customer[&lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;BUILDING&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œordersâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f_ord &lt;span style="color:#f92672">=&lt;/span> orders[orders[&lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;&lt;/span> datetime&lt;span style="color:#f92672">.&lt;/span>date(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œlineitemâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f_litem &lt;span style="color:#f92672">=&lt;/span> lineitem[lineitem[&lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> datetime&lt;span style="color:#f92672">.&lt;/span>date(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f_cust&lt;span style="color:#f92672">.&lt;/span>merge(f_ord, left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(f_litem, left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>assign(revenue&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[&lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>], as_index&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>agg({&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;sum&amp;#34;&lt;/span>})[[&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values([&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>], ascending&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#66d9ef">True&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>reset_index(drop&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>to_parquet(&lt;span style="color:#e6db74">&amp;#34;result.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Instead of loading all the 8 columns from the &lt;code>customer&lt;/code> table,
all the 16 columns from the &lt;code>lineitem&lt;/code> table,
and all the 9 columns from the &lt;code>orders&lt;/code> table,
it loads only the target columns that would be required to implement the query
by reducing the data in the horizontal direction (applying projection pushdown).&lt;/p>
&lt;p>Also, since we need only a specific rows from these tables based on the given conditions,
we performed an early filtration on the loaded data to reduce it further in the vertical direction (applying predicate pushdown).&lt;/p>
&lt;p>When we executed the above optimized implementation using pandas, it &lt;strong>took around 13 seconds and the memory consumption was around 5.5 GB&lt;/strong>.
&lt;img src="opt_q3_pandas.png" alt="pandas optimized-q3 metrics">&lt;/p>
&lt;p>From this experiment, it is quite evident that an optimized implementation of a pandas program
can itself improve its performance and memory consumption to a great extent.&lt;/p>
&lt;p>ðŸ‘‰ &lt;strong>Q. Can we automate such optimization such that one can focus more on in-depth data analysis relying on some tool or library for such expert-level optimization?&lt;/strong>&lt;/p>
&lt;p>The answer is &lt;strong>&amp;ldquo;YES&amp;rdquo;&lt;/strong>. You can rely on FireDucks for such optimization for sure. ðŸš€&lt;/p>
&lt;h2 id="fireducks-offerings">FireDucks Offerings&lt;/h2>
&lt;p>While being highly compatible with pandas,
FireDucks can perform such expert-level optimization automatically when using its default lazy execution mode.&lt;/p>
&lt;p>In order to verify the same, we have executed the methods as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># to use FireDucks for all the processings&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>q3()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>optimized_q3()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>And the execution could be completed within 4-5 seconds for both these cases showing FireDucks strength
in performing such optimizations automatically even when the program itself doesn&amp;rsquo;t take care of it (as in q3).&lt;/p>
&lt;p>We have used &lt;code>v2-8 TPU&lt;/code> instance from Google Colab for this evaluation and here is the finding in detail:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;/th>
&lt;th style="text-align:right">(pandas, exec_time (s))&lt;/th>
&lt;th style="text-align:right">(pandas, memory (GB))&lt;/th>
&lt;th style="text-align:right">(FireDucks, exec_time (s))&lt;/th>
&lt;th style="text-align:right">(FireDucks, memory (GB))&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">q3&lt;/td>
&lt;td style="text-align:right">203.18&lt;/td>
&lt;td style="text-align:right">60&lt;/td>
&lt;td style="text-align:right">4.24&lt;/td>
&lt;td style="text-align:right">3.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">optimized_q3&lt;/td>
&lt;td style="text-align:right">12.97&lt;/td>
&lt;td style="text-align:right">5.5&lt;/td>
&lt;td style="text-align:right">4.81&lt;/td>
&lt;td style="text-align:right">3.4&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>You might like to try this &lt;a href="https://colab.research.google.com/github/fireducks-dev/fireducks/blob/main/notebooks/tpch-query3-pandas-fireducks-cudf.ipynb">notebook&lt;/a>
on Google colab to reproduce the same.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping-up&lt;/h2>
&lt;p>Thank you for your time in reading this article.
We have discussed a couple of best practices that one should follow when performing large-scale data analysis in pandas
and how FireDucks can automatically implement the same. The experimental result shows when switching from pandas to FireDucks,
it can improve performance of a poorly written program by 48x (203.18s -&amp;gt; 4.24s)
while reducing the memory consumption by 18x (60 GB -&amp;gt; 3.3 GB).&lt;/p>
&lt;p>In case you have any queries or have an issue to report,
please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Pitfalls of Time Measurement for FireDucks with %%time in Notebooks</title><link>https://fireducks-dev.github.io/posts/2024-12-26-time-pitfalls/</link><pubDate>Thu, 26 Dec 2024 09:35:10 +0900</pubDate><guid>https://fireducks-dev.github.io/posts/2024-12-26-time-pitfalls/</guid><description>
&lt;p>This is Osamu Daido from the FireDucks development team. In today's developers' blog, I would like to present a subtle pitfall in time measurement.&lt;/p>
&lt;h2 id="quick-overview">Quick Overview&lt;/h2>
&lt;p>When measuring the execution time of FireDucks using the &lt;code>%%time&lt;/code> magic command in IPython Notebooks, make sure to always call the &lt;code>_evaluate()&lt;/code> method of DataFrames or Series to ensure proper evaluation!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">%%&lt;/span>time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;input.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>_evaluate()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="time-measurement-in-notebooks">Time Measurement in Notebooks&lt;/h2>
&lt;p>Jupyter and other IPython Notebooks provide the &lt;code>%%time&lt;/code> magic command to measure the execution time of the code written in a cell. For instance, a single percent sign &lt;code>%time&lt;/code> measures the execution time of only one line of code, while double percent signs &lt;code>%%time&lt;/code> measure the execution time for the entire cell. You may be interested in or curious about measuring the execution time of FireDucks because it can process data faster while offering the same API as pandas.&lt;/p>
&lt;p>However&amp;hellip;, hmm? Do you think the following time measurement is correct?&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">%%&lt;/span>time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;sample-dataset-tips.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>head()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;pre>&lt;code>CPU times: user 3.37 ms, sys: 4.06 ms, total: 7.43 ms
Wall time: 6.87 ms
&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:right">&lt;/th>
&lt;th style="text-align:right">total_bill&lt;/th>
&lt;th style="text-align:right">tip&lt;/th>
&lt;th style="text-align:right">sex&lt;/th>
&lt;th style="text-align:right">smoker&lt;/th>
&lt;th style="text-align:right">day&lt;/th>
&lt;th style="text-align:right">time&lt;/th>
&lt;th style="text-align:right">size&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:right">0&lt;/td>
&lt;td style="text-align:right">16.99&lt;/td>
&lt;td style="text-align:right">1.01&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">No&lt;/td>
&lt;td style="text-align:right">Sun&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">1&lt;/td>
&lt;td style="text-align:right">10.34&lt;/td>
&lt;td style="text-align:right">1.66&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">No&lt;/td>
&lt;td style="text-align:right">Sun&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">2&lt;/td>
&lt;td style="text-align:right">21.01&lt;/td>
&lt;td style="text-align:right">3.50&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">No&lt;/td>
&lt;td style="text-align:right">Sun&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">3&lt;/td>
&lt;td style="text-align:right">23.68&lt;/td>
&lt;td style="text-align:right">3.31&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">No&lt;/td>
&lt;td style="text-align:right">Sun&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">4&lt;/td>
&lt;td style="text-align:right">24.59&lt;/td>
&lt;td style="text-align:right">3.61&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">No&lt;/td>
&lt;td style="text-align:right">Sun&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">4&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/blockquote>
&lt;h3 id="time-measurement-for-fireducks">Time Measurement for FireDucks&lt;/h3>
&lt;p>As explained on &lt;a href="https://fireducks-dev.github.io/docs/user-guide/02-exec-model/">the execution model page&lt;/a>, FireDucks uses a lazy execution model. In simple terms, FireDucks DataFrames do not begin actual processing until explicitly displayed on the screen with functions like &lt;code>print()&lt;/code> or &lt;code>display()&lt;/code>, or when the &lt;code>_evaluate()&lt;/code> method is called. FireDucks can process data more quickly by optimizing the accumulated operations before executing them. This execution of accumulated operations is referred to as &amp;ldquo;evaluation.&amp;rdquo;&lt;/p>
&lt;p>In IPython Notebooks, if the last line of a cell is not an assignment statement but simply a value, it is automatically displayed on the screen, similar to the Python interpreter's REPL. In IPython terms, it's as if &lt;code>display()&lt;/code> is automatically called. This means that if you place a FireDucks DataFrame at the end of a cell, it will also be automatically evaluated.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;sample-dataset-tips.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>sort_values(by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;tip&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#75715e"># THIS!&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, there is a subtle pitfall when you want to measure execution time using the &lt;code>%%time&lt;/code> magic command. Just because placing a FireDucks DataFrame at the end of a cell triggers automatic evaluation, it does not necessarily mean that the correct execution time is measured.&lt;/p>
&lt;h3 id="example-of-incorrect-time-measurement">Example of Incorrect Time Measurement&lt;/h3>
&lt;p>I prepared a CSV file of about 10GB for experimentation. When executing the following cell, something strange happens.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">%%&lt;/span>time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;sample-dataset-tips10gb.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>sort_values(by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;tip&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;pre>&lt;code>CPU times: user 18.2 ms, sys: 4.31 ms, total: 22.5 ms
Wall time: 15.2 ms
&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:right">&lt;/th>
&lt;th style="text-align:right">total_bill&lt;/th>
&lt;th style="text-align:right">tip&lt;/th>
&lt;th style="text-align:right">sex&lt;/th>
&lt;th style="text-align:right">smoker&lt;/th>
&lt;th style="text-align:right">day&lt;/th>
&lt;th style="text-align:right">time&lt;/th>
&lt;th style="text-align:right">size&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:right">67&lt;/td>
&lt;td style="text-align:right">3.07&lt;/td>
&lt;td style="text-align:right">1.0&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">92&lt;/td>
&lt;td style="text-align:right">5.75&lt;/td>
&lt;td style="text-align:right">1.0&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Fri&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">319815362&lt;/td>
&lt;td style="text-align:right">50.81&lt;/td>
&lt;td style="text-align:right">10.0&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">319815606&lt;/td>
&lt;td style="text-align:right">50.81&lt;/td>
&lt;td style="text-align:right">10.0&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>319815680 rows x 7 columns&lt;/p>
&lt;/blockquote>
&lt;p>Let's look at the line labeled &amp;ldquo;Wall time.&amp;rdquo; Imagine if it only took 15 milliseconds to read and sort data with 300 million rows â€” wouldn't that be incredible? In reality, it took about 10 seconds from the start of the cell's execution until the results were displayed. You might wonder, &amp;ldquo;The results are displayed on the screen, so shouldn't they be properly evaluated?&amp;rdquo; That's half true and half false.&lt;/p>
&lt;p>In fact, with this approach, the evaluation of the DataFrame begins only after the &lt;code>%%time&lt;/code> timer has stopped. In other words, because the order is &lt;strong>timer stops â†’ evaluation â†’ display&lt;/strong>, the actual processing of the DataFrame is outside the measurement range of &lt;code>%%time&lt;/code>.&lt;/p>
&lt;h3 id="example-of-correct-time-measurement">Example of Correct Time Measurement&lt;/h3>
&lt;p>Therefore, even in IPython Notebooks, when you want to measure execution time, make sure to explicitly call the &lt;code>_evaluate()&lt;/code> method of DataFrames to properly evaluate them. Writing it as shown below will execute in the order of &lt;strong>evaluation â†’ timer stops â†’ display&lt;/strong>. This way, the actual processing of the DataFrame falls within the measurement range of &lt;code>%%time&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">%%&lt;/span>time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;sample-dataset-tips10gb.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>sort_values(by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;tip&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>_evaluate()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;pre>&lt;code>CPU times: user 3min 58s, sys: 1min 2s, total: 5min
Wall time: 11.1 s
&lt;/code>&lt;/pre>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:right">&lt;/th>
&lt;th style="text-align:right">total_bill&lt;/th>
&lt;th style="text-align:right">tip&lt;/th>
&lt;th style="text-align:right">sex&lt;/th>
&lt;th style="text-align:right">smoker&lt;/th>
&lt;th style="text-align:right">day&lt;/th>
&lt;th style="text-align:right">time&lt;/th>
&lt;th style="text-align:right">size&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:right">67&lt;/td>
&lt;td style="text-align:right">3.07&lt;/td>
&lt;td style="text-align:right">1.0&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">92&lt;/td>
&lt;td style="text-align:right">5.75&lt;/td>
&lt;td style="text-align:right">1.0&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Fri&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">319815362&lt;/td>
&lt;td style="text-align:right">50.81&lt;/td>
&lt;td style="text-align:right">10.0&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">319815606&lt;/td>
&lt;td style="text-align:right">50.81&lt;/td>
&lt;td style="text-align:right">10.0&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>319815680 rows x 7 columns&lt;/p>
&lt;/blockquote>
&lt;h3 id="slightly-different-solution">Slightly Different Solution&lt;/h3>
&lt;p>If you write it as shown below, the order will be &lt;strong>evaluation â†’ display â†’ timer stops&lt;/strong>. In this case, the process to display the DataFrame on the screen inadvertently becomes part of the time measurement. Do you notice any other differences? You might notice that the order of the DataFrame output and the timing result output is reversed.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">%%&lt;/span>time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#34;sample-dataset-tips10gb.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>sort_values(by&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;tip&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>display(df)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:right">&lt;/th>
&lt;th style="text-align:right">total_bill&lt;/th>
&lt;th style="text-align:right">tip&lt;/th>
&lt;th style="text-align:right">sex&lt;/th>
&lt;th style="text-align:right">smoker&lt;/th>
&lt;th style="text-align:right">day&lt;/th>
&lt;th style="text-align:right">time&lt;/th>
&lt;th style="text-align:right">size&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:right">67&lt;/td>
&lt;td style="text-align:right">3.07&lt;/td>
&lt;td style="text-align:right">1.0&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">92&lt;/td>
&lt;td style="text-align:right">5.75&lt;/td>
&lt;td style="text-align:right">1.0&lt;/td>
&lt;td style="text-align:right">Female&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Fri&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">2&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;td style="text-align:right">&amp;hellip;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">319815362&lt;/td>
&lt;td style="text-align:right">50.81&lt;/td>
&lt;td style="text-align:right">10.0&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:right">319815606&lt;/td>
&lt;td style="text-align:right">50.81&lt;/td>
&lt;td style="text-align:right">10.0&lt;/td>
&lt;td style="text-align:right">Male&lt;/td>
&lt;td style="text-align:right">Yes&lt;/td>
&lt;td style="text-align:right">Sat&lt;/td>
&lt;td style="text-align:right">Dinner&lt;/td>
&lt;td style="text-align:right">3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>319815680 rows x 7 columns&lt;/p>
&lt;pre>&lt;code>CPU times: user 3min 58s, sys: 55.4 s, total: 4min 53s
Wall time: 10.6 s
&lt;/code>&lt;/pre>
&lt;/blockquote>
&lt;h2 id="wrap-up">Wrap-up&lt;/h2>
&lt;p>FireDucks has the same API as pandas while adopting a lazy evaluation mechanism, so itâ€™s important to pay attention to such subtle details when measuring processing time. However, FireDucks allows you to speed up processing while using nearly the same code as you would with pandas, making it a powerful ally for data science.&lt;/p>
&lt;p>Recently, many people have shown interest in FireDucks, and we are receiving more feedback about its improved speed as well as bug reports. As the development team, we are committed to making sure FireDucks gets widely used and continues to be valuable over the long term. Please stay tuned for future updates!&lt;/p>
&lt;p>May the Acceleration be with you, FireDucks Development Team&lt;/p></description></item><item><title>Posts: Exploring performance benefits of FireDucks over cuDF</title><link>https://fireducks-dev.github.io/posts/cudf_vs_fireducks/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/cudf_vs_fireducks/</guid><description>
&lt;p>&lt;a href="https://www.anaconda.com/resources/whitepapers/state-of-data-science-2020">Research&lt;/a> says that Data
scientists spend about 45% of their time on data preparation tasks, including loading (19%) and
cleaning (26%) the data. &lt;a href="https://pandas.pydata.org/">Pandas&lt;/a> is one of the most popular python
libraries for tabular data processing because of its diverse utilities and large community support.
However, due to its performance issue with the large-scale data processing, there is a strong need
for high-performance data frame libraries for the community. Although there are many alternatives
available at this moment, due to compatibility issues with pandas some of those either compel
a user to learn completely new APIs (incurring migration cost) or to switch to a more
efficient computational systems, like GPU etc. (incurring hardware cost).&lt;/p>
&lt;p>In this article we will discuss two high-performance pandas alternatives that can help a pandas programmer
to smoothly migrate an existing application while offering promising speed. They are:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.rapids.ai/api/cudf/stable">cuDF&lt;/a>: GPU accelerated DataFrame library with highly compatible pandas APIs&lt;/li>
&lt;li>&lt;a href="https://fireducks-dev.github.io/">FireDucks&lt;/a>: A compiler accelerated DataFrame library with highly compatible pandas APIs for speedup even on CPU only systems&lt;/li>
&lt;/ul>
&lt;h2 id="fireducks-vs-cudf">FireDucks vs. cuDF&lt;/h2>
&lt;p>Both FireDucks and cuDF offer the following:&lt;/p>
&lt;ul>
&lt;li>ensure zero code changes with promising speedup&lt;/li>
&lt;li>highly-compatible pandas APIs for a seamless integration with an existing pandas application&lt;/li>
&lt;li>import-hook feature for a seamless integration with third party library using pandas&lt;/li>
&lt;li>parallel implementation of the kernel algorithms (like join, groupby etc.) to leverage all the available cores&lt;/li>
&lt;/ul>
&lt;p>However, the key differences are:&lt;/p>
&lt;ul>
&lt;li>FireDucks can speedup an existing pandas application even on CPU only systems, whereas
one needs to prepare a GPU environment before trying cuDF.&lt;/li>
&lt;li>FireDucks supports a lazy execution model aiming for JIT query optimization, whereas
cuDF supports only an eager execution model (similar to pandas). Therefore, if the program
is not written carefully with the right data-flow, cuDF might suffer performance issue while
FireDucks can outperform cuDF even on CPU only systems due to its efficient query optimization.&lt;/li>
&lt;/ul>
&lt;h2 id="evaluation">Evaluation&lt;/h2>
&lt;h3 id="multi-threaded-benefit">Multi-threaded Benefit&lt;/h3>
&lt;p>Here is an &lt;a href="https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes">article&lt;/a>
explaining the key features of cuDF along with its performance. We have used the notebook provided in that article
to evaluate &lt;code>pandas&lt;/code>, &lt;code>fireducks.pandas&lt;/code>, and &lt;code>cudf.pandas&lt;/code> respectively.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/pandas_nyc_demo.ipynb">test drive for native pandas&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/fireducks_pandas_nyc_demo.ipynb">test drive for fireducks.pandas&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/cudf_pandas_nyc_demo.ipynb">test drive for cudf.pandas&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Here are some details related to the evaluation environment:&lt;/p>
&lt;ul>
&lt;li>CPU model: Intel(R) Xeon(R) Gold 6126 CPU @ 2.60GHz&lt;/li>
&lt;li>CPU cores: 48&lt;/li>
&lt;li>Main memory: 256gb&lt;/li>
&lt;li>GPU model: NVIDIA Tesla V100&lt;/li>
&lt;/ul>
&lt;p>It can be noted that, by simply enabling the extension &lt;code>%load_ext fireducks.pandas&lt;/code>
or &lt;code>%load_ext cudf.pandas&lt;/code>, one can successfully speedup the operations in an
existing pandas notebook using FireDucks or cuDF. For this experiment, we have
disabled FireDucks lazy-execution mode as follows for a fair comparison among these 3 libraries:&lt;/p>
&lt;pre tabindex="0">&lt;code>from fireducks.core import get_fireducks_options
get_fireducks_options().set_benchmark_mode(True)
&lt;/code>&lt;/pre>&lt;p>The table below summarizes the query wise execution time for these libraries:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;/th>
&lt;th style="text-align:right">pandas (sec)&lt;/th>
&lt;th style="text-align:right">FireDucks (sec)&lt;/th>
&lt;th style="text-align:right">cuDF (sec)&lt;/th>
&lt;th style="text-align:left">speedup_from_FireDucks_over_pandas&lt;/th>
&lt;th style="text-align:left">speedup_from_cuDF_over_pandas&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">data_loading&lt;/td>
&lt;td style="text-align:right">1.85&lt;/td>
&lt;td style="text-align:right">0.53&lt;/td>
&lt;td style="text-align:right">0.42&lt;/td>
&lt;td style="text-align:left">3.49x&lt;/td>
&lt;td style="text-align:left">4.4x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">query_1&lt;/td>
&lt;td style="text-align:right">2.4&lt;/td>
&lt;td style="text-align:right">0.08&lt;/td>
&lt;td style="text-align:right">0.35&lt;/td>
&lt;td style="text-align:left">30.0x&lt;/td>
&lt;td style="text-align:left">6.86x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">query_2&lt;/td>
&lt;td style="text-align:right">0.75&lt;/td>
&lt;td style="text-align:right">0.03&lt;/td>
&lt;td style="text-align:right">0.01&lt;/td>
&lt;td style="text-align:left">25.0x&lt;/td>
&lt;td style="text-align:left">75.0x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">query_3&lt;/td>
&lt;td style="text-align:right">6.38&lt;/td>
&lt;td style="text-align:right">0.15&lt;/td>
&lt;td style="text-align:right">0.08&lt;/td>
&lt;td style="text-align:left">42.53x&lt;/td>
&lt;td style="text-align:left">79.75x&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Due to difference in the underlined hardware, cuDF operations (that worked on GPU) definitely performed much better
when compared to pandas, but the performance gain from FireDucks over pandas even on CPU is quite promising.
In fact, the &lt;strong>overall speedup is ~13x (11.37s -&amp;gt; 0.87s) when using cuDF,
whereas it is ~14x (11.37s -&amp;gt; 0.79s) when using FireDucks&lt;/strong> for the same pandas program.&lt;/p>
&lt;h3 id="jit-optimization-benefit">JIT Optimization Benefit&lt;/h3>
&lt;p>The above case shows how efficiently FireDucks can leverage the available cpu cores to speedup an existing pandas program.&lt;/p>
&lt;p>Let&amp;rsquo;s now understand how FireDucks JIT query optimization can make it even better!!&lt;/p>
&lt;p>We have used a &lt;a href="https://www.tpc.org/TPC_Documents_Current_Versions/pdf/TPC-H_v3.0.1.pdf#page=33">sample query&lt;/a>
from the &lt;a href="https://www.tpc.org/tpch/">TPC-H benchmark&lt;/a> that deals with a couple of tables of different dimensions
for a scale-factor 10.&lt;/p>
&lt;p>ðŸ‘‰ &lt;strong>Purpose: To retrieve the 10 unshipped orders with the highest value.&lt;/strong>&lt;/p>
&lt;p>Here is the pandas implementation for this query:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;customer.parquet&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;orders.parquet&amp;#34;&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;lineitem.parquet&amp;#34;&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;BUILDING&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>assign(revenue&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[&lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>], as_index&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>agg({&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;sum&amp;#34;&lt;/span>})[[&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values([&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>], ascending&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#66d9ef">True&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>reset_index(drop&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>to_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;q3_result.parquet&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This time we have used the default lazy-execution mode in FireDucks to demonstrate its true strength.
The execution time of this query for each DataFrame library is as follows:&lt;/p>
&lt;ul>
&lt;li>native pandas: 215.47 sec&lt;/li>
&lt;li>fireducks.pandas: 1.69 sec&lt;/li>
&lt;li>cudf.pandas: 26.79 sec&lt;/li>
&lt;/ul>
&lt;p>ðŸš€ðŸš€ &lt;strong>FireDucks outperformed pandas upto 127x (215.47s -&amp;gt; 1.69s) and cuDF upto 15x (26.79s -&amp;gt; 1.69s) for the avove query.&lt;/strong>&lt;/p>
&lt;p>ðŸ¤” You might be wondering how a CPU-based implementation in FireDucks can be
faster than a GPU-based implementation in cuDF!!&lt;/p>
&lt;p>This speedup from FireDucks is due to the efficient query planning and optimization that
is performed by the internal JIT compiler. Instead of executing the input query as it is,
it attempts to optimize the same by reducing the scope of the input data for the time
consuming join, groupby etc. operations majorly using the following steps:&lt;/p>
&lt;ul>
&lt;li>loading only required columns from the input parquet files to reduce the data horizontally&lt;/li>
&lt;li>performing early filtration to reduce the data vertically&lt;/li>
&lt;/ul>
&lt;p>ðŸ““ In case of FireDucks lazy-execution mode, when a method like &lt;code>to_parquet&lt;/code>, &lt;code>plot&lt;/code>, &lt;code>print&lt;/code>
etc. are called, it enables the compiler to start optimizing the accumulated data flow. Once
the optimization phase is completed, it is executed by a multi-threaded CPU kernel backed by
arrow memory helping you to experience superfast data processing, along with remarkable
reduction in the computational memory.&lt;/p>
&lt;p>The optimized implementation for the same query could be as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>req_customer_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># selecting (2/8) columns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>req_lineitem_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># selecting (4/16) columns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>req_orders_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># selecting (4/9) columns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>customer &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;customer.parquet&amp;#34;&lt;/span>), columns &lt;span style="color:#f92672">=&lt;/span> req_customer_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lineitem &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;lineitem.parquet&amp;#34;&lt;/span>), columns &lt;span style="color:#f92672">=&lt;/span> req_lineitem_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>orders &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;orders.parquet&amp;#34;&lt;/span>), columns &lt;span style="color:#f92672">=&lt;/span> req_orders_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œcustomerâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_cust &lt;span style="color:#f92672">=&lt;/span> customer[customer[&lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;BUILDING&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œordersâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_ord &lt;span style="color:#f92672">=&lt;/span> orders[orders[&lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œlineitemâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_litem &lt;span style="color:#f92672">=&lt;/span> lineitem[lineitem[&lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f_cust&lt;span style="color:#f92672">.&lt;/span>merge(f_ord, left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(f_litem, left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>assign(revenue&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[&lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>], as_index&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>agg({&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;sum&amp;#34;&lt;/span>})[[&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values([&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>], ascending&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#66d9ef">True&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>reset_index(drop&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>to_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;opt_q3_result.parquet&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The execution time of this optimized implementation for each DataFrame library is as follows:&lt;/p>
&lt;ul>
&lt;li>native pandas: 11.13 sec&lt;/li>
&lt;li>fireducks.pandas: 1.72 sec&lt;/li>
&lt;li>cudf.pandas: 0.76 sec&lt;/li>
&lt;/ul>
&lt;p>It can be noted that:&lt;/p>
&lt;ul>
&lt;li>the native pandas could itself be optimized upto &lt;strong>~19x (215.47 sec -&amp;gt; 11.13 sec)&lt;/strong>&lt;/li>
&lt;li>there is no visible change in the execution time of FireDucks (&lt;strong>since the compiler does the same optimization automatically in the earlier case&lt;/strong>)&lt;/li>
&lt;li>the cudf.pandas could be optimized upto &lt;strong>~35x (26.79 sec -&amp;gt; 0.76 sec)&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Most importantly there is no impact in the final result due to the optimization performed.
You can reproduce the same using this &lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/tpch-query3-pandas-fireducks-cudf.ipynb">notebook&lt;/a> at your end.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping up&lt;/h2>
&lt;p>Thank you for your time in reading this article. We have discussed performance benefit of FireDucks
over cuDF. While cuDF shows significant speedup without modifying an existing pandas program,
its performance relies on the underlined GPU specification and how well the program is written, whereas
FireDucks can optimize an existing pandas program efficiently like an expert programmer and
execute the same without any extra overhead, that too on CPU only systems.&lt;/p>
&lt;p>Being said that, &lt;strong>a GPU version of FireDucks is under dvelopment&lt;/strong>. It internally uses &lt;code>cuDF.pandas&lt;/code>
for the kernel operations (like groupby, join etc.), while adding the JIT optimization for further
acceleration as explained in this article. For example, even when you write the query as in the
first implementation, it would be auto-optimized by the FireDucks compiler similar to the
optimized implementation and then it will be passed to the cuDF kernel for the execution
at the GPU side (helping you to experience the query to be finished in ~0.76 sec).
We will be talking about the GPU version of FireDucks in details in some other article.&lt;/p>
&lt;p>We look forward your constant feedback to make FireDucks even better.
Please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</title><link>https://fireducks-dev.github.io/posts/lazy_execution_offering_part1/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/lazy_execution_offering_part1/</guid><description>
&lt;p>The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas.
To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).&lt;/p>
&lt;p>Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?
For example, let&amp;rsquo;s consider the below data is stored in a parquet file, named sample_data.parquet (or in a csv file, named sample_data.csv):&lt;/p>
&lt;pre tabindex="0">&lt;code> a b c x y z
0 1 0.1 1 0 t1 10
1 2 0.2 4 1 t2 20
2 3 0.3 9 1 t3 30
3 4 0.4 16 0 t1 40
4 5 0.5 25 1 t2 50
5 6 0.6 36 1 t1 60
6 7 0.7 49 0 t2 70
7 8 0.8 64 1 t3 80
&lt;/code>&lt;/pre>&lt;p>And you want to perform sum of &amp;ldquo;c&amp;rdquo; column, when the value of &amp;ldquo;x&amp;rdquo; column is 1. You may simply write the program as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res &lt;span style="color:#f92672">=&lt;/span> df[df[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#75715e"># filter data based on condition and calculate sum of &amp;#34;c&amp;#34; column from filtered frame&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print (res)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the problem may occur when the parquet file is too large to fit in your system memory, although you are interested only a part of it (column &amp;ldquo;x&amp;rdquo; and &amp;ldquo;c&amp;rdquo;).
Thankfully, read_parquet() method has a parameter named &lt;code>columns&lt;/code> and you can specify the target columns to be loaded from the input parquet file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns &lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res &lt;span style="color:#f92672">=&lt;/span> df[df[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#75715e"># filter data based on condition and calculate sum of &amp;#34;c&amp;#34; column from filtered frame&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print (res)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Similarly, read_csv() has a parameter, named &lt;code>usecols&lt;/code> that can be specified when loading only target columns from a CSV file.&lt;/p>
&lt;h2 id="fireducks-offerings">FireDucks Offerings&lt;/h2>
&lt;p>Although such parameters can be specified to optimize runtime memory consumption when using pandas, it
might be difficult to know what all columns are required at the very begining of analysing the data.
An automatic optimization for such cases would definitely be useful for users of pandas-like libraries.&lt;/p>
&lt;p>Since &lt;strong>FireDucks 1.1.1&lt;/strong>, we have supported such optimization to be taken care of by its internal JIT compiler.
Even though such parameters are not manually specified, the JIT compiler can inspect the projection targets
on various stages for a given data and it can automatically specify such parameters when generating the optimized code.
Such optimization is commonly known as &lt;strong>pushdown-projection&lt;/strong>. By specifiying the environment variable &lt;strong>FIRE_LOG_LEVEL=3&lt;/strong>,
you can inspect the before and after optimization for the below example.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ cat read_parquet_opt_demo.py
import pandas as pd
df = pd.read_parquet(&amp;#34;sample_data.parquet&amp;#34;)
r1 = df[df[&amp;#34;x&amp;#34;] == 1][&amp;#34;c&amp;#34;].sum()
print(r1)
&lt;/code>&lt;/pre>&lt;p>Execute the program as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ FIRE_LOG_LEVEL=3 python -mfireducks.pandas read_parquet_opt_demo.py
&lt;/code>&lt;/pre>&lt;p>It will then show the intermediate representation (IR) generated for the above program before execution as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-04 13:12:40.618398: 543780 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, []) &amp;lt;- load the input parquet file
%t1 = project(%t0, &amp;#39;x&amp;#39;) &amp;lt;- project &amp;#34;x&amp;#34; column from loaded data (df[&amp;#34;x&amp;#34;])
%t2 = eq.vector.scalar(%t1, 1) &amp;lt;- generate mask with equality check with scalar value, 1 (mask = df[&amp;#34;x&amp;#34;] == 1)
%t3 = filter(%t0, %t2) &amp;lt;- perform filter with computed mask (fdf = df[mask])
%t4 = project(%t3, &amp;#39;c&amp;#39;) &amp;lt;- project &amp;#34;c&amp;#34; column from filtered data (fdf[&amp;#34;c&amp;#34;])
%v5 = aggregate_column.scalar(%t4, &amp;#39;sum&amp;#39;) &amp;lt;- calculate sum of projected column (fdf[&amp;#34;c&amp;#34;].sum())
return(%t4, %v5)
}
&lt;/code>&lt;/pre>&lt;p>And the Optimized IR (target for execution) is as follows.
You can see that it is mostly the same with the optimization added in the instruction for read_parquet()
by automatically specifying the target columns to be loaded for the computation of this specific result (r1).&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-04 13:12:40.619360: 543780 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [&amp;#39;c&amp;#39;, &amp;#39;x&amp;#39;])
%t1 = project(%t0, &amp;#39;x&amp;#39;)
%t2 = eq.vector.scalar(%t1, 1)
%t3 = project(%t0, [&amp;#39;c&amp;#39;])
%t4 = filter(%t3, %t2)
%t5 = project(%t4, &amp;#39;c&amp;#39;)
%v6 = aggregate_column.scalar(%t5, &amp;#39;sum&amp;#39;)
return(%t5, %v6)
}
&lt;/code>&lt;/pre>&lt;p>The python equivalent of the above optimized IR (that will be executed by the FireDucks multi-threaded kernel) is as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>]) &lt;span style="color:#75715e"># load only required column for analysis&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t1 &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># projection of target column for equality check&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t2 &lt;span style="color:#f92672">=&lt;/span> (t1 &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t3 &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># projection of only target column to be filtered&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t4 &lt;span style="color:#f92672">=&lt;/span> t3[t2]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t5 &lt;span style="color:#f92672">=&lt;/span> t4[&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>v6 &lt;span style="color:#f92672">=&lt;/span> t5&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>âš ï¸ Please note that the verification through this environment variable setting is mainly for the developers and
we might change the way of representing the IRs in future. As a user, it would be good to inspect the optimization
using this variable at this moment though.&lt;/p>
&lt;h2 id="lets-put-it-into-a-test-drive">Let&amp;rsquo;s put it into a test drive&lt;/h2>
&lt;p>You can refer to the &lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/read_parquet_optimization.ipynb">notebook&lt;/a>.
It demonstrates the performance benefit of such optimization on a real dataset.
You may like to experiment around the query to realize the efficiency of FireDucks optimization.
For a sample query, &lt;strong>FireDucks performed 45x faster than Pandas, that too without any modification in the source program and affecting the result&lt;/strong>.&lt;/p>
&lt;p>It also explains some Do&amp;rsquo;s and Don&amp;rsquo;ts when executing a query in notebook-like platform. In case of notebook, the execution takes place cell-by-cell.
Thus when keeping the intermediate results in some cell variables, FireDucks compiler assumes that those might be used at some later stage.
So it will keep all of them alive hindering the optimization. Therefore, it is highly recommended to write a query in chained expression
when using notebook.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping-up&lt;/h2>
&lt;p>Thank you for your time in reading this article.
In case you have any queries or have an issue to report, please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</title><link>https://fireducks-dev.github.io/posts/efficient_caching/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/efficient_caching/</guid><description>
&lt;p>In the previous &lt;a href="../lazy_execution_offering_part1">article&lt;/a>, we have talked about how FireDucks can take care pushdown-projection related
optimization for read_parquet(), read_csv() etc. In today&amp;rsquo;s article, we will focus on the efficient caching mechanism
by its JIT compiler.&lt;/p>
&lt;p>Let&amp;rsquo;s consider the below sample query for the same data, used in previous article:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r1 &lt;span style="color:#f92672">=&lt;/span> f_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(r1)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When executing the above program (saved as sample.py) as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ FIRE_LOG_LEVEL=3 python -mfireducks.pandas sample.py
&lt;/code>&lt;/pre>&lt;p>You can find the generated IR before and after optimization:&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-05 12:37:21.012481: 958259 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [])
%t1 = project(%t0, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %v6)
}
2024-12-05 12:37:21.013462: 958259 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [&amp;#39;x&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;z&amp;#39;])
%t1 = project(%t0, [&amp;#39;z&amp;#39;, &amp;#39;x&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %v6)
}
&lt;/code>&lt;/pre>&lt;p>It can be noted that the compiler correctly identified the projection targets for read_parquet() as &amp;ldquo;x&amp;rdquo;, &amp;ldquo;a&amp;rdquo;, and &amp;ldquo;z&amp;rdquo; columns.
Although the &amp;ldquo;y&amp;rdquo; column is specified to be projected in the loc indexer, but that column is never used within the
above program. Hence, that is not even loaded during the read_parquet stage.&lt;/p>
&lt;h2 id="could-lazy-execution-be-expensive">Could lazy execution be expensive?&lt;/h2>
&lt;p>Now, the question is what will happen if we want to perform another groupby-aggregation on the same filtered dataframe
that requires &amp;ldquo;y&amp;rdquo; column as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r1 &lt;span style="color:#f92672">=&lt;/span> f_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(r1)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r2 &lt;span style="color:#f92672">=&lt;/span> f_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#75715e"># newly added groupby-sum&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(r2)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Since FireDucks performs lazy execution,&lt;/p>
&lt;ol>
&lt;li>&lt;strong>will it process two expensive calls as follows&lt;/strong>?&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>r1 &lt;span style="color:#f92672">=&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;[&amp;#34;&lt;/span>x&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>z&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>a&lt;span style="color:#e6db74">&amp;#34;])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r2 &lt;span style="color:#f92672">=&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;[&amp;#34;&lt;/span>y&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>z&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>a&lt;span style="color:#e6db74">&amp;#34;])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>&lt;strong>Or, will it keep the intermediate filtered result (f_df) alive when processing &lt;code>r1&lt;/code>&lt;/strong>? since it will be used later in the given program when processing &lt;code>r2&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>ðŸ‘‰ &lt;strong>The answer is (2)&lt;/strong>. It will effectively keep the intermediate results alive that are to be required at some later stage.&lt;/p>
&lt;p>Let&amp;rsquo;s look into the generated IR of the before and after optimization for the modified program:&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-05 13:26:41.691496: 959435 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [])
%t1 = project(%t0, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %t4, %v6)
}
2024-12-05 13:26:41.692423: 959435 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [&amp;#39;z&amp;#39;, &amp;#39;x&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;y&amp;#39;]) &amp;lt;- this time it also loads &amp;#34;y&amp;#34; column (as needed for r2)
%t1 = project(%t0, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %t4, %v6) &amp;lt;- this time it also returns filtered dataframe (%t4)
}
2024-12-05 13:26:41.706225: 959435 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main(%arg0: !table) { later use.
%t1 = groupby_select_agg(%arg0, [&amp;#39;y&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v2 = get_shape(%t1)
return(%t1, %v2)
}
2024-12-05 13:26:41.706721: 959435 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main(%arg0: !table) {
%t1 = groupby_select_agg(%arg0, [&amp;#39;y&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v2 = get_shape(%t1)
return(%t1, %v2)
}
&lt;/code>&lt;/pre>&lt;p>The first &amp;ldquo;Optimized IR&amp;rdquo; is generated when processing &lt;code>r1&lt;/code>.
This time the compiler identifies the &amp;ldquo;y&amp;rdquo; column and the filtered dataframe (f_df) will be used at later stage when computing &lt;code>r2&lt;/code>.
Hence it will also load the &amp;ldquo;y&amp;rdquo; column and keep the intermediate filtered dataframe alive (in other word, cache it) by returning
it (%t4) along with the result of &lt;code>r1&lt;/code> (%t5) to avoid further processing at later use.&lt;/p>
&lt;p>ðŸ‘‰If you carefully notice the previous IR returned only &lt;code>(%t5, %v6)&lt;/code>, when there was no computing related to &lt;code>r2&lt;/code> in the input program.&lt;/p>
&lt;p>The second &amp;ldquo;Optimized IR&amp;rdquo; is generated when processing &lt;code>r2&lt;/code>.
The input &lt;code>%arg0&lt;/code> is the filtered dataframe (%t4) that the compiler kept alive.
Hence only groupby-sum is performed when processing &lt;code>r2&lt;/code>.&lt;/p>
&lt;h2 id="how-to-profile">How to profile?&lt;/h2>
&lt;p>You can also check kernel-wise execution time, number of calls etc. by executing the program as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ FIREDUCKS_FLAGS=&amp;#34;--trace=3 --trace-file=-&amp;#34; python -mfireducks.pandas sample.py
&lt;/code>&lt;/pre>&lt;p>It will produce some profiling output as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-duration" data-lang="duration">== kernel ==
fireducks.gt.vector.scalar 0.004 8.26% 1
fireducks.read_parquet 0.003 6.02% 1
fireducks.groupby_select_agg 0.002 3.06% 2
fireducks.to_pandas.frame.metadata 0.001 1.89% 2
fireducks.filter 0.001 1.34% 1
fireducks.project 0.000 0.03% 2
&lt;/code>&lt;/pre>&lt;p>It can clearly be seen that the method related to read_parquet, filter etc. is called only once.
In order to produce the similar profiling on Jupyter notebook, you can use the cell magic: &lt;code>%%fireducks.profile&lt;/code>.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping-up&lt;/h2>
&lt;p>Thank you for your time in reading this article.
In case you have any queries or have an issue to report, please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Import hooks: how to use FireDucks without modifying your programs</title><link>https://fireducks-dev.github.io/posts/importhook/</link><pubDate>Wed, 15 Nov 2023 09:35:10 +0900</pubDate><guid>https://fireducks-dev.github.io/posts/importhook/</guid><description>
&lt;p>This is Osamu Daido from the FireDucks development team.
In today&amp;rsquo;s developers&amp;rsquo; blog, I would like to introduce the import hook feature of FireDucks.
This feature enables you to use FireDucks without modifying your existing programs at all.&lt;/p>
&lt;p>I&amp;rsquo;ll explain how to use hooks when running Python files on the command line and how to enable hooks in IPython or Jupyter Notebook.&lt;/p>
&lt;h1 id="what-is-an-import-hook">What is an import hook?&lt;/h1>
&lt;p>FireDucks behaves in the same way as the original pandas, so it&amp;rsquo;s easy to get started by simply modifying an import statement as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># import pandas as pd&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, even if it&amp;rsquo;s just a single line, finding and replacing import statements with FireDucks in your programs which use pandas may be annoying.
Moreover, if you want to use FireDucks in a third-party library that works with pandas, it&amp;rsquo;s not practical to modify all import statements in that library.&lt;/p>
&lt;p>As mentioned in &lt;a href="https://fireducks-dev.github.io/docs/get-started/#import-hook">Get Started&lt;/a>, FireDucks has a utility called an import hook.
Please specify the following options for the Python interpreter when you run &lt;code>your_script.py&lt;/code> on the command line.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>python3 -m fireducks.imhook your_script.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With this feature, &lt;code>fireducks.pandas&lt;/code> is imported instead of &lt;code>pandas&lt;/code> when the Python interpreter attempts to import &lt;code>pandas&lt;/code>.
Keep in mind that this does not edit the source code of &lt;code>your_script.py&lt;/code>, but rather dynamically hacks the import process while executing the program.&lt;/p>
&lt;h2 id="example-of-an-import-hook">Example of an import hook&lt;/h2>
&lt;p>Let&amp;rsquo;s see it in action with a simple Python script, &lt;code>print_classname.py&lt;/code>, as shown below.
This script outputs the repr string of the DataFrame class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(pd&lt;span style="color:#f92672">.&lt;/span>DataFrame)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you run it normally, the output is as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ python3 print_classname.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;class &lt;span style="color:#e6db74">&amp;#39;pandas.core.frame.DataFrame&amp;#39;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With the import hook, the output becomes different from the previous one, as follows! ðŸ¥³&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ python3 -m fireducks.imhook print_classname.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;class &lt;span style="color:#e6db74">&amp;#39;fireducks.pandas.frame.DataFrame&amp;#39;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So, yes, you can use dataframes of FireDucks even though you haven&amp;rsquo;t edited the source code.&lt;/p>
&lt;h2 id="limitations">Limitations&lt;/h2>
&lt;h3 id="no-shebang-support">No shebang support&lt;/h3>
&lt;p>Currently, execution by shebang (&lt;code>#!...&lt;/code>) is not supported.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#!/usr/bin/python3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(pd&lt;span style="color:#f92672">.&lt;/span>DataFrame)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You cannot enable an import hook, as you cannot specify the &lt;code>-m&lt;/code> option for the Python interpreter (hmm, it&amp;rsquo;s of course).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ chmod +x print_classname_shebang.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ ./print_classname_shebang.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;class &lt;span style="color:#e6db74">&amp;#39;pandas.core.frame.DataFrame&amp;#39;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="no-combination-with-other-executable-modules">No combination with other executable modules&lt;/h3>
&lt;p>The import hook feature cannot be used concurrently with other tools invoked by the &lt;code>-m&lt;/code> option, as only one &lt;code>-m&lt;/code> option can be passed to the Python interpreter.&lt;/p>
&lt;h3 id="no-subprocess-support">No subprocess support&lt;/h3>
&lt;p>If you start a new Python process using the &lt;code>subprocess&lt;/code> module, the import hook settings are not inherited by that subprocess.&lt;/p>
&lt;h1 id="how-to-use-import-hooks-in-jupyter-notebook">How to use import hooks in Jupyter Notebook&lt;/h1>
&lt;p>The import hook feature is also available in Jupyter Notebook.
Currently, however, you cannot specify an option when starting Jupyter, and you must activate a hook explicitly in the first cell of your notebook.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.importhook
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fireducks&lt;span style="color:#f92672">.&lt;/span>importhook&lt;span style="color:#f92672">.&lt;/span>activate_hook(&lt;span style="color:#e6db74">&amp;#34;fireducks.pandas&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;pandas&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There may not be much benefit to using import hooks if you&amp;rsquo;re just using pandas in your own notebook.
On the other hand, import hooks also work with third-party libraries that use pandas, so it&amp;rsquo;s useful if you want to utilize such libraries in your notebook.&lt;/p>
&lt;p>If you want to disable a hook, please call the following function.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>fireducks&lt;span style="color:#f92672">.&lt;/span>importhook&lt;span style="color:#f92672">.&lt;/span>deactivate_hook()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, if you mix dataframes from the original pandas with ones from FireDucks, you will likely encounter errors (probably with complicated and mysterious error messages).
Basically, it is recommended to keep a hook enabled once you enable it.&lt;/p>
&lt;h2 id="how-to-use-import-hooks-with-ipython-cli">How to use import hooks with IPython CLI&lt;/h2>
&lt;p>With IPython, you can enable a hook manually in the same way as in Jupyter Notebook described above.
Another option is to start the IPython CLI as follows (this is an example with bash):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>python3 -m fireducks.imhook &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>which ipython&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Well, it&amp;rsquo;s a bit of an unusual way, but it works!&lt;/p>
&lt;h1 id="wrap-up">Wrap-up&lt;/h1>
&lt;p>FireDucks is still under research and development, so you may face errors and problems if you switch from using pandas to FireDucks.
We have been working on improving features of FireDucks every day since the release of the beta version.
Your feedback, bug reports, and feature requests are welcome!
Please see our &lt;a href="https://fireducks-dev.github.io/docs/help/contact/">contact information&lt;/a> for further details.&lt;/p>
&lt;p>To sum up, I&amp;rsquo;ve shown you how to use FireDucks without modifying your existing programs at all.
If you want to try FireDucks, please refer to &lt;a href="https://fireducks-dev.github.io/docs/get-started/">Get Started&lt;/a> and &lt;a href="https://fireducks-dev.github.io/docs/user-guide/01-intro/">User Guide&lt;/a> documents. For information on how much faster FireDucks is compared to pandas, please check out our &lt;a href="https://fireducks-dev.github.io/docs/benchmarks/">Benchmarks&lt;/a>.&lt;/p>
&lt;p>May the Acceleration be with you,&lt;!-- raw HTML omitted -->
FireDucks Development Team&lt;/p></description></item><item><title>Posts: Using Python's fast data frame library FireDucks</title><link>https://fireducks-dev.github.io/posts/nes_taxi/</link><pubDate>Mon, 23 Oct 2023 08:47:36 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/nes_taxi/</guid><description>
&lt;p>pandas is a library that provides functions to support data analysis in the Python programming language.
NEC Research Laboratories has developed a library called FireDucks, a faster version of pandas.&lt;/p>
&lt;h2 id="data-preparation">Data Preparation&lt;/h2>
&lt;p>The analysis is performed on the data of passenger history of cabs in New York City.
The source of the data is as follows:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>To analyze large data sets, we downloaded and merged the &amp;ldquo;Yellow Taxi Trip Records&amp;rdquo; data from January 2022 to June 2023 from the above link.
The data is provided in parquet format, but I converted it to csv format for testing.
A script for preparing the data is included for reference.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dir &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;xxx&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_list &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> year &lt;span style="color:#f92672">in&lt;/span> [&lt;span style="color:#ae81ff">2022&lt;/span>, &lt;span style="color:#ae81ff">2023&lt;/span>]: &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">12&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">12&lt;/span>): &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">=&lt;/span> str(i&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>zfill(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>month &lt;span style="color:#f92672">=&lt;/span> str(i&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>zfill(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fn &lt;span style="color:#f92672">=&lt;/span> f &lt;span style="color:#e6db74">&amp;#34;yellow_tripdata_&lt;/span>&lt;span style="color:#e6db74">{year}&lt;/span>&lt;span style="color:#e6db74">-&lt;/span>&lt;span style="color:#e6db74">{month}&lt;/span>&lt;span style="color:#e6db74">.parquet&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>file &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(dir, fn)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>exists(file):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(fn)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_list&lt;span style="color:#f92672">.&lt;/span>append(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>all_df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>concat(df_list)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>all_df&lt;span style="color:#f92672">.&lt;/span>to_csv(&lt;span style="color:#e6db74">&amp;#34;taxi_all.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The contents of the data contains the following values (some columns are excerpts).&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Column name&lt;/th>
&lt;th>&lt;!-- raw HTML omitted -->Data type&lt;!-- raw HTML omitted -->&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>passenger_count&lt;/code>&lt;/td>
&lt;td>int&lt;/td>
&lt;td>The number of passengers&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>pu_location_Id&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The TLC cab zone where the cab meter started working.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>do_location_Id&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The TLC cab zone where the cab meter was deactivated.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>tpep_dropoff_datetime&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The date and time the meter was deactivated.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>tpep_pickupdate_time&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The date and time when the meter started to work.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>trip_distance&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>The trip distance (in miles) reported by the cab meter.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>total_amount&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>The total amount of money charged to the passenger, not including the cash tip.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>extra&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>Other surcharges and additional charges. Currently, this includes only the $0.50 and $1 rush hour and nighttime fares.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>fare_amount&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>Time-and-distance combined fare calculated by the meter.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="actual-preprocessing">Actual preprocessing&lt;/h2>
&lt;p>A series of preprocessing calculations, such as type conversion, column addition, and outlier deletion, which are often used in data analysis, are performed on the prepared data.&lt;/p>
&lt;p>First, prepare a wrapper for speed measurement.
&lt;code>_evaluate()&lt;/code> is described later.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> time &lt;span style="color:#f92672">import&lt;/span> time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> functools &lt;span style="color:#f92672">import&lt;/span> wraps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">timer&lt;/span>(func):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@wraps&lt;/span>(func)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">wp&lt;/span>(&lt;span style="color:#f92672">*&lt;/span>args, &lt;span style="color:#f92672">**&lt;/span>kargs):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t &lt;span style="color:#f92672">=&lt;/span> time()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ret &lt;span style="color:#f92672">=&lt;/span> func(&lt;span style="color:#f92672">*&lt;/span>args, &lt;span style="color:#f92672">**&lt;/span>kargs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>func&lt;span style="color:#f92672">.&lt;/span>__name__&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> : &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>(time() &lt;span style="color:#f92672">-&lt;/span> t)&lt;span style="color:#e6db74">:&lt;/span>&lt;span style="color:#e6db74">.5g&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> [sec]&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> ret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> wp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">evaluate&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> hasattr(df, &lt;span style="color:#e6db74">&amp;#34;_evaluate&amp;#34;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>_evaluate()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="loading-data">Loading data&lt;/h3>
&lt;p>First, read the data.
Import pandas and then use &lt;code>read_csv&lt;/code> to read the data.
Define a function, and call it later to measure the data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">file_read&lt;/span>(fn, args&lt;span style="color:#f92672">=&lt;/span>{}):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(fn, &lt;span style="color:#f92672">**&lt;/span>args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(df&lt;span style="color:#f92672">.&lt;/span>shape)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="data-processing">Data processing&lt;/h3>
&lt;p>Remove data with missing values.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">drop_na&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>dropna(how&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;all&amp;#34;&lt;/span>, inplace&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The date and time of boarding and alighting are read as strings, so they should be converted to dates.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">txt_to_date&lt;/span>(df, low):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[low] &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>to_datetime(df[low])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s look at the distribution grouped by the number of boardings (print is not included in the performance evaluation, so it is omitted).
We see that there are data with zero riders, so we remove them.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># At least one person on the train&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_passenger_c&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;passenger_count&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[df[&lt;span style="color:#e6db74">&amp;#34;passenger_count&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Extract the year, month, day, and hour information from the ride date data and add columns.
The distribution of the year and month of the ride contains incorrect values, so we remove them.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># correct ride year/month&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_pu_date&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;year&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>year
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;month&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>month
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;date&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>day
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;hour&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>hour
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;year&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#39;year&amp;#39;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">2022&lt;/span>) &lt;span style="color:#f92672">|&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#39;year&amp;#39;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">2023&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;month&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#39;month&amp;#39;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;month&amp;#39;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;year&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;month&amp;#34;&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Convert the difference between the disembarkation time and the ride time to minutes and add a column.
Remove non-positive or too long ride times.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># realistic ride time in minutes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_ride_time&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#34;ride_time&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;tpep_dropoff_datetime&amp;#34;&lt;/span>] &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;tpep_pickup_datetime&amp;#34;&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>seconds &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">60&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;ride_time&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;ride_time&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">180&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Remove non-negative or too large values for ride distance and fare.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># realistic distances&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_trip_distance&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;trip_distance&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;trip_distance&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">250&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Realistic fares&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_total_amount&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;total_amount&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;total_amount&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">1000&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Calculate the latitude and longitude from the IDs of the boarding and alighting points.
The relationship between the ID and the point can be checked as follows:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv">https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>The columns are added by merging the conversion table created based on the latitude and longitude calculated from:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip">https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Remove data outside New York City from the latitude and longitude information.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Find latitude and longitude from IDs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">add_coordinate&lt;/span>(df, ID_df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>merge(ID_df&lt;span style="color:#f92672">.&lt;/span>rename(columns&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;longitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;start_lon&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;latitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;start_lat&amp;#34;&lt;/span>}),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;PULocationID&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, how&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;left&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>drop(&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>merge(ID_df&lt;span style="color:#f92672">.&lt;/span>rename(columns&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;longitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;end_lon&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;latitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;end_lat&amp;#34;&lt;/span>}),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;DOLocationID&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, how&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;left&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>drop(&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Check if it is in NY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">in_NY&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;start_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">71.47&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;start_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">79.45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;start_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">40.29&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;start_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;end_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">71.47&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;end_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">79.45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;end_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">40.29&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;end_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_in_NY&lt;/span>(df, ID_df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> add_coordinate(df, ID_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> in_NY(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As described above, a series of processes are prepared to read data, perform type conversion, add columns, and remove outlier values.&lt;/p>
&lt;ol>
&lt;li>Read the file&lt;/li>
&lt;li>Convert date data from string to date data&lt;/li>
&lt;li>Preprocessing&lt;/li>
&lt;li>Remove missing values&lt;/li>
&lt;li>Check the number of passengers&lt;/li>
&lt;li>Check distribution by groupby&lt;/li>
&lt;li>Select at least 1 passenger&lt;/li>
&lt;li>Check the time of boarding&lt;/li>
&lt;li>Tet the year, month, date and time from the date data and add a column&lt;/li>
&lt;li>Group by year and check -&amp;gt; Select only the relevant year&lt;/li>
&lt;li>Group by month and check -&amp;gt; select only Jan-Dec&lt;/li>
&lt;li>Group by year and month and check the distribution&lt;/li>
&lt;li>Check the boarding time&lt;/li>
&lt;li>Take the difference between the time of disembarkation and the time of embarkation, convert to minutes, and add a column (&lt;code>dt.total_second&lt;/code> is not supported by FireDucks)&lt;/li>
&lt;li>Select realistic ride time data&lt;/li>
&lt;li>Check the ride distance&lt;/li>
&lt;li>Select realistic distance data&lt;/li>
&lt;li>Check fare&lt;/li>
&lt;li>Select realistic fare data&lt;/li>
&lt;li>Select NY City data&lt;/li>
&lt;li>Merge the passenger ID with the latitude and longitude table&lt;/li>
&lt;li>Select the data where the longitude and latitude of the boarding and alighting is in NY city&lt;/li>
&lt;/ol>
&lt;h2 id="execution-time-in-pandas">Execution time in pandas&lt;/h2>
&lt;p>First, let&amp;rsquo;s check the execution time on pandas.
A 24-core Xeon server (Intel(R) Xeon(R) Gold 6226 CPU x 2, 256GB main memory) was used for the measurement.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data_path &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;data_sets&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fn &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(data_path, &lt;span style="color:#e6db74">&amp;#34;taxi_all.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ID_file &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(data_path, &lt;span style="color:#e6db74">&amp;#34;ID_to_coordinate.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>need_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;tpep_dropoff_datetime&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;passenger_count&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;trip_distance&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;PULocationID&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;DOLocationID&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;total_amount&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;improvement_surcharge&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;extra&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;fare_amount&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;RatecodeID&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">Preprocessing&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> file_read(fn, {&lt;span style="color:#e6db74">&amp;#34;usecols&amp;#34;&lt;/span>: need_cols})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ID_df &lt;span style="color:#f92672">=&lt;/span> file_read(ID_file)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> txt_to_date(df, &lt;span style="color:#e6db74">&amp;#34;tpep_pickup_datetime&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> txt_to_date(df, &lt;span style="color:#e6db74">&amp;#34;tpep_dropoff_datetime&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> drop_na(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_passenger_c(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_pu_date(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_ride_time(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_trip_distance(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_total_amount(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_in_NY(df, ID_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> Preprocessing()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now, the execution time in pandas is as shown in the table below.
The two &lt;code>file_read&lt;/code> files are due to reading the taxi data as well as the location data for merging, and the &lt;code>txt_to_date&lt;/code> file is due to converting the ride time and the drop-off time.
The execution time shows that it took more than one minute to read the file.
In addition, &lt;code>check_pu_date&lt;/code> and &lt;code>add_coordinate&lt;/code>, which include adding columns and merge processing, take more than 30 seconds, and the implemented preprocessing takes 186 seconds to complete.&lt;/p>
&lt;h2 id="execution-time-with-fireducks">Execution time with FireDucks&lt;/h2>
&lt;p>Measure the execution time when using FireDucks with the imported library replaced by pandas.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>pip install fireducks
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The above scripts for pandas preprocessing can be used as-is by importing FireDucks, since FireDucks is compatible with pandas.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that FireDucks does not immediately execute methods when they are called.
Therefore, it is necessary to run &lt;code>_evaluate()&lt;/code> to measure the execution time of each method.&lt;/p>
&lt;p>The following table compares the execution time of FireDucks with that of pandas after importing FireDucks and performing the same preprocessing calculations.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Function&lt;/th>
&lt;th style="text-align:right">pandas [sec]&lt;/th>
&lt;th style="text-align:right">FireDucks [sec]&lt;/th>
&lt;th style="text-align:right">Speed-up ratio&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">&lt;code>file_read&lt;/code>&lt;/td>
&lt;td style="text-align:right">72.19&lt;/td>
&lt;td style="text-align:right">3.52&lt;/td>
&lt;td style="text-align:right">20.49&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>file_read&lt;/code>&lt;/td>
&lt;td style="text-align:right">0.003&lt;/td>
&lt;td style="text-align:right">0.01&lt;/td>
&lt;td style="text-align:right">0.38&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>txt_to_date&lt;/code>&lt;/td>
&lt;td style="text-align:right">9.07&lt;/td>
&lt;td style="text-align:right">19.10&lt;/td>
&lt;td style="text-align:right">0.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>txt_to_date&lt;/code>&lt;/td>
&lt;td style="text-align:right">8.57&lt;/td>
&lt;td style="text-align:right">20.57&lt;/td>
&lt;td style="text-align:right">0.42&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>drop_na&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.13&lt;/td>
&lt;td style="text-align:right">0.70&lt;/td>
&lt;td style="text-align:right">4.47&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_passenger_c&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.21&lt;/td>
&lt;td style="text-align:right">1.80&lt;/td>
&lt;td style="text-align:right">1.79&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_pu_date&lt;/code>&lt;/td>
&lt;td style="text-align:right">27.37&lt;/td>
&lt;td style="text-align:right">0.99&lt;/td>
&lt;td style="text-align:right">27.64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_ride_time&lt;/code>&lt;/td>
&lt;td style="text-align:right">7.02&lt;/td>
&lt;td style="text-align:right">2.00&lt;/td>
&lt;td style="text-align:right">3.51&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_trip_distance&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.24&lt;/td>
&lt;td style="text-align:right">0.91&lt;/td>
&lt;td style="text-align:right">3.55&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_total_amount&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.11&lt;/td>
&lt;td style="text-align:right">0.93&lt;/td>
&lt;td style="text-align:right">3.59&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_total_amount&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.11&lt;/td>
&lt;td style="text-align:right">0.93&lt;/td>
&lt;td style="text-align:right">3.59&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>in_NY&lt;/code>&lt;/td>
&lt;td style="text-align:right">20.75&lt;/td>
&lt;td style="text-align:right">2.71&lt;/td>
&lt;td style="text-align:right">7.65&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>Preprocessing&lt;/code>&lt;/td>
&lt;td style="text-align:right">186.02&lt;/td>
&lt;td style="text-align:right">54.92&lt;/td>
&lt;td style="text-align:right">3.39&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The &lt;code>file_read&lt;/code> process took more than 70 seconds to complete in pandas, but it took about 3.5 seconds, which is more than 20 times faster.
Other time-consuming processes (&lt;code>check_pu_date&lt;/code>, &lt;code>add_coordinate&lt;/code>) were also significantly reduced.&lt;/p>
&lt;p>The computation time for &lt;code>txt_to_date&lt;/code> was increased by using FireDucks.
This is because the &lt;code>to_datetime()&lt;/code> function is not supported by FireDucks at the time of writing.
However, even when a function like &lt;code>to_datetime()&lt;/code> is called that does not support acceleration, FireDucks does not return an error because it performs the calculation by calling a pandas function.&lt;/p>
&lt;p>The total computation time for the preprocessing calculations in this article was 55 seconds with FireDucks, compared to 186 seconds with pandas, which is about 3.4 times faster.
Of the 55 seconds, about 40 seconds was for processing that had not yet been accelerated, and further acceleration is expected in the future.&lt;/p></description></item></channel></rss>