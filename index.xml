<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FireDucks â€“ FireDucks</title><link>https://fireducks-dev.github.io/</link><description>Recent content on FireDucks</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 18 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://fireducks-dev.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Posts: Exploring performance benefits of FireDucks over cuDF</title><link>https://fireducks-dev.github.io/posts/cudf_vs_fireducks/</link><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/cudf_vs_fireducks/</guid><description>
&lt;p>&lt;a href="https://www.anaconda.com/resources/whitepapers/state-of-data-science-2020">Research&lt;/a> says that Data
scientists spend about 45% of their time on data preparation tasks, including loading (19%) and
cleaning (26%) the data. &lt;a href="https://pandas.pydata.org/">Pandas&lt;/a> is one of the most popular python
libraries for tabular data processing because of its diverse utilities and large community support.
However, due to its performance issue with the large-scale data processing, there is a strong need
for high-performance data frame libraries for the community. Although there are many alternatives
available at this moment, due to compatibility issue with pandas some of those either compel
a user to learn completely new APIs (incurring migration cost) or to switch to a more
efficient computational systems, like GPU etc. (incurring hardware cost).&lt;/p>
&lt;p>In this article we will discuss two high-performance pandas alternatives that can help a pandas programmer
to smoothly migrate an existing application while offering promising speed. They are:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.rapids.ai/api/cudf/stable">cuDF&lt;/a>: GPU accelerated DataFrame library with highly compatible pandas APIs&lt;/li>
&lt;li>&lt;a href="https://fireducks-dev.github.io/">FireDucks&lt;/a>: A compiler accelerated DataFrame library with highly compatible pandas APIs for speedup even on CPU only systems&lt;/li>
&lt;/ul>
&lt;h2 id="fireducks-vs-cudf">FireDucks vs cuDF&lt;/h2>
&lt;p>Both FireDucks and cuDF offer the following:&lt;/p>
&lt;ul>
&lt;li>ensure zero code changes with promising speedup&lt;/li>
&lt;li>highly-compatible pandas APIs for a seamless integration with an existing pandas application&lt;/li>
&lt;li>import-hook feature for a seamless integration with third party library using pandas&lt;/li>
&lt;li>parallel implementation of the kernel algorithms (like join, groupby etc.) to leverage all the available cores&lt;/li>
&lt;/ul>
&lt;p>However, the key differences are:&lt;/p>
&lt;ul>
&lt;li>FireDucks can speedup an existing pandas application even on CPU only systems, whereas
one needs to prepare a GPU environment before trying cuDF.&lt;/li>
&lt;li>FireDucks supports a lazy execution model aiming for JIT query optimization, whereas
cuDF supports only an eager execution model (similar to pandas). Therefore, if the program
is not written carefully with the right data-flow, cuDF might suffer performance issue while
FireDucks can outperform cuDF even on CPU only systems due to its efficient query optimization.&lt;/li>
&lt;/ul>
&lt;h2 id="evaluation">Evaluation&lt;/h2>
&lt;h3 id="multi-threaded-benefit">Multi-threaded Benefit&lt;/h3>
&lt;p>Here is an &lt;a href="https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes">article&lt;/a>
explaining the key features of cuDF along with its performance. We have used the notebook provided in that article
to evaluate &lt;code>pandas&lt;/code>, &lt;code>fireducks.pandas &lt;/code>and &lt;code>cudf.pandas&lt;/code> respectively.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/pandas_nyc_demo.ipynb">test drive for native pandas&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/fireducks_pandas_nyc_demo.ipynb">test drive for fireducks.pandas&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/cudf_pandas_nyc_demo.ipynb">test drive for cudf.pandas&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Here are some details related to the evaluation environment:&lt;/p>
&lt;ul>
&lt;li>CPU model: Intel(R) Xeon(R) Gold 6126 CPU @ 2.60GHz&lt;/li>
&lt;li>CPU cores: 48&lt;/li>
&lt;li>main memory: 256gb&lt;/li>
&lt;li>GPU model: NVIDIA Tesla V100&lt;/li>
&lt;/ul>
&lt;p>It can be noted that, by simply enabling the extension &lt;code>%load_ext fireducks.pandas&lt;/code>
or &lt;code>%load_ext cudf.pandas&lt;/code>, one can successfully speedup the operations in an
existing pandas notebook using FireDucks or cuDF. For this experiment, we have
disabled FireDucks lazy-execution mode as follows for a fair comparison among these 3 libraries:&lt;/p>
&lt;pre tabindex="0">&lt;code>from fireducks.core import get_fireducks_options
get_fireducks_options().set_benchmark_mode(True)
&lt;/code>&lt;/pre>&lt;p>The table below summarizes the query wise execution time for these libraries:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;/th>
&lt;th style="text-align:right">pandas (sec)&lt;/th>
&lt;th style="text-align:right">FireDucks (sec)&lt;/th>
&lt;th style="text-align:right">cuDF (sec)&lt;/th>
&lt;th style="text-align:left">speedup_from_FireDucks_over_pandas&lt;/th>
&lt;th style="text-align:left">speedup_from_cuDF_over_pandas&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">data_loading&lt;/td>
&lt;td style="text-align:right">1.85&lt;/td>
&lt;td style="text-align:right">0.53&lt;/td>
&lt;td style="text-align:right">0.42&lt;/td>
&lt;td style="text-align:left">3.49x&lt;/td>
&lt;td style="text-align:left">4.4x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">query_1&lt;/td>
&lt;td style="text-align:right">2.4&lt;/td>
&lt;td style="text-align:right">0.08&lt;/td>
&lt;td style="text-align:right">0.35&lt;/td>
&lt;td style="text-align:left">30.0x&lt;/td>
&lt;td style="text-align:left">6.86x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">query_2&lt;/td>
&lt;td style="text-align:right">0.75&lt;/td>
&lt;td style="text-align:right">0.03&lt;/td>
&lt;td style="text-align:right">0.01&lt;/td>
&lt;td style="text-align:left">25.0x&lt;/td>
&lt;td style="text-align:left">75.0x&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">query_3&lt;/td>
&lt;td style="text-align:right">6.38&lt;/td>
&lt;td style="text-align:right">0.15&lt;/td>
&lt;td style="text-align:right">0.08&lt;/td>
&lt;td style="text-align:left">42.53x&lt;/td>
&lt;td style="text-align:left">79.75x&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Due to difference in the underlined hardware, cuDF operations (that worked on GPU) definitely performed much better
when compared to pandas, but the performance gain from FireDucks over pandas even on CPU is quite promising.
In fact, the &lt;strong>overall speedup is ~13x (11.37s -&amp;gt; 0.87s) when using cuDF,
whereas it is ~14x (11.37s -&amp;gt; 0.79s) when using FireDucks&lt;/strong> for the same pandas program.&lt;/p>
&lt;h3 id="jit-optimization-benefit">JIT Optimization Benefit&lt;/h3>
&lt;p>The above case shows how efficiently FireDucks can leverage the available cpu cores to speedup an existing pandas program.&lt;/p>
&lt;p>Let&amp;rsquo;s now understand how FireDucks JIT query optimization can make it even better!!&lt;/p>
&lt;p>We have used a &lt;a href="https://www.tpc.org/TPC_Documents_Current_Versions/pdf/TPC-H_v3.0.1.pdf#page=33">sample query&lt;/a>
from the &lt;a href="https://www.tpc.org/tpch/">TPC-H benchmark&lt;/a> that deals with a couple of tables of different dimensions
for a scale-factor 10.&lt;/p>
&lt;p>ðŸ‘‰ &lt;strong>Purpose: To retrieve the 10 unshipped orders with the highest value.&lt;/strong>&lt;/p>
&lt;p>Here is the pandas implementation for this query:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;customer.parquet&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;orders.parquet&amp;#34;&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;lineitem.parquet&amp;#34;&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;BUILDING&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>pipe(&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[df[&lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>assign(revenue&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[&lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>], as_index&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>agg({&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;sum&amp;#34;&lt;/span>})[[&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values([&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>], ascending&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#66d9ef">True&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>reset_index(drop&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>to_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;q3_result.parquet&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This time we have used the default lazy-execution mode in FireDucks to demonstrate its true strength.
The execution time of this query for each DataFrame library is as follows:&lt;/p>
&lt;ul>
&lt;li>native pandas: 215.47 sec&lt;/li>
&lt;li>fireducks.pandas: 1.69 sec&lt;/li>
&lt;li>cudf.pandas: 26.79 sec&lt;/li>
&lt;/ul>
&lt;p>ðŸ‘‰ &lt;strong>FireDucks outperformed pandas upto 127x (215.47s -&amp;gt; 1.69s) and cuDF upto 15x (215.47s -&amp;gt; 26.79s) for the avove query.&lt;/strong>&lt;/p>
&lt;p>This speedup from FireDucks is due to the efficient query planning and optimization that
is performed by the internal JIT compiler. Instead of executing the input query as it is,
it attempts to optimize the same by reducing the scope of the input data for the time
consuming join, groupby etc. operations majorly using the following steps:&lt;/p>
&lt;ul>
&lt;li>loading only required columns from the input parquet files to reduce the data horizontally&lt;/li>
&lt;li>performing early filtration to reduce the data vertically&lt;/li>
&lt;/ul>
&lt;p>The optimized implementation for the same query could be as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>req_customer_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># selecting (2/8) columns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>req_lineitem_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># selecting (4/16) columns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>req_orders_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># selecting (4/9) columns&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>customer &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;customer.parquet&amp;#34;&lt;/span>), columns &lt;span style="color:#f92672">=&lt;/span> req_customer_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lineitem &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;lineitem.parquet&amp;#34;&lt;/span>), columns &lt;span style="color:#f92672">=&lt;/span> req_lineitem_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>orders &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;orders.parquet&amp;#34;&lt;/span>), columns &lt;span style="color:#f92672">=&lt;/span> req_orders_cols)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œcustomerâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_cust &lt;span style="color:#f92672">=&lt;/span> customer[customer[&lt;span style="color:#e6db74">&amp;#34;c_mktsegment&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#e6db74">&amp;#34;BUILDING&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œordersâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_ord &lt;span style="color:#f92672">=&lt;/span> orders[orders[&lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># advanced-filter: to reduce scope of â€œlineitemâ€ table to be processed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_litem &lt;span style="color:#f92672">=&lt;/span> lineitem[lineitem[&lt;span style="color:#e6db74">&amp;#34;l_shipdate&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> datetime(&lt;span style="color:#ae81ff">1995&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">15&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f_cust&lt;span style="color:#f92672">.&lt;/span>merge(f_ord, left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;c_custkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_custkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>merge(f_litem, left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;o_orderkey&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>assign(revenue&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">lambda&lt;/span> df: df[&lt;span style="color:#e6db74">&amp;#34;l_extendedprice&amp;#34;&lt;/span>] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;l_discount&amp;#34;&lt;/span>]))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>], as_index&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>agg({&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;sum&amp;#34;&lt;/span>})[[&lt;span style="color:#e6db74">&amp;#34;l_orderkey&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_shippriority&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>sort_values([&lt;span style="color:#e6db74">&amp;#34;revenue&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;o_orderdate&amp;#34;&lt;/span>], ascending&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#66d9ef">False&lt;/span>, &lt;span style="color:#66d9ef">True&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>reset_index(drop&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>head(&lt;span style="color:#ae81ff">10&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>to_parquet(os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(datapath, &lt;span style="color:#e6db74">&amp;#34;opt_q3_result.parquet&amp;#34;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The execution time of this optimized implementation for each DataFrame library is as follows:&lt;/p>
&lt;ul>
&lt;li>native pandas: 11.13 sec&lt;/li>
&lt;li>fireducks.pandas: 1.72 sec&lt;/li>
&lt;li>cudf.pandas: 0.76 sec&lt;/li>
&lt;/ul>
&lt;p>It can be noted that:&lt;/p>
&lt;ul>
&lt;li>the native pandas could itself be optimized upto &lt;strong>~19x (215.47 sec -&amp;gt; 11.13 sec)&lt;/strong>&lt;/li>
&lt;li>there is no visible change in the execution time of FireDucks (&lt;strong>since the compiler does the same optimization automatically in the earlier case&lt;/strong>)&lt;/li>
&lt;li>the cudf.pandas could be optimized upto &lt;strong>~35x (26.79 sec -&amp;gt; 0.76 sec)&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>Most importantly there is no impact in the final result due to the optimization performed.
You can reproduce the same using this &lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/tpch-query3-pandas-fireducks-cudf.ipynb">notebook&lt;/a> at your end.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping up&lt;/h2>
&lt;p>Thank you for your time in reading this article. We have discussed performance benefit of FireDucks
over cuDF. While cuDF shows significant speedup without modifying an existing pandas program,
its performance relies on the underlined GPU specification and how well the program is written, whereas
FireDucks can optimize an existing pandas program efficiently like an expert programmer and
execute the same without any extra overhead, that too on CPU only systems.&lt;/p>
&lt;p>Being said that, &lt;strong>a GPU version of FireDucks is under dvelopment&lt;/strong>. It internally uses &lt;code>cuDF.pandas&lt;/code>
for the kernel operations (like groupby, join etc.) while adding the JIT optimization for further
acceleration as explained in this article. We will be talking about the GPU version of FireDucks
in details in some other article.&lt;/p>
&lt;p>We look forward your constant feedback to make FireDucks even better.
Please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</title><link>https://fireducks-dev.github.io/posts/lazy_execution_offering_part1/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/lazy_execution_offering_part1/</guid><description>
&lt;p>The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas.
To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).&lt;/p>
&lt;p>Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?
For example, let&amp;rsquo;s consider the below data is stored in a parquet file, named sample_data.parquet (or in a csv file, named sample_data.csv):&lt;/p>
&lt;pre tabindex="0">&lt;code> a b c x y z
0 1 0.1 1 0 t1 10
1 2 0.2 4 1 t2 20
2 3 0.3 9 1 t3 30
3 4 0.4 16 0 t1 40
4 5 0.5 25 1 t2 50
5 6 0.6 36 1 t1 60
6 7 0.7 49 0 t2 70
7 8 0.8 64 1 t3 80
&lt;/code>&lt;/pre>&lt;p>And you want to perform sum of &amp;ldquo;c&amp;rdquo; column, when the value of &amp;ldquo;x&amp;rdquo; column is 1. You may simply write the program as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res &lt;span style="color:#f92672">=&lt;/span> df[df[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#75715e"># filter data based on condition and calculate sum of &amp;#34;c&amp;#34; column from filtered frame&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print (res)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the problem may occur when the parquet file is too large to fit in your system memory, although you are interested only a part of it (column &amp;ldquo;x&amp;rdquo; and &amp;ldquo;c&amp;rdquo;).
Thankfully, read_parquet() method has a parameter named &lt;code>columns&lt;/code> and you can specify the target columns to be loaded from the input parquet file:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns &lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>res &lt;span style="color:#f92672">=&lt;/span> df[df[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#75715e"># filter data based on condition and calculate sum of &amp;#34;c&amp;#34; column from filtered frame&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print (res)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Similarly, read_csv() has a parameter, named &lt;code>usecols&lt;/code> that can be specified when loading only target columns from a CSV file.&lt;/p>
&lt;h2 id="fireducks-offerings">FireDucks Offerings&lt;/h2>
&lt;p>Although such parameters can be specified to optimize runtime memory consumption when using pandas, it
might be difficult to know what all columns are required at the very begining of analysing the data.
An automatic optimization for such cases would definitely be useful for users of pandas-like libraries.&lt;/p>
&lt;p>Since &lt;strong>FireDucks 1.1.1&lt;/strong>, we have supported such optimization to be taken care of by its internal JIT compiler.
Even though such parameters are not manually specified, the JIT compiler can inspect the projection targets
on various stages for a given data and it can automatically specify such parameters when generating the optimized code.
Such optimization is commonly known as &lt;strong>pushdown-projection&lt;/strong>. By specifiying the environment variable &lt;strong>FIRE_LOG_LEVEL=3&lt;/strong>,
you can inspect the before and after optimization for the below example.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ cat read_parquet_opt_demo.py
import pandas as pd
df = pd.read_parquet(&amp;#34;sample_data.parquet&amp;#34;)
r1 = df[df[&amp;#34;x&amp;#34;] == 1][&amp;#34;c&amp;#34;].sum()
print(r1)
&lt;/code>&lt;/pre>&lt;p>Execute the program as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ FIRE_LOG_LEVEL=3 python -mfireducks.pandas read_parquet_opt_demo.py
&lt;/code>&lt;/pre>&lt;p>It will then show the intermediate representation (IR) generated for the above program before execution as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-04 13:12:40.618398: 543780 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, []) &amp;lt;- load the input parquet file
%t1 = project(%t0, &amp;#39;x&amp;#39;) &amp;lt;- project &amp;#34;x&amp;#34; column from loaded data (df[&amp;#34;x&amp;#34;])
%t2 = eq.vector.scalar(%t1, 1) &amp;lt;- generate mask with equality check with scalar value, 1 (mask = df[&amp;#34;x&amp;#34;] == 1)
%t3 = filter(%t0, %t2) &amp;lt;- perform filter with computed mask (fdf = df[mask])
%t4 = project(%t3, &amp;#39;c&amp;#39;) &amp;lt;- project &amp;#34;c&amp;#34; column from filtered data (fdf[&amp;#34;c&amp;#34;])
%v5 = aggregate_column.scalar(%t4, &amp;#39;sum&amp;#39;) &amp;lt;- calculate sum of projected column (fdf[&amp;#34;c&amp;#34;].sum())
return(%t4, %v5)
}
&lt;/code>&lt;/pre>&lt;p>And the Optimized IR (target for execution) is as follows.
You can see that it is mostly the same with the optimization added in the instruction for read_parquet()
by automatically specifying the target columns to be loaded for the computation of this specific result (r1).&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-04 13:12:40.619360: 543780 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [&amp;#39;c&amp;#39;, &amp;#39;x&amp;#39;])
%t1 = project(%t0, &amp;#39;x&amp;#39;)
%t2 = eq.vector.scalar(%t1, 1)
%t3 = project(%t0, [&amp;#39;c&amp;#39;])
%t4 = filter(%t3, %t2)
%t5 = project(%t4, &amp;#39;c&amp;#39;)
%v6 = aggregate_column.scalar(%t5, &amp;#39;sum&amp;#39;)
return(%t5, %v6)
}
&lt;/code>&lt;/pre>&lt;p>The python equivalent of the above optimized IR (that will be executed by the FireDucks multi-threaded kernel) is as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns&lt;span style="color:#f92672">=&lt;/span>[&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>]) &lt;span style="color:#75715e"># load only required column for analysis&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t1 &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># projection of target column for equality check&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t2 &lt;span style="color:#f92672">=&lt;/span> (t1 &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t3 &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>] &lt;span style="color:#75715e"># projection of only target column to be filtered&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t4 &lt;span style="color:#f92672">=&lt;/span> t3[t2]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t5 &lt;span style="color:#f92672">=&lt;/span> t4[&lt;span style="color:#e6db74">&amp;#34;c&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>v6 &lt;span style="color:#f92672">=&lt;/span> t5&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>âš ï¸ Please note that the verification through this environment variable setting is mainly for the developers and
we might change the way of representing the IRs in future. As a user, it would be good to inspect the optimization
using this variable at this moment though.&lt;/p>
&lt;h2 id="lets-put-it-into-a-test-drive">Let&amp;rsquo;s put it into a test drive&lt;/h2>
&lt;p>You can refer to the &lt;a href="https://github.com/fireducks-dev/fireducks/blob/main/notebooks/read_parquet_optimization.ipynb">notebook&lt;/a>.
It demonstrates the performance benefit of such optimization on a real dataset.
You may like to experiment around the query to realize the efficiency of FireDucks optimization.
For a sample query, &lt;strong>FireDucks performed 45x faster than Pandas, that too without any modification in the source program and affecting the result&lt;/strong>.&lt;/p>
&lt;p>It also explains some Do&amp;rsquo;s and Don&amp;rsquo;ts when executing a query in notebook-like platform. In case of notebook, the execution takes place cell-by-cell.
Thus when keeping the intermediate results in some cell variables, FireDucks compiler assumes that those might be used at some later stage.
So it will keep all of them alive hindering the optimization. Therefore, it is highly recommended to write a query in chained expression
when using notebook.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping-up&lt;/h2>
&lt;p>Thank you for your time in reading this article.
In case you have any queries or have an issue to report, please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</title><link>https://fireducks-dev.github.io/posts/efficient_caching/</link><pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/efficient_caching/</guid><description>
&lt;p>In the previous &lt;a href="../lazy_execution_offering_part1">article&lt;/a>, we have talked about how FireDucks can take care pushdown-projection related
optimization for read_parquet(), read_csv() etc. In today&amp;rsquo;s article, we will focus on the efficient caching mechanism
by its JIT compiler.&lt;/p>
&lt;p>Let&amp;rsquo;s consider the below sample query for the same data, used in previous article:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r1 &lt;span style="color:#f92672">=&lt;/span> f_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(r1)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When executing the above program (saved as sample.py) as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ FIRE_LOG_LEVEL=3 python -mfireducks.pandas sample.py
&lt;/code>&lt;/pre>&lt;p>You can find the generated IR before and after optimization:&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-05 12:37:21.012481: 958259 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [])
%t1 = project(%t0, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %v6)
}
2024-12-05 12:37:21.013462: 958259 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [&amp;#39;x&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;z&amp;#39;])
%t1 = project(%t0, [&amp;#39;z&amp;#39;, &amp;#39;x&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %v6)
}
&lt;/code>&lt;/pre>&lt;p>It can be noted that the compiler correctly identified the projection targets for read_parquet() as &amp;ldquo;x&amp;rdquo;, &amp;ldquo;a&amp;rdquo;, and &amp;ldquo;z&amp;rdquo; columns.
Although the &amp;ldquo;y&amp;rdquo; column is specified to be projected in the loc indexer, but that column is never used within the
above program. Hence, that is not even loaded during the read_parquet stage.&lt;/p>
&lt;h2 id="could-lazy-execution-be-expensive">Could lazy execution be expensive?&lt;/h2>
&lt;p>Now, the question is what will happen if we want to perform another groupby-aggregation on the same filtered dataframe
that requires &amp;ldquo;y&amp;rdquo; column as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f_df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r1 &lt;span style="color:#f92672">=&lt;/span> f_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(r1)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r2 &lt;span style="color:#f92672">=&lt;/span> f_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum() &lt;span style="color:#75715e"># newly added groupby-sum&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(r2)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Since FireDucks performs lazy execution,&lt;/p>
&lt;ol>
&lt;li>&lt;strong>will it process two expensive calls as follows&lt;/strong>?&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>r1 &lt;span style="color:#f92672">=&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;[&amp;#34;&lt;/span>x&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>z&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>a&lt;span style="color:#e6db74">&amp;#34;])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;x&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>r2 &lt;span style="color:#f92672">=&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(&lt;span style="color:#e6db74">&amp;#34;sample_data.parquet&amp;#34;&lt;/span>, columns&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;[&amp;#34;&lt;/span>y&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>z&lt;span style="color:#e6db74">&amp;#34;, &amp;#34;&lt;/span>a&lt;span style="color:#e6db74">&amp;#34;])&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>loc[df[&lt;span style="color:#e6db74">&amp;#34;a&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">3&lt;/span>, [&lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;y&amp;#34;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#34;z&amp;#34;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>sum()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>&lt;strong>Or, will it keep the intermediate filtered result (f_df) alive when processing &lt;code>r1&lt;/code>&lt;/strong>? since it will be used later in the given program when processing &lt;code>r2&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>ðŸ‘‰ &lt;strong>The answer is (2)&lt;/strong>. It will effectively keep the intermediate results alive that are to be required at some later stage.&lt;/p>
&lt;p>Let&amp;rsquo;s look into the generated IR of the before and after optimization for the modified program:&lt;/p>
&lt;pre tabindex="0">&lt;code>2024-12-05 13:26:41.691496: 959435 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [])
%t1 = project(%t0, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %t4, %v6)
}
2024-12-05 13:26:41.692423: 959435 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
%t0 = read_parquet(&amp;#39;sample_data.parquet&amp;#39;, [&amp;#39;z&amp;#39;, &amp;#39;x&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;y&amp;#39;]) &amp;lt;- this time it also loads &amp;#34;y&amp;#34; column (as needed for r2)
%t1 = project(%t0, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, &amp;#39;z&amp;#39;])
%t2 = project(%t0, &amp;#39;a&amp;#39;)
%t3 = gt.vector.scalar(%t2, 3)
%t4 = filter(%t1, %t3)
%t5 = groupby_select_agg(%t4, [&amp;#39;x&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v6 = get_shape(%t5)
return(%t5, %t4, %v6) &amp;lt;- this time it also returns filtered dataframe (%t4)
}
2024-12-05 13:26:41.706225: 959435 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main(%arg0: !table) { later use.
%t1 = groupby_select_agg(%arg0, [&amp;#39;y&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v2 = get_shape(%t1)
return(%t1, %v2)
}
2024-12-05 13:26:41.706721: 959435 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main(%arg0: !table) {
%t1 = groupby_select_agg(%arg0, [&amp;#39;y&amp;#39;], [&amp;#39;sum&amp;#39;], [], [], &amp;#39;z&amp;#39;)
%v2 = get_shape(%t1)
return(%t1, %v2)
}
&lt;/code>&lt;/pre>&lt;p>The first &amp;ldquo;Optimized IR&amp;rdquo; is generated when processing &lt;code>r1&lt;/code>.
This time the compiler identifies the &amp;ldquo;y&amp;rdquo; column and the filtered dataframe (f_df) will be used at later stage when computing &lt;code>r2&lt;/code>.
Hence it will also load the &amp;ldquo;y&amp;rdquo; column and keep the intermediate filtered dataframe alive (in other word, cache it) by returning
it (%t4) along with the result of &lt;code>r1&lt;/code> (%t5) to avoid further processing at later use.&lt;/p>
&lt;p>ðŸ‘‰If you carefully notice the previous IR returned only &lt;code>(%t5, %v6)&lt;/code>, when there was no computing related to &lt;code>r2&lt;/code> in the input program.&lt;/p>
&lt;p>The second &amp;ldquo;Optimized IR&amp;rdquo; is generated when processing &lt;code>r2&lt;/code>.
The input &lt;code>%arg0&lt;/code> is the filtered dataframe (%t4) that the compiler kept alive.
Hence only groupby-sum is performed when processing &lt;code>r2&lt;/code>.&lt;/p>
&lt;h2 id="how-to-profile">How to profile?&lt;/h2>
&lt;p>You can also check kernel-wise execution time, number of calls etc. by executing the program as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ FIREDUCKS_FLAGS=&amp;#34;--trace=3 --trace-file=-&amp;#34; python -mfireducks.pandas sample.py
&lt;/code>&lt;/pre>&lt;p>It will produce some profiling output as follows:&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-duration" data-lang="duration">== kernel ==
fireducks.gt.vector.scalar 0.004 8.26% 1
fireducks.read_parquet 0.003 6.02% 1
fireducks.groupby_select_agg 0.002 3.06% 2
fireducks.to_pandas.frame.metadata 0.001 1.89% 2
fireducks.filter 0.001 1.34% 1
fireducks.project 0.000 0.03% 2
&lt;/code>&lt;/pre>&lt;p>It can clearly be seen that the method related to read_parquet, filter etc. is called only once.
In order to produce the similar profiling on Jupyter notebook, you can use the cell magic: &lt;code>%%fireducks.profile&lt;/code>.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping-up&lt;/h2>
&lt;p>Thank you for your time in reading this article.
In case you have any queries or have an issue to report, please feel free to get in touch with us in any of your prefered channel mentioned below:&lt;/p>
&lt;ul>
&lt;li>ðŸ¦†github : &lt;a href="https://github.com/fireducks-dev/fireducks/issues/new">https://github.com/fireducks-dev/fireducks/issues/new&lt;/a>&lt;/li>
&lt;li>ðŸ“§mail : &lt;a href="mailto:contact@fireducks.jp.nec.com">contact@fireducks.jp.nec.com&lt;/a>&lt;/li>
&lt;li>ðŸ¤slack : &lt;a href="https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w">https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Posts: Import hooks: how to use FireDucks without modifying your programs</title><link>https://fireducks-dev.github.io/posts/importhook/</link><pubDate>Wed, 15 Nov 2023 09:35:10 +0900</pubDate><guid>https://fireducks-dev.github.io/posts/importhook/</guid><description>
&lt;p>This is Osamu Daido from the FireDucks development team.
In today&amp;rsquo;s developers&amp;rsquo; blog, I would like to introduce the import hook feature of FireDucks.
This feature enables you to use FireDucks without modifying your existing programs at all.&lt;/p>
&lt;p>I&amp;rsquo;ll explain how to use hooks when running Python files on the command line and how to enable hooks in IPython or Jupyter Notebook.&lt;/p>
&lt;h1 id="what-is-an-import-hook">What is an import hook?&lt;/h1>
&lt;p>FireDucks behaves in the same way as the original pandas, so it&amp;rsquo;s easy to get started by simply modifying an import statement as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># import pandas as pd&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, even if it&amp;rsquo;s just a single line, finding and replacing import statements with FireDucks in your programs which use pandas may be annoying.
Moreover, if you want to use FireDucks in a third-party library that works with pandas, it&amp;rsquo;s not practical to modify all import statements in that library.&lt;/p>
&lt;p>As mentioned in &lt;a href="https://fireducks-dev.github.io/docs/get-started/#import-hook">Get Started&lt;/a>, FireDucks has a utility called an import hook.
Please specify the following options for the Python interpreter when you run &lt;code>your_script.py&lt;/code> on the command line.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>python3 -m fireducks.imhook your_script.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With this feature, &lt;code>fireducks.pandas&lt;/code> is imported instead of &lt;code>pandas&lt;/code> when the Python interpreter attempts to import &lt;code>pandas&lt;/code>.
Keep in mind that this does not edit the source code of &lt;code>your_script.py&lt;/code>, but rather dynamically hacks the import process while executing the program.&lt;/p>
&lt;h2 id="example-of-an-import-hook">Example of an import hook&lt;/h2>
&lt;p>Let&amp;rsquo;s see it in action with a simple Python script, &lt;code>print_classname.py&lt;/code>, as shown below.
This script outputs the repr string of the DataFrame class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(pd&lt;span style="color:#f92672">.&lt;/span>DataFrame)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you run it normally, the output is as follows:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ python3 print_classname.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;class &lt;span style="color:#e6db74">&amp;#39;pandas.core.frame.DataFrame&amp;#39;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With the import hook, the output becomes different from the previous one, as follows! ðŸ¥³&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ python3 -m fireducks.imhook print_classname.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;class &lt;span style="color:#e6db74">&amp;#39;fireducks.pandas.frame.DataFrame&amp;#39;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So, yes, you can use dataframes of FireDucks even though you haven&amp;rsquo;t edited the source code.&lt;/p>
&lt;h2 id="limitations">Limitations&lt;/h2>
&lt;h3 id="no-shebang-support">No shebang support&lt;/h3>
&lt;p>Currently, execution by shebang (&lt;code>#!...&lt;/code>) is not supported.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">#!/usr/bin/python3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(pd&lt;span style="color:#f92672">.&lt;/span>DataFrame)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You cannot enable an import hook, as you cannot specify the &lt;code>-m&lt;/code> option for the Python interpreter (hmm, it&amp;rsquo;s of course).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>$ chmod +x print_classname_shebang.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ ./print_classname_shebang.py
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&amp;lt;class &lt;span style="color:#e6db74">&amp;#39;pandas.core.frame.DataFrame&amp;#39;&lt;/span>&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="no-combination-with-other-executable-modules">No combination with other executable modules&lt;/h3>
&lt;p>The import hook feature cannot be used concurrently with other tools invoked by the &lt;code>-m&lt;/code> option, as only one &lt;code>-m&lt;/code> option can be passed to the Python interpreter.&lt;/p>
&lt;h3 id="no-subprocess-support">No subprocess support&lt;/h3>
&lt;p>If you start a new Python process using the &lt;code>subprocess&lt;/code> module, the import hook settings are not inherited by that subprocess.&lt;/p>
&lt;h1 id="how-to-use-import-hooks-in-jupyter-notebook">How to use import hooks in Jupyter Notebook&lt;/h1>
&lt;p>The import hook feature is also available in Jupyter Notebook.
Currently, however, you cannot specify an option when starting Jupyter, and you must activate a hook explicitly in the first cell of your notebook.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.importhook
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fireducks&lt;span style="color:#f92672">.&lt;/span>importhook&lt;span style="color:#f92672">.&lt;/span>activate_hook(&lt;span style="color:#e6db74">&amp;#34;fireducks.pandas&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;pandas&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There may not be much benefit to using import hooks if you&amp;rsquo;re just using pandas in your own notebook.
On the other hand, import hooks also work with third-party libraries that use pandas, so it&amp;rsquo;s useful if you want to utilize such libraries in your notebook.&lt;/p>
&lt;p>If you want to disable a hook, please call the following function.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>fireducks&lt;span style="color:#f92672">.&lt;/span>importhook&lt;span style="color:#f92672">.&lt;/span>deactivate_hook()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, if you mix dataframes from the original pandas with ones from FireDucks, you will likely encounter errors (probably with complicated and mysterious error messages).
Basically, it is recommended to keep a hook enabled once you enable it.&lt;/p>
&lt;h2 id="how-to-use-import-hooks-with-ipython-cli">How to use import hooks with IPython CLI&lt;/h2>
&lt;p>With IPython, you can enable a hook manually in the same way as in Jupyter Notebook described above.
Another option is to start the IPython CLI as follows (this is an example with bash):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>python3 -m fireducks.imhook &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>which ipython&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Well, it&amp;rsquo;s a bit of an unusual way, but it works!&lt;/p>
&lt;h1 id="wrap-up">Wrap-up&lt;/h1>
&lt;p>FireDucks is still under research and development, so you may face errors and problems if you switch from using pandas to FireDucks.
We have been working on improving features of FireDucks every day since the release of the beta version.
Your feedback, bug reports, and feature requests are welcome!
Please see our &lt;a href="https://fireducks-dev.github.io/docs/help/contact/">contact information&lt;/a> for further details.&lt;/p>
&lt;p>To sum up, I&amp;rsquo;ve shown you how to use FireDucks without modifying your existing programs at all.
If you want to try FireDucks, please refer to &lt;a href="https://fireducks-dev.github.io/docs/get-started/">Get Started&lt;/a> and &lt;a href="https://fireducks-dev.github.io/docs/user-guide/01-intro/">User Guide&lt;/a> documents. For information on how much faster FireDucks is compared to pandas, please check out our &lt;a href="https://fireducks-dev.github.io/docs/benchmarks/">Benchmarks&lt;/a>.&lt;/p>
&lt;p>May the Acceleration be with you,&lt;!-- raw HTML omitted -->
FireDucks Development Team&lt;/p></description></item><item><title>Posts: Using Python's fast data frame library FireDucks</title><link>https://fireducks-dev.github.io/posts/nes_taxi/</link><pubDate>Mon, 23 Oct 2023 08:47:36 +0000</pubDate><guid>https://fireducks-dev.github.io/posts/nes_taxi/</guid><description>
&lt;p>pandas is a library that provides functions to support data analysis in the Python programming language.
NEC Research Laboratories has developed a library called FireDucks, a faster version of pandas.&lt;/p>
&lt;h2 id="data-preparation">Data Preparation&lt;/h2>
&lt;p>The analysis is performed on the data of passenger history of cabs in New York City.
The source of the data is as follows:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page">https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>To analyze large data sets, we downloaded and merged the &amp;ldquo;Yellow Taxi Trip Records&amp;rdquo; data from January 2022 to June 2023 from the above link.
The data is provided in parquet format, but I converted it to csv format for testing.
A script for preparing the data is included for reference.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dir &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;xxx&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_list &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> year &lt;span style="color:#f92672">in&lt;/span> [&lt;span style="color:#ae81ff">2022&lt;/span>, &lt;span style="color:#ae81ff">2023&lt;/span>]: &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">12&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">12&lt;/span>): &lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">=&lt;/span> str(i&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>zfill(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>month &lt;span style="color:#f92672">=&lt;/span> str(i&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>zfill(&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fn &lt;span style="color:#f92672">=&lt;/span> f &lt;span style="color:#e6db74">&amp;#34;yellow_tripdata_&lt;/span>&lt;span style="color:#e6db74">{year}&lt;/span>&lt;span style="color:#e6db74">-&lt;/span>&lt;span style="color:#e6db74">{month}&lt;/span>&lt;span style="color:#e6db74">.parquet&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>file &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(dir, fn)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">not&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>exists(file):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">continue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_parquet(fn)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_list&lt;span style="color:#f92672">.&lt;/span>append(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>all_df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>concat(df_list)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>all_df&lt;span style="color:#f92672">.&lt;/span>to_csv(&lt;span style="color:#e6db74">&amp;#34;taxi_all.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The contents of the data contains the following values (some columns are excerpts).&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Column name&lt;/th>
&lt;th>&lt;!-- raw HTML omitted -->Data type&lt;!-- raw HTML omitted -->&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>passenger_count&lt;/code>&lt;/td>
&lt;td>int&lt;/td>
&lt;td>The number of passengers&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>pu_location_Id&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The TLC cab zone where the cab meter started working.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>do_location_Id&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The TLC cab zone where the cab meter was deactivated.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>tpep_dropoff_datetime&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The date and time the meter was deactivated.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>tpep_pickupdate_time&lt;/code>&lt;/td>
&lt;td>string&lt;/td>
&lt;td>The date and time when the meter started to work.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>trip_distance&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>The trip distance (in miles) reported by the cab meter.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>total_amount&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>The total amount of money charged to the passenger, not including the cash tip.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>extra&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>Other surcharges and additional charges. Currently, this includes only the $0.50 and $1 rush hour and nighttime fares.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>fare_amount&lt;/code>&lt;/td>
&lt;td>double&lt;/td>
&lt;td>Time-and-distance combined fare calculated by the meter.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="actual-preprocessing">Actual preprocessing&lt;/h2>
&lt;p>A series of preprocessing calculations, such as type conversion, column addition, and outlier deletion, which are often used in data analysis, are performed on the prepared data.&lt;/p>
&lt;p>First, prepare a wrapper for speed measurement.
&lt;code>_evaluate()&lt;/code> is described later.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> time &lt;span style="color:#f92672">import&lt;/span> time
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> functools &lt;span style="color:#f92672">import&lt;/span> wraps
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">timer&lt;/span>(func):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@wraps&lt;/span>(func)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">wp&lt;/span>(&lt;span style="color:#f92672">*&lt;/span>args, &lt;span style="color:#f92672">**&lt;/span>kargs):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>t &lt;span style="color:#f92672">=&lt;/span> time()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ret &lt;span style="color:#f92672">=&lt;/span> func(&lt;span style="color:#f92672">*&lt;/span>args, &lt;span style="color:#f92672">**&lt;/span>kargs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">f&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">{&lt;/span>func&lt;span style="color:#f92672">.&lt;/span>__name__&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> : &lt;/span>&lt;span style="color:#e6db74">{&lt;/span>(time() &lt;span style="color:#f92672">-&lt;/span> t)&lt;span style="color:#e6db74">:&lt;/span>&lt;span style="color:#e6db74">.5g&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> [sec]&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> ret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> wp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">evaluate&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> hasattr(df, &lt;span style="color:#e6db74">&amp;#34;_evaluate&amp;#34;&lt;/span>):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>_evaluate()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="loading-data">Loading data&lt;/h3>
&lt;p>First, read the data.
Import pandas and then use &lt;code>read_csv&lt;/code> to read the data.
Define a function, and call it later to measure the data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">file_read&lt;/span>(fn, args&lt;span style="color:#f92672">=&lt;/span>{}):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(fn, &lt;span style="color:#f92672">**&lt;/span>args)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(df&lt;span style="color:#f92672">.&lt;/span>shape)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="data-processing">Data processing&lt;/h3>
&lt;p>Remove data with missing values.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">drop_na&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df&lt;span style="color:#f92672">.&lt;/span>dropna(how&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;all&amp;#34;&lt;/span>, inplace&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The date and time of boarding and alighting are read as strings, so they should be converted to dates.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">txt_to_date&lt;/span>(df, low):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[low] &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>to_datetime(df[low])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s look at the distribution grouped by the number of boardings (print is not included in the performance evaluation, so it is omitted).
We see that there are data with zero riders, so we remove them.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># At least one person on the train&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_passenger_c&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;passenger_count&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[df[&lt;span style="color:#e6db74">&amp;#34;passenger_count&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Extract the year, month, day, and hour information from the ride date data and add columns.
The distribution of the year and month of the ride contains incorrect values, so we remove them.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># correct ride year/month&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_pu_date&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;year&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>year
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;month&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>month
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;date&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>day
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#39;hour&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>hour
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;year&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#39;year&amp;#39;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">2022&lt;/span>) &lt;span style="color:#f92672">|&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#39;year&amp;#39;&lt;/span>] &lt;span style="color:#f92672">==&lt;/span> &lt;span style="color:#ae81ff">2023&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#34;month&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#39;month&amp;#39;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> df[&lt;span style="color:#e6db74">&amp;#39;month&amp;#39;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df_ &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>groupby([&lt;span style="color:#e6db74">&amp;#34;year&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;month&amp;#34;&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>size()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df_)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Convert the difference between the disembarkation time and the ride time to minutes and add a column.
Remove non-positive or too long ride times.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># realistic ride time in minutes&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_ride_time&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df[&lt;span style="color:#e6db74">&amp;#34;ride_time&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;tpep_dropoff_datetime&amp;#34;&lt;/span>] &lt;span style="color:#f92672">-&lt;/span> df[&lt;span style="color:#e6db74">&amp;#34;tpep_pickup_datetime&amp;#34;&lt;/span>])&lt;span style="color:#f92672">.&lt;/span>dt&lt;span style="color:#f92672">.&lt;/span>seconds &lt;span style="color:#f92672">/&lt;/span> &lt;span style="color:#ae81ff">60&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;ride_time&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;ride_time&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">180&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Remove non-negative or too large values for ride distance and fare.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># realistic distances&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_trip_distance&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;trip_distance&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;trip_distance&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">250&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Realistic fares&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_total_amount&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;total_amount&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;total_amount&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">1000&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Calculate the latitude and longitude from the IDs of the boarding and alighting points.
The relationship between the ID and the point can be checked as follows:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv">https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>The columns are added by merging the conversion table created based on the latitude and longitude calculated from:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip">https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Remove data outside New York City from the latitude and longitude information.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Find latitude and longitude from IDs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">add_coordinate&lt;/span>(df, ID_df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>merge(ID_df&lt;span style="color:#f92672">.&lt;/span>rename(columns&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;longitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;start_lon&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;latitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;start_lat&amp;#34;&lt;/span>}),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;PULocationID&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, how&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;left&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>drop(&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df&lt;span style="color:#f92672">.&lt;/span>merge(ID_df&lt;span style="color:#f92672">.&lt;/span>rename(columns&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#34;longitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;end_lon&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;latitude&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;end_lat&amp;#34;&lt;/span>}),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>left_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;DOLocationID&amp;#34;&lt;/span>, right_on&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, how&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;left&amp;#34;&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>drop(&lt;span style="color:#e6db74">&amp;#34;LocationID&amp;#34;&lt;/span>, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Check if it is in NY&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">in_NY&lt;/span>(df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;start_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">71.47&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;start_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">79.45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;start_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">40.29&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;start_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;end_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">71.47&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;end_lon&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">79.45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> df[(df[&lt;span style="color:#e6db74">&amp;#34;end_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;gt;=&lt;/span> &lt;span style="color:#ae81ff">40.29&lt;/span>) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (df[&lt;span style="color:#e6db74">&amp;#34;end_lat&amp;#34;&lt;/span>] &lt;span style="color:#f92672">&amp;lt;=&lt;/span> &lt;span style="color:#ae81ff">45&lt;/span>)]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">check_in_NY&lt;/span>(df, ID_df):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> add_coordinate(df, ID_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> in_NY(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As described above, a series of processes are prepared to read data, perform type conversion, add columns, and remove outlier values.&lt;/p>
&lt;ol>
&lt;li>Read the file&lt;/li>
&lt;li>Convert date data from string to date data&lt;/li>
&lt;li>Preprocessing&lt;/li>
&lt;li>Remove missing values&lt;/li>
&lt;li>Check the number of passengers&lt;/li>
&lt;li>Check distribution by groupby&lt;/li>
&lt;li>Select at least 1 passenger&lt;/li>
&lt;li>Check the time of boarding&lt;/li>
&lt;li>Tet the year, month, date and time from the date data and add a column&lt;/li>
&lt;li>Group by year and check -&amp;gt; Select only the relevant year&lt;/li>
&lt;li>Group by month and check -&amp;gt; select only Jan-Dec&lt;/li>
&lt;li>Group by year and month and check the distribution&lt;/li>
&lt;li>Check the boarding time&lt;/li>
&lt;li>Take the difference between the time of disembarkation and the time of embarkation, convert to minutes, and add a column (&lt;code>dt.total_second&lt;/code> is not supported by FireDucks)&lt;/li>
&lt;li>Select realistic ride time data&lt;/li>
&lt;li>Check the ride distance&lt;/li>
&lt;li>Select realistic distance data&lt;/li>
&lt;li>Check fare&lt;/li>
&lt;li>Select realistic fare data&lt;/li>
&lt;li>Select NY City data&lt;/li>
&lt;li>Merge the passenger ID with the latitude and longitude table&lt;/li>
&lt;li>Select the data where the longitude and latitude of the boarding and alighting is in NY city&lt;/li>
&lt;/ol>
&lt;h2 id="execution-time-in-pandas">Execution time in pandas&lt;/h2>
&lt;p>First, let&amp;rsquo;s check the execution time on pandas.
A 24-core Xeon server (Intel(R) Xeon(R) Gold 6226 CPU x 2, 256GB main memory) was used for the measurement.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> os
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data_path &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;data_sets&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>fn &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(data_path, &lt;span style="color:#e6db74">&amp;#34;taxi_all.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ID_file &lt;span style="color:#f92672">=&lt;/span> os&lt;span style="color:#f92672">.&lt;/span>path&lt;span style="color:#f92672">.&lt;/span>join(data_path, &lt;span style="color:#e6db74">&amp;#34;ID_to_coordinate.csv&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>need_cols &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;tpep_pickup_datetime&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;tpep_dropoff_datetime&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;passenger_count&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;trip_distance&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#39;PULocationID&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;DOLocationID&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;total_amount&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;improvement_surcharge&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;extra&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;fare_amount&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;RatecodeID&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">@timer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">Preprocessing&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> file_read(fn, {&lt;span style="color:#e6db74">&amp;#34;usecols&amp;#34;&lt;/span>: need_cols})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>ID_df &lt;span style="color:#f92672">=&lt;/span> file_read(ID_file)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> txt_to_date(df, &lt;span style="color:#e6db74">&amp;#34;tpep_pickup_datetime&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> txt_to_date(df, &lt;span style="color:#e6db74">&amp;#34;tpep_dropoff_datetime&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> drop_na(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_passenger_c(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_pu_date(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_ride_time(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_trip_distance(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_total_amount(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> check_in_NY(df, ID_df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>evaluate(df)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">return&lt;/span> df
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>df &lt;span style="color:#f92672">=&lt;/span> Preprocessing()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now, the execution time in pandas is as shown in the table below.
The two &lt;code>file_read&lt;/code> files are due to reading the taxi data as well as the location data for merging, and the &lt;code>txt_to_date&lt;/code> file is due to converting the ride time and the drop-off time.
The execution time shows that it took more than one minute to read the file.
In addition, &lt;code>check_pu_date&lt;/code> and &lt;code>add_coordinate&lt;/code>, which include adding columns and merge processing, take more than 30 seconds, and the implemented preprocessing takes 186 seconds to complete.&lt;/p>
&lt;h2 id="execution-time-with-fireducks">Execution time with FireDucks&lt;/h2>
&lt;p>Measure the execution time when using FireDucks with the imported library replaced by pandas.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>pip install fireducks
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The above scripts for pandas preprocessing can be used as-is by importing FireDucks, since FireDucks is compatible with pandas.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> fireducks.pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that FireDucks does not immediately execute methods when they are called.
Therefore, it is necessary to run &lt;code>_evaluate()&lt;/code> to measure the execution time of each method.&lt;/p>
&lt;p>The following table compares the execution time of FireDucks with that of pandas after importing FireDucks and performing the same preprocessing calculations.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Function&lt;/th>
&lt;th style="text-align:right">pandas [sec]&lt;/th>
&lt;th style="text-align:right">FireDucks [sec]&lt;/th>
&lt;th style="text-align:right">Speed-up ratio&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">&lt;code>file_read&lt;/code>&lt;/td>
&lt;td style="text-align:right">72.19&lt;/td>
&lt;td style="text-align:right">3.52&lt;/td>
&lt;td style="text-align:right">20.49&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>file_read&lt;/code>&lt;/td>
&lt;td style="text-align:right">0.003&lt;/td>
&lt;td style="text-align:right">0.01&lt;/td>
&lt;td style="text-align:right">0.38&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>txt_to_date&lt;/code>&lt;/td>
&lt;td style="text-align:right">9.07&lt;/td>
&lt;td style="text-align:right">19.10&lt;/td>
&lt;td style="text-align:right">0.48&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>txt_to_date&lt;/code>&lt;/td>
&lt;td style="text-align:right">8.57&lt;/td>
&lt;td style="text-align:right">20.57&lt;/td>
&lt;td style="text-align:right">0.42&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>drop_na&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.13&lt;/td>
&lt;td style="text-align:right">0.70&lt;/td>
&lt;td style="text-align:right">4.47&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_passenger_c&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.21&lt;/td>
&lt;td style="text-align:right">1.80&lt;/td>
&lt;td style="text-align:right">1.79&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_pu_date&lt;/code>&lt;/td>
&lt;td style="text-align:right">27.37&lt;/td>
&lt;td style="text-align:right">0.99&lt;/td>
&lt;td style="text-align:right">27.64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_ride_time&lt;/code>&lt;/td>
&lt;td style="text-align:right">7.02&lt;/td>
&lt;td style="text-align:right">2.00&lt;/td>
&lt;td style="text-align:right">3.51&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_trip_distance&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.24&lt;/td>
&lt;td style="text-align:right">0.91&lt;/td>
&lt;td style="text-align:right">3.55&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_total_amount&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.11&lt;/td>
&lt;td style="text-align:right">0.93&lt;/td>
&lt;td style="text-align:right">3.59&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>check_total_amount&lt;/code>&lt;/td>
&lt;td style="text-align:right">3.11&lt;/td>
&lt;td style="text-align:right">0.93&lt;/td>
&lt;td style="text-align:right">3.59&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>in_NY&lt;/code>&lt;/td>
&lt;td style="text-align:right">20.75&lt;/td>
&lt;td style="text-align:right">2.71&lt;/td>
&lt;td style="text-align:right">7.65&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>Preprocessing&lt;/code>&lt;/td>
&lt;td style="text-align:right">186.02&lt;/td>
&lt;td style="text-align:right">54.92&lt;/td>
&lt;td style="text-align:right">3.39&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The &lt;code>file_read&lt;/code> process took more than 70 seconds to complete in pandas, but it took about 3.5 seconds, which is more than 20 times faster.
Other time-consuming processes (&lt;code>check_pu_date&lt;/code>, &lt;code>add_coordinate&lt;/code>) were also significantly reduced.&lt;/p>
&lt;p>The computation time for &lt;code>txt_to_date&lt;/code> was increased by using FireDucks.
This is because the &lt;code>to_datetime()&lt;/code> function is not supported by FireDucks at the time of writing.
However, even when a function like &lt;code>to_datetime()&lt;/code> is called that does not support acceleration, FireDucks does not return an error because it performs the calculation by calling a pandas function.&lt;/p>
&lt;p>The total computation time for the preprocessing calculations in this article was 55 seconds with FireDucks, compared to 186 seconds with pandas, which is about 3.4 times faster.
Of the 55 seconds, about 40 seconds was for processing that had not yet been accelerated, and further acceleration is expected in the future.&lt;/p></description></item></channel></rss>