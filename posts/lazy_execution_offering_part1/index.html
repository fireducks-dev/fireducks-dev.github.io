<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1 | FireDucks</title>
<meta name=description content="The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas. To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).
Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?"><meta property="og:title" content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1"><meta property="og:description" content="The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas. To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).
Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?"><meta property="og:type" content="article"><meta property="og:url" content="https://fireducks-dev.github.io/posts/lazy_execution_offering_part1/"><meta property="og:image" content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-05T00:00:00+00:00"><meta itemprop=name content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1"><meta itemprop=description content="The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas. To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).
Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?"><meta itemprop=datePublished content="2024-12-05T00:00:00+00:00"><meta itemprop=dateModified content="2024-12-05T00:00:00+00:00"><meta itemprop=wordCount content="958"><meta itemprop=image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta name=twitter:title content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1"><meta name=twitter:description content="The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas. To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).
Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?"><link rel=preload href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css as=style><link href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.3.min.js integrity="sha512-STof4xm1wgkfm7heWqFJVn58Hm3EtS31XFaagaa8VMReCXAkQnJZ+jEy8PCC/iT18dFy95WcExNHFTqLyp72eQ==" crossorigin=anonymous></script></head><body class="td-page td-blog"><header><nav class="td-navbar navbar-dark js-navbar-scroll"><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>FireDucks</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/docs/get-started><span>Get Started</span></a></li><li class=nav-item><a class=nav-link href=/docs/user-guide/01-intro/><span>Docs</span></a></li><li class=nav-item><a class=nav-link href=/posts><span>Blogs</span></a></li><li class=nav-item><a class=nav-link href=/docs/benchmarks><span>Benchmarks</span></a></li><li class=nav-item><a class=nav-link href=/talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/fireducks-dev/fireducks/issues target=_blank rel=noopener><span>Report Issue</span></a></li><li class=nav-item><a class=nav-link href=/docs/about-us><span>About Us</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="td-sidebar-nav collapse" id=td-section-nav><div class="td-sidebar-nav__section nav-item dropdown d-block d-lg-none"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></div><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-posts-li><a href=/posts/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-posts><span>Posts</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241206_update_polars-tpch-li><a href=/posts/20241206_update_polars-tpch/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241206_update_polars-tpch><span>How to run polars-tpch benchmark with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-postslazy_execution_offering_part1-li><a href=/posts/lazy_execution_offering_part1/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-postslazy_execution_offering_part1><span class=td-sidebar-nav-active-item>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsefficient_caching-li><a href=/posts/efficient_caching/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsefficient_caching><span>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsbeginner_guide-li><a href=/posts/beginner_guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsbeginner_guide><span>What to do when FireDucks is slow</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20240919-workshop-li><a href=/posts/20240919-workshop/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20240919-workshop><span>Workshop at Bangalore, India</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postssourav_cse_demo_20240701-li><a href=/posts/sourav_cse_demo_20240701/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postssourav_cse_demo_20240701><span>Have you ever thought of speeding up your data analysis in pandas with a compiler?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-05-08-medium-li><a href=https://medium.com/@fireducks/introduction-to-fireducks-get-performance-beyond-pandas-with-zero-learning-cost-8694d4eab9c6 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-05-08-medium><i class="fa fa-external-link"></i><span>Introduction to FireDucks: Get performance beyond pandas with zero learning cost!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci4-li><a href=https://medium.com/@ashu.thakur/backtesting-trading-strategies-with-ease-an-excursion-with-fireducks-e771b701dcd5 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci4><i class="fa fa-external-link"></i><span>Backtesting Trading Strategies with Ease: An excursion with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci3-li><a href=https://medium.com/@ashu.thakur/fireducks-diving-into-api-compatibility-with-pandas-e8f4111c2f98 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci3><i class="fa fa-external-link"></i><span>FireDucks: Diving into API Compatibility with Pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci2-li><a href=https://medium.com/@ashu.thakur/choosing-your-data-champion-a-side-by-side-look-at-fireducks-and-polars-51c144fd4689 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci2><i class="fa fa-external-link"></i><span>Choosing Your Data Champion: A Side-by-Side Look at FireDucks and Polars</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci1-li><a href=https://medium.com/@ashu.thakur/boosting-data-analysis-with-fireducks-0066ad25966d target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci1><i class="fa fa-external-link"></i><span>Boosting Data Analysis with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231216-sourav-li><a href=https://qiita.com/qsourav/items/5c06426fae5f3df0244c target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231216-sourav><i class="fa fa-external-link"></i><span>A hidden fact you must know when working with pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231211-sourav-li><a href=https://qiita.com/qsourav/items/1c1fe15faa06fce1dd33 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231211-sourav><i class="fa fa-external-link"></i><span>Tricks to improve computational performance of JOIN operation more than 10x</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231207-sourav-li><a href=https://qiita.com/qsourav/items/e87f25c4b307391d784a target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231207-sourav><i class="fa fa-external-link"></i><span>FireDucks - An economical and environment-friendly high-performance solution for your complex Data Analysis</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231206-sourav-li><a href=https://qiita.com/qsourav/items/cc4ca4c8d4668ce617bf target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231206-sourav><i class="fa fa-external-link"></i><span>One thing you might be doing wrong in pandas!!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsest-li><a href=/posts/est/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsest><span>Acceleration technology inside FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsimporthook-li><a href=/posts/importhook/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsimporthook><span>Import hooks: how to use FireDucks without modifying your programs</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsnes_taxi-li><a href=/posts/nes_taxi/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsnes_taxi><span>Using Python's fast data frame library FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-poststtdc-li><a href=https://www.nec.com/en/global/rd/technologies/202312/index.html target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-poststtdc><i class="fa fa-external-link"></i><span>Application example: Spicy MINT at Toyota Technical Development Corporation</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#fireducks-offerings>FireDucks Offerings</a></li><li><a href=#lets-put-it-into-a-test-drive>Let&rsquo;s put it into a test drive</a></li><li><a href=#wrapping-up>Wrapping-up</a></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><a class=td-rss-button title=RSS href=https://fireducks-dev.github.io/posts/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</h1><div class="td-byline mb-4">By <b>Sourav Saha</b> |
<time datetime=2024-12-05 class=text-muted>Thursday, December 05, 2024</time></div><header class=article-meta></header><p>The availability of runtime memory is often a challenge faced at processing larger-than-memory-dataset while working with pandas.
To solve the problem, one can either shift to a system with larger memory capacity or consider switching to alternative libraries supporting distributed data processing like (Dask, PySpark etc.).</p><p>Well, do you know when working with data stored in columnar formats like csv, parquet etc. and only some part of data is to be processed, manual optimization is possible even in pandas?
For example, let&rsquo;s consider the below data is stored in a parquet file, named sample_data.parquet (or in a csv file, named sample_data.csv):</p><pre tabindex=0><code>   a    b   c  x   y   z
0  1  0.1   1  0  t1  10
1  2  0.2   4  1  t2  20
2  3  0.3   9  1  t3  30
3  4  0.4  16  0  t1  40
4  5  0.5  25  1  t2  50
5  6  0.6  36  1  t1  60
6  7  0.7  49  0  t2  70
7  8  0.8  64  1  t3  80
</code></pre><p>And you want to perform sum of &ldquo;c&rdquo; column, when the value of &ldquo;x&rdquo; column is 1. You may simply write the program as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>)
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;x&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>][<span style=color:#e6db74>&#34;c&#34;</span>]<span style=color:#f92672>.</span>sum() <span style=color:#75715e># filter data based on condition and calculate sum of &#34;c&#34; column from filtered frame</span>
</span></span><span style=display:flex><span>print (res)
</span></span></code></pre></div><p>Now the problem may occur when the parquet file is too large to fit in your system memory, although you are interested only a part of it (column &ldquo;x&rdquo; and &ldquo;c&rdquo;).
Thankfully, read_parquet() method has a parameter named <code>columns</code> and you can specify the target columns to be loaded from the input parquet file:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>, columns <span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;x&#34;</span>, <span style=color:#e6db74>&#34;c&#34;</span>])
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> df[df[<span style=color:#e6db74>&#34;x&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>][<span style=color:#e6db74>&#34;c&#34;</span>]<span style=color:#f92672>.</span>sum() <span style=color:#75715e># filter data based on condition and calculate sum of &#34;c&#34; column from filtered frame</span>
</span></span><span style=display:flex><span>print (res)
</span></span></code></pre></div><p>Similarly, read_csv() has a parameter, named <code>usecols</code> that can be specified when loading only target columns from a CSV file.</p><h2 id=fireducks-offerings>FireDucks Offerings</h2><p>Although such parameters can be specified to optimize runtime memory consumption when using pandas, it
might be difficult to know what all columns are required at the very begining of analysing the data.
An automatic optimization for such cases would definitely be useful for users of pandas-like libraries.</p><p>Since <strong>FireDucks 1.1.1</strong>, we have supported such optimization to be taken care of by its internal JIT compiler.
Even though such parameters are not manually specified, the JIT compiler can inspect the projection targets
on various stages for a given data and it can automatically specify such parameters when generating the optimized code.
Such optimization is commonly known as <strong>pushdown-projection</strong>. By specifiying the environment variable <strong>FIRE_LOG_LEVEL=3</strong>,
you can inspect the before and after optimization for the below example.</p><pre tabindex=0><code>$ cat read_parquet_opt_demo.py
import pandas as pd

df = pd.read_parquet(&#34;sample_data.parquet&#34;)
r1 = df[df[&#34;x&#34;] == 1][&#34;c&#34;].sum()
print(r1)
</code></pre><p>Execute the program as follows:</p><pre tabindex=0><code>$ FIRE_LOG_LEVEL=3 python -mfireducks.pandas read_parquet_opt_demo.py
</code></pre><p>It will then show the intermediate representation (IR) generated for the above program before execution as follows:</p><pre tabindex=0><code>2024-12-04 13:12:40.618398: 543780 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
  %t0 = read_parquet(&#39;sample_data.parquet&#39;, [])   &lt;- load the input parquet file
  %t1 = project(%t0, &#39;x&#39;)                         &lt;- project &#34;x&#34; column from loaded data (df[&#34;x&#34;])
  %t2 = eq.vector.scalar(%t1, 1)                  &lt;- generate mask with equality check with scalar value, 1 (mask = df[&#34;x&#34;] == 1)
  %t3 = filter(%t0, %t2)                          &lt;- perform filter with computed mask (fdf = df[mask])      
  %t4 = project(%t3, &#39;c&#39;)                         &lt;- project &#34;c&#34; column from filtered data (fdf[&#34;c&#34;])
  %v5 = aggregate_column.scalar(%t4, &#39;sum&#39;)       &lt;- calculate sum of projected column (fdf[&#34;c&#34;].sum())
  return(%t4, %v5)                                 
}
</code></pre><p>And the Optimized IR (target for execution) is as follows.
You can see that it is mostly the same with the optimization added in the instruction for read_parquet()
by automatically specifying the target columns to be loaded for the computation of this specific result (r1).</p><pre tabindex=0><code>2024-12-04 13:12:40.619360: 543780 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
  %t0 = read_parquet(&#39;sample_data.parquet&#39;, [&#39;c&#39;, &#39;x&#39;])   
  %t1 = project(%t0, &#39;x&#39;)                                
  %t2 = eq.vector.scalar(%t1, 1)                         
  %t3 = project(%t0, [&#39;c&#39;])
  %t4 = filter(%t3, %t2)
  %t5 = project(%t4, &#39;c&#39;)
  %v6 = aggregate_column.scalar(%t5, &#39;sum&#39;)
  return(%t5, %v6)
}
</code></pre><p>The python equivalent of the above optimized IR (that will be executed by the FireDucks multi-threaded kernel) is as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>, columns<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;c&#34;</span>, <span style=color:#e6db74>&#34;x&#34;</span>]) <span style=color:#75715e># load only required column for analysis</span>
</span></span><span style=display:flex><span>t1 <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;x&#34;</span>] <span style=color:#75715e># projection of target column for equality check</span>
</span></span><span style=display:flex><span>t2 <span style=color:#f92672>=</span> (t1 <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>t3 <span style=color:#f92672>=</span> df[<span style=color:#e6db74>&#34;c&#34;</span>] <span style=color:#75715e># projection of only target column to be filtered</span>
</span></span><span style=display:flex><span>t4 <span style=color:#f92672>=</span> t3[t2] 
</span></span><span style=display:flex><span>t5 <span style=color:#f92672>=</span> t4[<span style=color:#e6db74>&#34;c&#34;</span>]
</span></span><span style=display:flex><span>v6 <span style=color:#f92672>=</span> t5<span style=color:#f92672>.</span>sum()
</span></span></code></pre></div><p>⚠️ Please note that the verification through this environment variable setting is mainly for the developers and
we might change the way of representing the IRs in future. As a user, it would be good to inspect the optimization
using this variable at this moment though.</p><h2 id=lets-put-it-into-a-test-drive>Let&rsquo;s put it into a test drive</h2><p>You can refer to the <a href=https://github.com/fireducks-dev/fireducks/blob/main/notebooks/read_parquet_optimization.ipynb>notebook</a>.
It demonstrates the performance benefit of such optimization on a real dataset.
You may like to experiment around the query to realize the efficiency of FireDucks optimization.
For a sample query, <strong>FireDucks performed 45x faster than Pandas, that too without any modification in the source program and affecting the result</strong>.</p><p>It also explains some Do&rsquo;s and Don&rsquo;ts when executing a query in notebook-like platform. In case of notebook, the execution takes place cell-by-cell.
Thus when keeping the intermediate results in some cell variables, FireDucks compiler assumes that those might be used at some later stage.
So it will keep all of them alive hindering the optimization. Therefore, it is highly recommended to write a query in chained expression
when using notebook.</p><h2 id=wrapping-up>Wrapping-up</h2><p>Thank you for your time in reading this article.
In case you have any queries or have an issue to report, please feel free to get in touch with us in any of your prefered channel mentioned below:</p><ul><li>🦆github : <a href=https://github.com/fireducks-dev/fireducks/issues/new>https://github.com/fireducks-dev/fireducks/issues/new</a></li><li>📧mail : <a href=mailto:contact@fireducks.jp.nec.com>contact@fireducks.jp.nec.com</a></li><li>🤝slack : <a href=https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w>https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w</a></li></ul><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/posts/efficient_caching/ aria-label="Previous - Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2" class="btn btn-primary"><span class=me-1>←</span>Previous</a></li><li><a href=/posts/20241206_update_polars-tpch/ aria-label="Next - How to run polars-tpch benchmark with FireDucks" class="btn btn-primary">Next<span class=ms-1>→</span></a></li></ul></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="Post issues on GitHub issues" aria-label="Post issues on GitHub issues"><a target=_blank rel=noopener href=https://github.com/fireducks-dev/fireducks aria-label="Post issues on GitHub issues"><i class="fa-brands fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Send an e-mail to us" aria-label="Send an e-mail to us"><a target=_blank rel=noopener href=mailto:contact@fireducks.jp.nec.com aria-label="Send an e-mail to us"><i class="fa-solid fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Follow us in X" aria-label="Follow us in X"><a target=_blank rel=noopener href=https://x.com/fireducksdev aria-label="Follow us in X"><i class="fa-brands fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Join us on Slack" aria-label="Join us on Slack"><a target=_blank rel=noopener href=https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w aria-label="Join us on Slack"><i class="fa-brands fa-slack"></i></a></li></ul></div><div class="col-6 col-sm-4 text-end text-xs-center order-sm-3"></div><div class="td-footer__copyright-etc col-12 col-sm-4 text-center py-2 order-sm-2"><span>&copy; 2024 FireDucks Dev Team All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.350b703200e2632331b6ab5a6c71195d176b52e89c9b70db7c43764d40b28d92.js integrity="sha256-NQtwMgDiYyMxtqtabHEZXRdrUuicm3DbfEN2TUCyjZI=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.f724d3de49218995223b7316aa2e53e2b34bf42026bf399ebb21bb02212402d1.js integrity="sha256-9yTT3kkhiZUiO3MWqi5T4rNL9CAmvzmeuyG7AiEkAtE=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>