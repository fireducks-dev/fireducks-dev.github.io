<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2 | FireDucks</title>
<meta name=description content="In the previous article, we have talked about how FireDucks can take care pushdown-projection related optimization for read_parquet(), read_csv() etc. In today&amp;rsquo;s article, we will focus on the efficient caching mechanism by its JIT compiler.
Let&amp;rsquo;s consider the below sample query for the same data, used in previous article:
import pandas as pd df = pd.read_parquet(&amp;#34;sample_data.parquet&amp;#34;) f_df = df.loc[df[&amp;#34;a&amp;#34;] &amp;gt; 3, [&amp;#34;x&amp;#34;, &amp;#34;y&amp;#34;, &amp;#34;z&amp;#34;]] r1 = f_df.groupby(&amp;#34;x&amp;#34;)[&amp;#34;z&amp;#34;].sum() print(r1) When executing the above program (saved as sample."><meta property="og:title" content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2"><meta property="og:description" content="In the previous article, we have talked about how FireDucks can take care pushdown-projection related optimization for read_parquet(), read_csv() etc. In today&rsquo;s article, we will focus on the efficient caching mechanism by its JIT compiler.
Let&rsquo;s consider the below sample query for the same data, used in previous article:
import pandas as pd df = pd.read_parquet(&#34;sample_data.parquet&#34;) f_df = df.loc[df[&#34;a&#34;] > 3, [&#34;x&#34;, &#34;y&#34;, &#34;z&#34;]] r1 = f_df.groupby(&#34;x&#34;)[&#34;z&#34;].sum() print(r1) When executing the above program (saved as sample."><meta property="og:type" content="article"><meta property="og:url" content="https://fireducks-dev.github.io/posts/efficient_caching/"><meta property="og:image" content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-05T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-05T00:00:00+00:00"><meta itemprop=name content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2"><meta itemprop=description content="In the previous article, we have talked about how FireDucks can take care pushdown-projection related optimization for read_parquet(), read_csv() etc. In today&rsquo;s article, we will focus on the efficient caching mechanism by its JIT compiler.
Let&rsquo;s consider the below sample query for the same data, used in previous article:
import pandas as pd df = pd.read_parquet(&#34;sample_data.parquet&#34;) f_df = df.loc[df[&#34;a&#34;] > 3, [&#34;x&#34;, &#34;y&#34;, &#34;z&#34;]] r1 = f_df.groupby(&#34;x&#34;)[&#34;z&#34;].sum() print(r1) When executing the above program (saved as sample."><meta itemprop=datePublished content="2024-12-05T00:00:00+00:00"><meta itemprop=dateModified content="2024-12-05T00:00:00+00:00"><meta itemprop=wordCount content="826"><meta itemprop=image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta name=twitter:title content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2"><meta name=twitter:description content="In the previous article, we have talked about how FireDucks can take care pushdown-projection related optimization for read_parquet(), read_csv() etc. In today&rsquo;s article, we will focus on the efficient caching mechanism by its JIT compiler.
Let&rsquo;s consider the below sample query for the same data, used in previous article:
import pandas as pd df = pd.read_parquet(&#34;sample_data.parquet&#34;) f_df = df.loc[df[&#34;a&#34;] > 3, [&#34;x&#34;, &#34;y&#34;, &#34;z&#34;]] r1 = f_df.groupby(&#34;x&#34;)[&#34;z&#34;].sum() print(r1) When executing the above program (saved as sample."><link rel=preload href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css as=style><link href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.3.min.js integrity="sha512-STof4xm1wgkfm7heWqFJVn58Hm3EtS31XFaagaa8VMReCXAkQnJZ+jEy8PCC/iT18dFy95WcExNHFTqLyp72eQ==" crossorigin=anonymous></script></head><body class="td-page td-blog"><header><nav class="td-navbar navbar-dark js-navbar-scroll"><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>FireDucks</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/docs/get-started><span>Get Started</span></a></li><li class=nav-item><a class=nav-link href=/docs/user-guide/01-intro/><span>Docs</span></a></li><li class=nav-item><a class=nav-link href=/posts><span>Blogs</span></a></li><li class=nav-item><a class=nav-link href=/docs/benchmarks><span>Benchmarks</span></a></li><li class=nav-item><a class=nav-link href=/talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/fireducks-dev/fireducks/issues target=_blank rel=noopener><span>Report Issue</span></a></li><li class=nav-item><a class=nav-link href=/docs/about-us><span>About Us</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="td-sidebar-nav collapse" id=td-section-nav><div class="td-sidebar-nav__section nav-item dropdown d-block d-lg-none"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></div><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-posts-li><a href=/posts/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-posts><span>Posts</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241217_liveness_analysis-li><a href=/posts/20241217_liveness_analysis/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241217_liveness_analysis><span>Cache or Eliminate? How FireDucks increase opportunity of optimization</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241206_update_polars-tpch-li><a href=/posts/20241206_update_polars-tpch/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241206_update_polars-tpch><span>How to run polars-tpch benchmark with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postslazy_execution_offering_part1-li><a href=/posts/lazy_execution_offering_part1/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postslazy_execution_offering_part1><span>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-postsefficient_caching-li><a href=/posts/efficient_caching/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-postsefficient_caching><span class=td-sidebar-nav-active-item>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsbeginner_guide-li><a href=/posts/beginner_guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsbeginner_guide><span>What to do when FireDucks is slow</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20240919-workshop-li><a href=/posts/20240919-workshop/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20240919-workshop><span>Workshop at Bangalore, India</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postssourav_cse_demo_20240701-li><a href=/posts/sourav_cse_demo_20240701/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postssourav_cse_demo_20240701><span>Have you ever thought of speeding up your data analysis in pandas with a compiler?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-05-08-medium-li><a href=https://medium.com/@fireducks/introduction-to-fireducks-get-performance-beyond-pandas-with-zero-learning-cost-8694d4eab9c6 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-05-08-medium><i class="fa fa-external-link"></i><span>Introduction to FireDucks: Get performance beyond pandas with zero learning cost!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci4-li><a href=https://medium.com/@ashu.thakur/backtesting-trading-strategies-with-ease-an-excursion-with-fireducks-e771b701dcd5 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci4><i class="fa fa-external-link"></i><span>Backtesting Trading Strategies with Ease: An excursion with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci3-li><a href=https://medium.com/@ashu.thakur/fireducks-diving-into-api-compatibility-with-pandas-e8f4111c2f98 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci3><i class="fa fa-external-link"></i><span>FireDucks: Diving into API Compatibility with Pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci2-li><a href=https://medium.com/@ashu.thakur/choosing-your-data-champion-a-side-by-side-look-at-fireducks-and-polars-51c144fd4689 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci2><i class="fa fa-external-link"></i><span>Choosing Your Data Champion: A Side-by-Side Look at FireDucks and Polars</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci1-li><a href=https://medium.com/@ashu.thakur/boosting-data-analysis-with-fireducks-0066ad25966d target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci1><i class="fa fa-external-link"></i><span>Boosting Data Analysis with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231216-sourav-li><a href=https://qiita.com/qsourav/items/5c06426fae5f3df0244c target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231216-sourav><i class="fa fa-external-link"></i><span>A hidden fact you must know when working with pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231211-sourav-li><a href=https://qiita.com/qsourav/items/1c1fe15faa06fce1dd33 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231211-sourav><i class="fa fa-external-link"></i><span>Tricks to improve computational performance of JOIN operation more than 10x</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231207-sourav-li><a href=https://qiita.com/qsourav/items/e87f25c4b307391d784a target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231207-sourav><i class="fa fa-external-link"></i><span>FireDucks - An economical and environment-friendly high-performance solution for your complex Data Analysis</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231206-sourav-li><a href=https://qiita.com/qsourav/items/cc4ca4c8d4668ce617bf target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231206-sourav><i class="fa fa-external-link"></i><span>One thing you might be doing wrong in pandas!!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsest-li><a href=/posts/est/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsest><span>Acceleration technology inside FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsimporthook-li><a href=/posts/importhook/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsimporthook><span>Import hooks: how to use FireDucks without modifying your programs</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsnes_taxi-li><a href=/posts/nes_taxi/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsnes_taxi><span>Using Python's fast data frame library FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-poststtdc-li><a href=https://www.nec.com/en/global/rd/technologies/202312/index.html target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-poststtdc><i class="fa fa-external-link"></i><span>Application example: Spicy MINT at Toyota Technical Development Corporation</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#could-lazy-execution-be-expensive>Could lazy execution be expensive?</a></li><li><a href=#how-to-profile>How to profile?</a></li><li><a href=#wrapping-up>Wrapping-up</a></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><a class=td-rss-button title=RSS href=https://fireducks-dev.github.io/posts/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</h1><div class="td-byline mb-4">By <b>Sourav Saha</b> |
<time datetime=2024-12-05 class=text-muted>Thursday, December 05, 2024</time></div><header class=article-meta></header><p>In the previous <a href=../lazy_execution_offering_part1>article</a>, we have talked about how FireDucks can take care pushdown-projection related
optimization for read_parquet(), read_csv() etc. In today&rsquo;s article, we will focus on the efficient caching mechanism
by its JIT compiler.</p><p>Let&rsquo;s consider the below sample query for the same data, used in previous article:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>)
</span></span><span style=display:flex><span>f_df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>loc[df[<span style=color:#e6db74>&#34;a&#34;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>3</span>, [<span style=color:#e6db74>&#34;x&#34;</span>, <span style=color:#e6db74>&#34;y&#34;</span>, <span style=color:#e6db74>&#34;z&#34;</span>]]
</span></span><span style=display:flex><span>r1 <span style=color:#f92672>=</span> f_df<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;x&#34;</span>)[<span style=color:#e6db74>&#34;z&#34;</span>]<span style=color:#f92672>.</span>sum()
</span></span><span style=display:flex><span>print(r1)
</span></span></code></pre></div><p>When executing the above program (saved as sample.py) as follows:</p><pre tabindex=0><code>$ FIRE_LOG_LEVEL=3 python -mfireducks.pandas sample.py
</code></pre><p>You can find the generated IR before and after optimization:</p><pre tabindex=0><code>2024-12-05 12:37:21.012481: 958259 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
  %t0 = read_parquet(&#39;sample_data.parquet&#39;, [])
  %t1 = project(%t0, [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;])
  %t2 = project(%t0, &#39;a&#39;)
  %t3 = gt.vector.scalar(%t2, 3)
  %t4 = filter(%t1, %t3)
  %t5 = groupby_select_agg(%t4, [&#39;x&#39;], [&#39;sum&#39;], [], [], &#39;z&#39;)
  %v6 = get_shape(%t5)
  return(%t5, %v6)
}

2024-12-05 12:37:21.013462: 958259 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
  %t0 = read_parquet(&#39;sample_data.parquet&#39;, [&#39;x&#39;, &#39;a&#39;, &#39;z&#39;])
  %t1 = project(%t0, [&#39;z&#39;, &#39;x&#39;])
  %t2 = project(%t0, &#39;a&#39;)
  %t3 = gt.vector.scalar(%t2, 3)
  %t4 = filter(%t1, %t3)
  %t5 = groupby_select_agg(%t4, [&#39;x&#39;], [&#39;sum&#39;], [], [], &#39;z&#39;)
  %v6 = get_shape(%t5)
  return(%t5, %v6)
}
</code></pre><p>It can be noted that the compiler correctly identified the projection targets for read_parquet() as &ldquo;x&rdquo;, &ldquo;a&rdquo;, and &ldquo;z&rdquo; columns.
Although the &ldquo;y&rdquo; column is specified to be projected in the loc indexer, but that column is never used within the
above program. Hence, that is not even loaded during the read_parquet stage.</p><h2 id=could-lazy-execution-be-expensive>Could lazy execution be expensive?</h2><p>Now, the question is what will happen if we want to perform another groupby-aggregation on the same filtered dataframe
that requires &ldquo;y&rdquo; column as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>)
</span></span><span style=display:flex><span>f_df <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>loc[df[<span style=color:#e6db74>&#34;a&#34;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>3</span>, [<span style=color:#e6db74>&#34;x&#34;</span>, <span style=color:#e6db74>&#34;y&#34;</span>, <span style=color:#e6db74>&#34;z&#34;</span>]]
</span></span><span style=display:flex><span>r1 <span style=color:#f92672>=</span> f_df<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;x&#34;</span>)[<span style=color:#e6db74>&#34;z&#34;</span>]<span style=color:#f92672>.</span>sum()
</span></span><span style=display:flex><span>print(r1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>r2 <span style=color:#f92672>=</span> f_df<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;y&#34;</span>)[<span style=color:#e6db74>&#34;z&#34;</span>]<span style=color:#f92672>.</span>sum() <span style=color:#75715e># newly added groupby-sum</span>
</span></span><span style=display:flex><span>print(r2)
</span></span></code></pre></div><p>Since FireDucks performs lazy execution,</p><ol><li><strong>will it process two expensive calls as follows</strong>?</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>r1 <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>  pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>, columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;[&#34;</span>x<span style=color:#e6db74>&#34;, &#34;</span>z<span style=color:#e6db74>&#34;, &#34;</span>a<span style=color:#e6db74>&#34;])</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>loc[df[<span style=color:#e6db74>&#34;a&#34;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>3</span>, [<span style=color:#e6db74>&#34;x&#34;</span>, <span style=color:#e6db74>&#34;z&#34;</span>]]
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;x&#34;</span>)[<span style=color:#e6db74>&#34;z&#34;</span>]<span style=color:#f92672>.</span>sum()
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>r2 <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>  pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;sample_data.parquet&#34;</span>, columns<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;[&#34;</span>y<span style=color:#e6db74>&#34;, &#34;</span>z<span style=color:#e6db74>&#34;, &#34;</span>a<span style=color:#e6db74>&#34;])</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>loc[df[<span style=color:#e6db74>&#34;a&#34;</span>] <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>3</span>, [<span style=color:#e6db74>&#34;y&#34;</span>, <span style=color:#e6db74>&#34;z&#34;</span>]]
</span></span><span style=display:flex><span>    <span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;y&#34;</span>)[<span style=color:#e6db74>&#34;z&#34;</span>]<span style=color:#f92672>.</span>sum()
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><ol start=2><li><strong>Or, will it keep the intermediate filtered result (f_df) alive when processing <code>r1</code></strong>? since it will be used later in the given program when processing <code>r2</code>.</li></ol><p>👉 <strong>The answer is (2)</strong>. It will effectively keep the intermediate results alive that are to be required at some later stage.</p><p>Let&rsquo;s look into the generated IR of the before and after optimization for the modified program:</p><pre tabindex=0><code>2024-12-05 13:26:41.691496: 959435 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main() {
  %t0 = read_parquet(&#39;sample_data.parquet&#39;, [])
  %t1 = project(%t0, [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;])
  %t2 = project(%t0, &#39;a&#39;)
  %t3 = gt.vector.scalar(%t2, 3)
  %t4 = filter(%t1, %t3)
  %t5 = groupby_select_agg(%t4, [&#39;x&#39;], [&#39;sum&#39;], [], [], &#39;z&#39;)
  %v6 = get_shape(%t5)
  return(%t5, %t4, %v6)
}

2024-12-05 13:26:41.692423: 959435 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main() {
  %t0 = read_parquet(&#39;sample_data.parquet&#39;, [&#39;z&#39;, &#39;x&#39;, &#39;a&#39;, &#39;y&#39;])    &lt;- this time it also loads &#34;y&#34; column (as needed for r2)
  %t1 = project(%t0, [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;])
  %t2 = project(%t0, &#39;a&#39;)
  %t3 = gt.vector.scalar(%t2, 3)
  %t4 = filter(%t1, %t3)
  %t5 = groupby_select_agg(%t4, [&#39;x&#39;], [&#39;sum&#39;], [], [], &#39;z&#39;)
  %v6 = get_shape(%t5)
  return(%t5, %t4, %v6)                                              &lt;- this time it also returns filtered dataframe (%t4)
}

2024-12-05 13:26:41.706225: 959435 fireducks/lib/fireducks_core.cc:64] Input IR:
func @main(%arg0: !table) { later use.
  %t1 = groupby_select_agg(%arg0, [&#39;y&#39;], [&#39;sum&#39;], [], [], &#39;z&#39;)
  %v2 = get_shape(%t1)
  return(%t1, %v2)
}

2024-12-05 13:26:41.706721: 959435 fireducks/lib/fireducks_core.cc:73] Optimized IR:
func @main(%arg0: !table) {
  %t1 = groupby_select_agg(%arg0, [&#39;y&#39;], [&#39;sum&#39;], [], [], &#39;z&#39;)
  %v2 = get_shape(%t1)
  return(%t1, %v2)
}
</code></pre><p>The first &ldquo;Optimized IR&rdquo; is generated when processing <code>r1</code>.
This time the compiler identifies the &ldquo;y&rdquo; column and the filtered dataframe (f_df) will be used at later stage when computing <code>r2</code>.
Hence it will also load the &ldquo;y&rdquo; column and keep the intermediate filtered dataframe alive (in other word, cache it) by returning
it (%t4) along with the result of <code>r1</code> (%t5) to avoid further processing at later use.</p><p>👉If you carefully notice the previous IR returned only <code>(%t5, %v6)</code>, when there was no computing related to <code>r2</code> in the input program.</p><p>The second &ldquo;Optimized IR&rdquo; is generated when processing <code>r2</code>.
The input <code>%arg0</code> is the filtered dataframe (%t4) that the compiler kept alive.
Hence only groupby-sum is performed when processing <code>r2</code>.</p><h2 id=how-to-profile>How to profile?</h2><p>You can also check kernel-wise execution time, number of calls etc. by executing the program as follows:</p><pre tabindex=0><code>$ FIREDUCKS_FLAGS=&#34;--trace=3 --trace-file=-&#34; python -mfireducks.pandas sample.py
</code></pre><p>It will produce some profiling output as follows:</p><pre tabindex=0><code class=language-duration data-lang=duration>== kernel ==
fireducks.gt.vector.scalar                           0.004    8.26%          1
fireducks.read_parquet                               0.003    6.02%          1
fireducks.groupby_select_agg                         0.002    3.06%          2
fireducks.to_pandas.frame.metadata                   0.001    1.89%          2
fireducks.filter                                     0.001    1.34%          1
fireducks.project                                    0.000    0.03%          2
</code></pre><p>It can clearly be seen that the method related to read_parquet, filter etc. is called only once.
In order to produce the similar profiling on Jupyter notebook, you can use the cell magic: <code>%%fireducks.profile</code>.</p><h2 id=wrapping-up>Wrapping-up</h2><p>Thank you for your time in reading this article.
In case you have any queries or have an issue to report, please feel free to get in touch with us in any of your prefered channel mentioned below:</p><ul><li>🦆github : <a href=https://github.com/fireducks-dev/fireducks/issues/new>https://github.com/fireducks-dev/fireducks/issues/new</a></li><li>📧mail : <a href=mailto:contact@fireducks.jp.nec.com>contact@fireducks.jp.nec.com</a></li><li>🤝slack : <a href=https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w>https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w</a></li></ul><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/posts/beginner_guide/ aria-label="Previous - What to do when FireDucks is slow" class="btn btn-primary"><span class=me-1>←</span>Previous</a></li><li><a href=/posts/lazy_execution_offering_part1/ aria-label="Next - Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1" class="btn btn-primary">Next<span class=ms-1>→</span></a></li></ul></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="Post issues on GitHub issues" aria-label="Post issues on GitHub issues"><a target=_blank rel=noopener href=https://github.com/fireducks-dev/fireducks aria-label="Post issues on GitHub issues"><i class="fa-brands fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Send an e-mail to us" aria-label="Send an e-mail to us"><a target=_blank rel=noopener href=mailto:contact@fireducks.jp.nec.com aria-label="Send an e-mail to us"><i class="fa-solid fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Follow us in X" aria-label="Follow us in X"><a target=_blank rel=noopener href=https://x.com/fireducksdev aria-label="Follow us in X"><i class="fa-brands fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Join us on Slack" aria-label="Join us on Slack"><a target=_blank rel=noopener href=https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w aria-label="Join us on Slack"><i class="fa-brands fa-slack"></i></a></li></ul></div><div class="col-6 col-sm-4 text-end text-xs-center order-sm-3"></div><div class="td-footer__copyright-etc col-12 col-sm-4 text-center py-2 order-sm-2"><span>&copy; 2024 FireDucks Dev Team All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.350b703200e2632331b6ab5a6c71195d176b52e89c9b70db7c43764d40b28d92.js integrity="sha256-NQtwMgDiYyMxtqtabHEZXRdrUuicm3DbfEN2TUCyjZI=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.f724d3de49218995223b7316aa2e53e2b34bf42026bf399ebb21bb02212402d1.js integrity="sha256-9yTT3kkhiZUiO3MWqi5T4rNL9CAmvzmeuyG7AiEkAtE=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>