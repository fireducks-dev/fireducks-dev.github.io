<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3 | FireDucks</title>
<meta name=description content="In the previous article, we have talked about how FireDucks lazy-execution can take care of the caching for the intermediate results in order to avoid recomputation of an expensive operation. In today&amp;rsquo;s article, we will focus on the efficient data flow optimization by its JIT compiler. We will first try to understand some best practices when performing large-scale data analysis in pandas and then discuss how those can be automatically taken care by FireDucks lazy execution model."><meta property="og:title" content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3"><meta property="og:description" content="In the previous article, we have talked about how FireDucks lazy-execution can take care of the caching for the intermediate results in order to avoid recomputation of an expensive operation. In today&rsquo;s article, we will focus on the efficient data flow optimization by its JIT compiler. We will first try to understand some best practices when performing large-scale data analysis in pandas and then discuss how those can be automatically taken care by FireDucks lazy execution model."><meta property="og:type" content="article"><meta property="og:url" content="https://fireducks-dev.github.io/posts/data_flow_optimization/"><meta property="og:image" content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-31T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-31T00:00:00+00:00"><meta itemprop=name content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3"><meta itemprop=description content="In the previous article, we have talked about how FireDucks lazy-execution can take care of the caching for the intermediate results in order to avoid recomputation of an expensive operation. In today&rsquo;s article, we will focus on the efficient data flow optimization by its JIT compiler. We will first try to understand some best practices when performing large-scale data analysis in pandas and then discuss how those can be automatically taken care by FireDucks lazy execution model."><meta itemprop=datePublished content="2025-01-31T00:00:00+00:00"><meta itemprop=dateModified content="2025-01-31T00:00:00+00:00"><meta itemprop=wordCount content="1500"><meta itemprop=image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta name=twitter:title content="Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3"><meta name=twitter:description content="In the previous article, we have talked about how FireDucks lazy-execution can take care of the caching for the intermediate results in order to avoid recomputation of an expensive operation. In today&rsquo;s article, we will focus on the efficient data flow optimization by its JIT compiler. We will first try to understand some best practices when performing large-scale data analysis in pandas and then discuss how those can be automatically taken care by FireDucks lazy execution model."><link rel=preload href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css as=style><link href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.3.min.js integrity="sha512-STof4xm1wgkfm7heWqFJVn58Hm3EtS31XFaagaa8VMReCXAkQnJZ+jEy8PCC/iT18dFy95WcExNHFTqLyp72eQ==" crossorigin=anonymous></script></head><body class="td-page td-blog"><header><nav class="td-navbar navbar-dark js-navbar-scroll"><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>FireDucks</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/docs/get-started><span>Get Started</span></a></li><li class=nav-item><a class=nav-link href=/docs/user-guide/01-intro/><span>Docs</span></a></li><li class=nav-item><a class=nav-link href=/posts><span>Blogs</span></a></li><li class=nav-item><a class=nav-link href=/docs/benchmarks><span>Benchmarks</span></a></li><li class=nav-item><a class=nav-link href=/talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/fireducks-dev/fireducks/issues target=_blank rel=noopener><span>Report Issue</span></a></li><li class=nav-item><a class=nav-link href=/docs/about-us><span>About Us</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="td-sidebar-nav collapse" id=td-section-nav><div class="td-sidebar-nav__section nav-item dropdown d-block d-lg-none"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></div><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-posts-li><a href=/posts/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-posts><span>Posts</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-postsdata_flow_optimization-li><a href=/posts/data_flow_optimization/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-postsdata_flow_optimization><span class=td-sidebar-nav-active-item>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-12-26-time-pitfalls-li><a href=/posts/2024-12-26-time-pitfalls/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-12-26-time-pitfalls><span>Pitfalls of Time Measurement for FireDucks with %%time in Notebooks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-12-20-trace-li><a href=/posts/2024-12-20-trace/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-12-20-trace><span>How to take traces in FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-12-19-araki-en-li><a href=/posts/2024-12-19-araki-en/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-12-19-araki-en><span>Ensuring compatibility with pandas in the GPU version of FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postscudf_vs_fireducks-li><a href=/posts/cudf_vs_fireducks/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postscudf_vs_fireducks><span>Exploring performance benefits of FireDucks over cuDF</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241217_liveness_analysis-li><a href=/posts/20241217_liveness_analysis/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241217_liveness_analysis><span>Cache or Eliminate? How FireDucks increase opportunity of optimization</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241206_update_polars-tpch-li><a href=/posts/20241206_update_polars-tpch/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241206_update_polars-tpch><span>How to run polars-tpch benchmark with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postslazy_execution_offering_part1-li><a href=/posts/lazy_execution_offering_part1/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postslazy_execution_offering_part1><span>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsefficient_caching-li><a href=/posts/efficient_caching/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsefficient_caching><span>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsbeginner_guide-li><a href=/posts/beginner_guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsbeginner_guide><span>What to do when FireDucks is slow</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20240919-workshop-li><a href=/posts/20240919-workshop/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20240919-workshop><span>Workshop at Bangalore, India</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postssourav_cse_demo_20240701-li><a href=/posts/sourav_cse_demo_20240701/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postssourav_cse_demo_20240701><span>Have you ever thought of speeding up your data analysis in pandas with a compiler?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-05-08-medium-li><a href=https://medium.com/@fireducks/introduction-to-fireducks-get-performance-beyond-pandas-with-zero-learning-cost-8694d4eab9c6 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-05-08-medium><i class="fa fa-external-link"></i><span>Introduction to FireDucks: Get performance beyond pandas with zero learning cost!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci4-li><a href=https://medium.com/@ashu.thakur/backtesting-trading-strategies-with-ease-an-excursion-with-fireducks-e771b701dcd5 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci4><i class="fa fa-external-link"></i><span>Backtesting Trading Strategies with Ease: An excursion with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci3-li><a href=https://medium.com/@ashu.thakur/fireducks-diving-into-api-compatibility-with-pandas-e8f4111c2f98 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci3><i class="fa fa-external-link"></i><span>FireDucks: Diving into API Compatibility with Pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci2-li><a href=https://medium.com/@ashu.thakur/choosing-your-data-champion-a-side-by-side-look-at-fireducks-and-polars-51c144fd4689 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci2><i class="fa fa-external-link"></i><span>Choosing Your Data Champion: A Side-by-Side Look at FireDucks and Polars</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci1-li><a href=https://medium.com/@ashu.thakur/boosting-data-analysis-with-fireducks-0066ad25966d target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci1><i class="fa fa-external-link"></i><span>Boosting Data Analysis with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231216-sourav-li><a href=https://qiita.com/qsourav/items/5c06426fae5f3df0244c target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231216-sourav><i class="fa fa-external-link"></i><span>A hidden fact you must know when working with pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231211-sourav-li><a href=https://qiita.com/qsourav/items/1c1fe15faa06fce1dd33 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231211-sourav><i class="fa fa-external-link"></i><span>Tricks to improve computational performance of JOIN operation more than 10x</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231207-sourav-li><a href=https://qiita.com/qsourav/items/e87f25c4b307391d784a target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231207-sourav><i class="fa fa-external-link"></i><span>FireDucks - An economical and environment-friendly high-performance solution for your complex Data Analysis</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231206-sourav-li><a href=https://qiita.com/qsourav/items/cc4ca4c8d4668ce617bf target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231206-sourav><i class="fa fa-external-link"></i><span>One thing you might be doing wrong in pandas!!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsest-li><a href=/posts/est/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsest><span>Acceleration technology inside FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsimporthook-li><a href=/posts/importhook/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsimporthook><span>Import hooks: how to use FireDucks without modifying your programs</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsnes_taxi-li><a href=/posts/nes_taxi/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsnes_taxi><span>Using Python's fast data frame library FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-poststtdc-li><a href=https://www.nec.com/en/global/rd/technologies/202312/index.html target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-poststtdc><i class="fa fa-external-link"></i><span>Application example: Spicy MINT at Toyota Technical Development Corporation</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#challenge-1>Challenge #1</a></li><li><a href=#challenge-2>Challenge #2</a></li><li><a href=#lets-follow-these-best-practices>Let&rsquo;s follow these best practices</a></li><li><a href=#case-study>Case Study</a></li><li><a href=#fireducks-offerings>FireDucks Offerings</a></li><li><a href=#wrapping-up>Wrapping-up</a></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><a class=td-rss-button title=RSS href=https://fireducks-dev.github.io/posts/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #3</h1><div class="td-byline mb-4">By <b>Sourav Saha</b> |
<time datetime=2025-01-31 class=text-muted>Friday, January 31, 2025</time></div><header class=article-meta></header><p>In the previous <a href=../efficient_caching>article</a>, we have talked about how FireDucks lazy-execution can take care of the
caching for the intermediate results in order to avoid recomputation of an expensive operation.
In today&rsquo;s article, we will focus on the <strong>efficient data flow optimization</strong> by its JIT compiler.
We will first try to understand some best practices when performing large-scale data analysis in pandas
and then discuss how those can be automatically taken care by FireDucks lazy execution model.</p><h2 id=challenge-1>Challenge #1</h2><p>Let&rsquo;s consider the following two queries solving the same problem: <em>Find top 2 &ldquo;A&rdquo; based on the &ldquo;B&rdquo; column</em>.</p><p>👉 <strong>Can you guess which one is better from performance point of view?</strong></p><p>(1) version 1</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>res <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;B&#34;</span>)[<span style=color:#e6db74>&#34;A&#34;</span>]<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><p>(2) version 2</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tmp <span style=color:#f92672>=</span> df[[<span style=color:#e6db74>&#34;A&#34;</span>, <span style=color:#e6db74>&#34;B&#34;</span>]]
</span></span><span style=display:flex><span>res <span style=color:#f92672>=</span> tmp<span style=color:#f92672>.</span>sort_values(by<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;B&#34;</span>)[<span style=color:#e6db74>&#34;A&#34;</span>]<span style=color:#f92672>.</span>head(<span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><p>Well, when we conducted this quiz in one of the recent Data Science events,
45% of the participants answered the first one is more efficient, while the remaining 55% answered the second one is more efficient.</p><p>Congratulations, if your answer is (2) as well. 👏</p><p>In real world situation the target data might have many columns and when we invoked sort operation on <code>df</code> instance,
it performed sorting the entire data involving a significant cost in terms of memory and computational power.</p><p>As depicted in the following diagram, if the data have columns from &lsquo;a&rsquo; to &lsquo;j&rsquo;, when performing the first query,
it also sorts the column &lsquo;c&rsquo; to &lsquo;j&rsquo; that is not of our interest. Hence, it is a wise call to create a view of
the part of data that is of our interest (as shown in the following figure) before performing an computationally intensive operation
like sort, groupby, join etc. At this we can save significant amount of runtime memory and computational time.
Such optimization is typically known as <code>projection pushdown</code>.
<img src=pushdown_projection.png alt="projection pushdown example"></p><h2 id=challenge-2>Challenge #2</h2><p>Let&rsquo;s now consider another example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>m <span style=color:#f92672>=</span> employee<span style=color:#f92672>.</span>merge(country, on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;C_Code&#34;</span>)
</span></span><span style=display:flex><span>f <span style=color:#f92672>=</span> m[m[<span style=color:#e6db74>&#34;Gender&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;Male&#34;</span>]
</span></span><span style=display:flex><span>r <span style=color:#f92672>=</span> f<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;C_Name&#34;</span>)[<span style=color:#e6db74>&#34;E_Name&#34;</span>]<span style=color:#f92672>.</span>count()
</span></span></code></pre></div><p>The following diagram illustrates the operations that takes place while executing the query above:
<img src=illustration1.png alt="country-wise count of male employees"></p><p>👉 <strong>Can you guess the performance bottleneck involved in the above query?</strong></p><p>Probably you guessed it correct!!</p><p>The query wants to analyze only the <code>male</code> employees.
Then why to include all the employees at the very first step while joining the two dataframes <code>employee</code> and <code>country</code>?
We could simply filter only the male employees from the <code>employee</code> data and
perform the rest of the operations like merge, groupby etc. on the filtered result as shown below.
At this we could save significant execution time and memory during the expensive merge operation.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>f <span style=color:#f92672>=</span> employee[employee[<span style=color:#e6db74>&#34;Gender&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;Male&#34;</span>]
</span></span><span style=display:flex><span>m <span style=color:#f92672>=</span> f<span style=color:#f92672>.</span>merge(country, on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;C_Code&#34;</span>)
</span></span><span style=display:flex><span>r <span style=color:#f92672>=</span> m<span style=color:#f92672>.</span>groupby(<span style=color:#e6db74>&#34;C_Name&#34;</span>)[<span style=color:#e6db74>&#34;E_Name&#34;</span>]<span style=color:#f92672>.</span>count()
</span></span></code></pre></div><p>Such optimization is typically known as <code>predicate pushdown</code>.
<img src=predicate_pushdown.png alt="predicate pushdown example"></p><h2 id=lets-follow-these-best-practices>Let&rsquo;s follow these best practices</h2><p>When dealing with large-scale data, sometime we might not be interested on all part of the data.
Hence, its always the best practice to reduce the scope of your data before applying an
expensive operation on it to reduce a significant amount of runtime memory and computational time.</p><ul><li>When it is known that you are going to perform an operation that involves only some of the columns,
it is recommended to project the target columns first to reduce it in the horizontal direction.</li><li>Again, if your operation targets only some selected rows of the data,
it is recommended to filter the target rows before performing the operation to reduce it further in the vertical direction.</li></ul><p>For example, let&rsquo;s consider the below example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#34;A&#34;</span>)
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>query(<span style=color:#e6db74>&#34;B &gt; 1&#34;</span>)[<span style=color:#e6db74>&#34;E&#34;</span>]
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><p>Let&rsquo;s consider the data with following color codes, where the expected sorted order is: <strong>yellow, red, green, blue.</strong></p><p>Also, let&rsquo;s assume B=1 for darker shade and B=2 for lighter shade.
The flow of the above operation will be as follows:
<img src=illustration2.png alt="sample data flow"></p><p>As you can see the columns <code>C</code> and <code>D</code> have been used in all the first three steps, but they have never been required in the final result.
Also, the sort operation is performed on all the rows of the data, whereas we are only interested in the data of the lighter shades.</p><p>Hence, the optimized data flow could be as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>df<span style=color:#f92672>.</span>loc[:, [<span style=color:#e6db74>&#34;A&#34;</span>, <span style=color:#e6db74>&#34;B&#34;</span>, <span style=color:#e6db74>&#34;E&#34;</span>]]
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>query(<span style=color:#e6db74>&#34;B &gt; 1&#34;</span>)
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>sort_values(<span style=color:#e6db74>&#34;A&#34;</span>)[<span style=color:#e6db74>&#34;E&#34;</span>]
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>2</span>)
</span></span></code></pre></div><p>It efficiently reduces the data in the horizontal (applying projection pushdown) and vertical (applying predicate pushdown) direction,
before applying the expensive sort operation as depicted follows:
<img src=illustration3.png alt="sample optimized data flow"></p><h2 id=case-study>Case Study</h2><p>Now let&rsquo;s understand how such optimization can be useful in real world situations.</p><p>The <a href=https://www.tpc.org/tpch/>TPC-H</a> is a decision support benchmark that consists of a suite of business-oriented ad-hoc queries and concurrent data modifications.
We will use <a href="https://www.tpc.org/TPC_Documents_Current_Versions/pdf/TPC-H_v3.0.1.pdf#page=33">Query-3</a> as an example in this demonstration that deals with three large tables,
namely <code>lineitem</code>, <code>customer</code>, and <code>orders</code> with complex join, groupby, sort etc.</p><p>The original query was written in SQL. We can realize the following pandas equaivalent of the same query:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>q3</span>():
</span></span><span style=display:flex><span>    (
</span></span><span style=display:flex><span>        pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;customer.parquet&#34;</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>merge(pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;orders.parquet&#34;</span>), left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;c_custkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_custkey&#34;</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>merge(pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;lineitem.parquet&#34;</span>), left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_orderkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l_orderkey&#34;</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>pipe(<span style=color:#66d9ef>lambda</span> df: df[df[<span style=color:#e6db74>&#34;c_mktsegment&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;BUILDING&#34;</span>])
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>pipe(<span style=color:#66d9ef>lambda</span> df: df[df[<span style=color:#e6db74>&#34;o_orderdate&#34;</span>] <span style=color:#f92672>&lt;</span> datetime<span style=color:#f92672>.</span>date(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)])
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>pipe(<span style=color:#66d9ef>lambda</span> df: df[df[<span style=color:#e6db74>&#34;l_shipdate&#34;</span>] <span style=color:#f92672>&gt;</span> datetime<span style=color:#f92672>.</span>date(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)])
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>assign(revenue<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> df: df[<span style=color:#e6db74>&#34;l_extendedprice&#34;</span>] <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> df[<span style=color:#e6db74>&#34;l_discount&#34;</span>]))
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>groupby([<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>], as_index<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>agg({<span style=color:#e6db74>&#34;revenue&#34;</span>: <span style=color:#e6db74>&#34;sum&#34;</span>})[[<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>]]
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>sort_values([<span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>], ascending<span style=color:#f92672>=</span>[<span style=color:#66d9ef>False</span>, <span style=color:#66d9ef>True</span>])
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>reset_index(drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)            
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>to_parquet(<span style=color:#e6db74>&#34;result.parquet&#34;</span>)     
</span></span><span style=display:flex><span>    )
</span></span></code></pre></div><p>The above implementation doesn&rsquo;t take care of the &ldquo;best practices&rdquo;.
It loads the entire data from all the three tables and directly merge them to construct a large table
before performing rest of the filter, groupby etc. operations as required for the query.</p><p>When we executed the above program in pandas for a scale-factor 10,
it <strong>took around 203 seconds and the peak memory consumption was around 56 GB</strong>.
<img src=q3_pandas.png alt="pandas q3 metrics"></p><p>Let&rsquo;s now implement the best-practices discussed in the previous section to manually optimize the query as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>optimized_q3</span>():
</span></span><span style=display:flex><span>    <span style=color:#75715e># load only required columns from respective tables</span>
</span></span><span style=display:flex><span>    req_customer_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;c_custkey&#34;</span>, <span style=color:#e6db74>&#34;c_mktsegment&#34;</span>] <span style=color:#75715e># (2/8)</span>
</span></span><span style=display:flex><span>    req_lineitem_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;l_shipdate&#34;</span>, <span style=color:#e6db74>&#34;l_extendedprice&#34;</span>, <span style=color:#e6db74>&#34;l_discount&#34;</span>] <span style=color:#75715e>#(4/16)</span>
</span></span><span style=display:flex><span>    req_orders_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;o_custkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>] <span style=color:#75715e>#(4/9)</span>
</span></span><span style=display:flex><span>    customer <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;customer.parquet&#34;</span>, columns <span style=color:#f92672>=</span> req_customer_cols)
</span></span><span style=display:flex><span>    lineitem <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;lineitem.parquet&#34;</span>, columns <span style=color:#f92672>=</span> req_lineitem_cols)
</span></span><span style=display:flex><span>    orders <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(<span style=color:#e6db74>&#34;orders.parquet&#34;</span>, columns <span style=color:#f92672>=</span> req_orders_cols)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#75715e># advanced-filter: to reduce scope of “customer” table to be processed</span>
</span></span><span style=display:flex><span>    f_cust <span style=color:#f92672>=</span> customer[customer[<span style=color:#e6db74>&#34;c_mktsegment&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;BUILDING&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># advanced-filter: to reduce scope of “orders” table to be processed</span>
</span></span><span style=display:flex><span>    f_ord <span style=color:#f92672>=</span> orders[orders[<span style=color:#e6db74>&#34;o_orderdate&#34;</span>] <span style=color:#f92672>&lt;</span> datetime<span style=color:#f92672>.</span>date(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># advanced-filter: to reduce scope of “lineitem” table to be processed</span>
</span></span><span style=display:flex><span>    f_litem <span style=color:#f92672>=</span> lineitem[lineitem[<span style=color:#e6db74>&#34;l_shipdate&#34;</span>] <span style=color:#f92672>&gt;</span> datetime<span style=color:#f92672>.</span>date(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    (
</span></span><span style=display:flex><span>        f_cust<span style=color:#f92672>.</span>merge(f_ord, left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;c_custkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_custkey&#34;</span>)
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>merge(f_litem, left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_orderkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l_orderkey&#34;</span>)
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>assign(revenue<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> df: df[<span style=color:#e6db74>&#34;l_extendedprice&#34;</span>] <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> df[<span style=color:#e6db74>&#34;l_discount&#34;</span>]))
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>groupby([<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>], as_index<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>agg({<span style=color:#e6db74>&#34;revenue&#34;</span>: <span style=color:#e6db74>&#34;sum&#34;</span>})[[<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>]]
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>sort_values([<span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>], ascending<span style=color:#f92672>=</span>[<span style=color:#66d9ef>False</span>, <span style=color:#66d9ef>True</span>])
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>reset_index(drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>              <span style=color:#f92672>.</span>to_parquet(<span style=color:#e6db74>&#34;result.parquet&#34;</span>)
</span></span><span style=display:flex><span>    )
</span></span></code></pre></div><p>Instead of loading all the 8 columns from the <code>customer</code> table,
all the 16 columns from the <code>lineitem</code> table,
and all the 9 columns from the <code>orders</code> table,
it loads only the target columns that would be required to implement the query
by reducing the data in the horizontal direction (applying projection pushdown).</p><p>Also, since we need only a specific rows from these tables based on the given conditions,
we performed an early filtration on the loaded data to reduce it further in the vertical direction (applying predicate pushdown).</p><p>When we executed the above optimized implementation using pandas for a scale-factor 10,
it <strong>took around 13 seconds and the peak memory consumption was around 5.5 GB</strong>.
<img src=opt_q3_pandas.png alt="pandas optimized-q3 metrics"></p><p>From this experiment, it is quite evident that an optimized implementation of a pandas program
can itself improve its performance and memory consumption to a great extent.</p><p>👉 <strong>Q. Can we automate such optimization such that one can focus more on in-depth data analysis relying on some tool or library for such expert-level optimization?</strong></p><p>The answer is <strong>&ldquo;YES&rdquo;</strong>. You can rely on FireDucks for such optimization for sure. 🚀</p><h2 id=fireducks-offerings>FireDucks Offerings</h2><p>While being highly compatible with pandas,
FireDucks can perform such expert-level optimization automatically when using its default lazy execution mode.</p><p>In order to verify the same, we have executed the methods as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># to use FireDucks for all the processings</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> fireducks.pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>q3()
</span></span><span style=display:flex><span>optimized_q3()
</span></span></code></pre></div><p>And the execution could be completed within 4-5 seconds for both these cases showing FireDucks strength
in performing such optimizations automatically even when the program itself doesn&rsquo;t take care of it (as in q3).</p><p>We have used <code>v2-8 TPU</code> instance from Google Colab for this evaluation and here is the finding in detail:</p><table><thead><tr><th style=text-align:left></th><th style=text-align:right>(pandas, exec_time (s))</th><th style=text-align:right>(pandas, memory (GB))</th><th style=text-align:right>(FireDucks, exec_time (s))</th><th style=text-align:right>(FireDucks, memory (GB))</th></tr></thead><tbody><tr><td style=text-align:left>q3</td><td style=text-align:right>203.18</td><td style=text-align:right>56</td><td style=text-align:right>4.24</td><td style=text-align:right>3.3</td></tr><tr><td style=text-align:left>optimized_q3</td><td style=text-align:right>12.97</td><td style=text-align:right>5.5</td><td style=text-align:right>4.81</td><td style=text-align:right>3.4</td></tr></tbody></table><p>You might like to try this <a href=https://colab.research.google.com/github/fireducks-dev/fireducks/blob/main/notebooks/tpch-query3-pandas-fireducks-cudf.ipynb>notebook</a>
on Google colab to reproduce the same.</p><h2 id=wrapping-up>Wrapping-up</h2><p>Thank you for your time in reading this article.
We have discussed a couple of best practices that one should follow when performing large-scale data analysis in pandas
and how FireDucks can automatically implement the same. The experimental result shows when switching from pandas to FireDucks,
it can improve performance of a poorly written program by 48x (203.18 s -> 4.24 s)
while reducing the memory consumption by 17x (56 GB -> 3.3 GB).</p><p>In case you have any queries or have an issue to report,
please feel free to get in touch with us in any of your prefered channel mentioned below:</p><ul><li>🦆github : <a href=https://github.com/fireducks-dev/fireducks/issues/new>https://github.com/fireducks-dev/fireducks/issues/new</a></li><li>📧mail : <a href=mailto:contact@fireducks.jp.nec.com>contact@fireducks.jp.nec.com</a></li><li>🤝slack : <a href=https://join.slack.com/t/fireducks/shared_invite/zt-34qpdgr6q-_iWdIoZW4l_hGhljKS0pyg>https://join.slack.com/t/fireducks/shared_invite/zt-34qpdgr6q-_iWdIoZW4l_hGhljKS0pyg</a></li></ul><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/posts/2024-12-26-time-pitfalls/ aria-label="Previous - Pitfalls of Time Measurement for FireDucks with %%time in Notebooks" class="btn btn-primary"><span class=me-1>←</span>Previous</a></li><li><a class="btn btn-primary disabled">Next<span class=ms-1>→</span></a></li></ul></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="Post issues on GitHub issues" aria-label="Post issues on GitHub issues"><a target=_blank rel=noopener href=https://github.com/fireducks-dev/fireducks aria-label="Post issues on GitHub issues"><i class="fa-brands fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Send an e-mail to us" aria-label="Send an e-mail to us"><a target=_blank rel=noopener href=mailto:contact@fireducks.jp.nec.com aria-label="Send an e-mail to us"><i class="fa-solid fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Follow us in X" aria-label="Follow us in X"><a target=_blank rel=noopener href=https://x.com/fireducksdev aria-label="Follow us in X"><i class="fa-brands fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Join us on Slack" aria-label="Join us on Slack"><a target=_blank rel=noopener href=https://join.slack.com/t/fireducks/shared_invite/zt-34qpdgr6q-_iWdIoZW4l_hGhljKS0pyg aria-label="Join us on Slack"><i class="fa-brands fa-slack"></i></a></li></ul></div><div class="col-6 col-sm-4 text-end text-xs-center order-sm-3"></div><div class="td-footer__copyright-etc col-12 col-sm-4 text-center py-2 order-sm-2"><span>&copy; 2025 FireDucks Dev Team All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.350b703200e2632331b6ab5a6c71195d176b52e89c9b70db7c43764d40b28d92.js integrity="sha256-NQtwMgDiYyMxtqtabHEZXRdrUuicm3DbfEN2TUCyjZI=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.f724d3de49218995223b7316aa2e53e2b34bf42026bf399ebb21bb02212402d1.js integrity="sha256-9yTT3kkhiZUiO3MWqi5T4rNL9CAmvzmeuyG7AiEkAtE=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>