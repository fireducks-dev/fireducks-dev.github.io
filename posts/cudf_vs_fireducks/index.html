<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Exploring performance benefits of FireDucks over cuDF | FireDucks</title>
<meta name=description content="Research says that Data scientists spend about 45% of their time on data preparation tasks, including loading (19%) and cleaning (26%) the data. Pandas is one of the most popular python libraries for tabular data processing because of its diverse utilities and large community support. However, due to its performance issue with the large-scale data processing, there is a strong need for high-performance data frame libraries for the community. Although there are many alternatives available at this moment, due to compatibility issues with pandas some of those either compel a user to learn completely new APIs (incurring migration cost) or to switch to a more efficient computational systems, like GPU etc."><meta property="og:title" content="Exploring performance benefits of FireDucks over cuDF"><meta property="og:description" content="Research says that Data scientists spend about 45% of their time on data preparation tasks, including loading (19%) and cleaning (26%) the data. Pandas is one of the most popular python libraries for tabular data processing because of its diverse utilities and large community support. However, due to its performance issue with the large-scale data processing, there is a strong need for high-performance data frame libraries for the community. Although there are many alternatives available at this moment, due to compatibility issues with pandas some of those either compel a user to learn completely new APIs (incurring migration cost) or to switch to a more efficient computational systems, like GPU etc."><meta property="og:type" content="article"><meta property="og:url" content="https://fireducks-dev.github.io/posts/cudf_vs_fireducks/"><meta property="og:image" content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-18T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-18T00:00:00+00:00"><meta itemprop=name content="Exploring performance benefits of FireDucks over cuDF"><meta itemprop=description content="Research says that Data scientists spend about 45% of their time on data preparation tasks, including loading (19%) and cleaning (26%) the data. Pandas is one of the most popular python libraries for tabular data processing because of its diverse utilities and large community support. However, due to its performance issue with the large-scale data processing, there is a strong need for high-performance data frame libraries for the community. Although there are many alternatives available at this moment, due to compatibility issues with pandas some of those either compel a user to learn completely new APIs (incurring migration cost) or to switch to a more efficient computational systems, like GPU etc."><meta itemprop=datePublished content="2024-12-18T00:00:00+00:00"><meta itemprop=dateModified content="2024-12-18T00:00:00+00:00"><meta itemprop=wordCount content="1364"><meta itemprop=image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta itemprop=keywords content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://fireducks-dev.github.io/images/fireducks_1200x630.png"><meta name=twitter:title content="Exploring performance benefits of FireDucks over cuDF"><meta name=twitter:description content="Research says that Data scientists spend about 45% of their time on data preparation tasks, including loading (19%) and cleaning (26%) the data. Pandas is one of the most popular python libraries for tabular data processing because of its diverse utilities and large community support. However, due to its performance issue with the large-scale data processing, there is a strong need for high-performance data frame libraries for the community. Although there are many alternatives available at this moment, due to compatibility issues with pandas some of those either compel a user to learn completely new APIs (incurring migration cost) or to switch to a more efficient computational systems, like GPU etc."><link rel=preload href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css as=style><link href=/scss/main.min.2404b01c5fb65f0b4d76f0c632723d405f2faf20557f5aeff94d8efb2e91ec8b.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.3.min.js integrity="sha512-STof4xm1wgkfm7heWqFJVn58Hm3EtS31XFaagaa8VMReCXAkQnJZ+jEy8PCC/iT18dFy95WcExNHFTqLyp72eQ==" crossorigin=anonymous></script></head><body class="td-page td-blog"><header><nav class="td-navbar navbar-dark js-navbar-scroll"><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"></span><span class=navbar-brand__name>FireDucks</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=/docs/get-started><span>Get Started</span></a></li><li class=nav-item><a class=nav-link href=/docs/user-guide/01-intro/><span>Docs</span></a></li><li class=nav-item><a class=nav-link href=/posts><span>Blogs</span></a></li><li class=nav-item><a class=nav-link href=/docs/benchmarks><span>Benchmarks</span></a></li><li class=nav-item><a class=nav-link href=/talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=https://github.com/fireducks-dev/fireducks/issues target=_blank rel=noopener><span>Report Issue</span></a></li><li class=nav-item><a class=nav-link href=/docs/about-us><span>About Us</span></a></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></li></ul></div><div class="d-none d-lg-block"></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type=button data-bs-toggle=collapse data-bs-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="td-sidebar-nav collapse" id=td-section-nav><div class="td-sidebar-nav__section nav-item dropdown d-block d-lg-none"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=/ja/>Japanese</a></li></ul></div></div><ul class="td-sidebar-nav__section pe-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-posts-li><a href=/posts/ class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-posts><span>Posts</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-12-26-time-pitfalls-li><a href=/posts/2024-12-26-time-pitfalls/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-12-26-time-pitfalls><span>Pitfalls of Time Measurement for FireDucks with %%time in Notebooks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-12-20-trace-li><a href=/posts/2024-12-20-trace/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-12-20-trace><span>How to take traces in FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-12-19-araki-en-li><a href=/posts/2024-12-19-araki-en/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-12-19-araki-en><span>Ensuring compatibility with pandas in the GPU version of FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-postscudf_vs_fireducks-li><a href=/posts/cudf_vs_fireducks/ class="align-left ps-0 active td-sidebar-link td-sidebar-link__page" id=m-postscudf_vs_fireducks><span class=td-sidebar-nav-active-item>Exploring performance benefits of FireDucks over cuDF</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241217_liveness_analysis-li><a href=/posts/20241217_liveness_analysis/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241217_liveness_analysis><span>Cache or Eliminate? How FireDucks increase opportunity of optimization</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20241206_update_polars-tpch-li><a href=/posts/20241206_update_polars-tpch/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20241206_update_polars-tpch><span>How to run polars-tpch benchmark with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postslazy_execution_offering_part1-li><a href=/posts/lazy_execution_offering_part1/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postslazy_execution_offering_part1><span>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #1</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsefficient_caching-li><a href=/posts/efficient_caching/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsefficient_caching><span>Unveiling the Optimization Benefit of FireDucks Lazy Execution: Part #2</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsbeginner_guide-li><a href=/posts/beginner_guide/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsbeginner_guide><span>What to do when FireDucks is slow</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20240919-workshop-li><a href=/posts/20240919-workshop/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20240919-workshop><span>Workshop at Bangalore, India</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postssourav_cse_demo_20240701-li><a href=/posts/sourav_cse_demo_20240701/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postssourav_cse_demo_20240701><span>Have you ever thought of speeding up your data analysis in pandas with a compiler?</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts2024-05-08-medium-li><a href=https://medium.com/@fireducks/introduction-to-fireducks-get-performance-beyond-pandas-with-zero-learning-cost-8694d4eab9c6 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts2024-05-08-medium><i class="fa fa-external-link"></i><span>Introduction to FireDucks: Get performance beyond pandas with zero learning cost!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci4-li><a href=https://medium.com/@ashu.thakur/backtesting-trading-strategies-with-ease-an-excursion-with-fireducks-e771b701dcd5 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci4><i class="fa fa-external-link"></i><span>Backtesting Trading Strategies with Ease: An excursion with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci3-li><a href=https://medium.com/@ashu.thakur/fireducks-diving-into-api-compatibility-with-pandas-e8f4111c2f98 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci3><i class="fa fa-external-link"></i><span>FireDucks: Diving into API Compatibility with Pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci2-li><a href=https://medium.com/@ashu.thakur/choosing-your-data-champion-a-side-by-side-look-at-fireducks-and-polars-51c144fd4689 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci2><i class="fa fa-external-link"></i><span>Choosing Your Data Champion: A Side-by-Side Look at FireDucks and Polars</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsneci1-li><a href=https://medium.com/@ashu.thakur/boosting-data-analysis-with-fireducks-0066ad25966d target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsneci1><i class="fa fa-external-link"></i><span>Boosting Data Analysis with FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231216-sourav-li><a href=https://qiita.com/qsourav/items/5c06426fae5f3df0244c target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231216-sourav><i class="fa fa-external-link"></i><span>A hidden fact you must know when working with pandas</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231211-sourav-li><a href=https://qiita.com/qsourav/items/1c1fe15faa06fce1dd33 target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231211-sourav><i class="fa fa-external-link"></i><span>Tricks to improve computational performance of JOIN operation more than 10x</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231207-sourav-li><a href=https://qiita.com/qsourav/items/e87f25c4b307391d784a target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231207-sourav><i class="fa fa-external-link"></i><span>FireDucks - An economical and environment-friendly high-performance solution for your complex Data Analysis</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-posts20231206-sourav-li><a href=https://qiita.com/qsourav/items/cc4ca4c8d4668ce617bf target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-posts20231206-sourav><i class="fa fa-external-link"></i><span>One thing you might be doing wrong in pandas!!</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsest-li><a href=/posts/est/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsest><span>Acceleration technology inside FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsimporthook-li><a href=/posts/importhook/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsimporthook><span>Import hooks: how to use FireDucks without modifying your programs</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-postsnes_taxi-li><a href=/posts/nes_taxi/ class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-postsnes_taxi><span>Using Python's fast data frame library FireDucks</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-poststtdc-li><a href=https://www.nec.com/en/global/rd/technologies/202312/index.html target=_blank rel=noopener class="align-left ps-0 td-sidebar-link td-sidebar-link__page" id=m-poststtdc><i class="fa fa-external-link"></i><span>Application example: Spicy MINT at Toyota Technical Development Corporation</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ms-2 pb-1 pt-2 mb-0"></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#fireducks-vs-cudf>FireDucks vs. cuDF</a></li><li><a href=#evaluation>Evaluation</a><ul><li><a href=#multi-threaded-benefit>Multi-threaded Benefit</a></li><li><a href=#jit-optimization-benefit>JIT Optimization Benefit</a></li></ul></li><li><a href=#wrapping-up>Wrapping up</a></li></ul></nav></div></aside><main class="col-12 col-md-9 col-xl-8 ps-md-5 pe-md-4" role=main><a class=td-rss-button title=RSS href=https://fireducks-dev.github.io/posts/index.xml target=_blank rel=noopener><i class="fa-solid fa-rss" aria-hidden=true></i></a><div class=td-content><h1>Exploring performance benefits of FireDucks over cuDF</h1><div class="td-byline mb-4">By <b>Sourav Saha</b> |
<time datetime=2024-12-18 class=text-muted>Wednesday, December 18, 2024</time></div><header class=article-meta></header><p><a href=https://www.anaconda.com/resources/whitepapers/state-of-data-science-2020>Research</a> says that Data
scientists spend about 45% of their time on data preparation tasks, including loading (19%) and
cleaning (26%) the data. <a href=https://pandas.pydata.org/>Pandas</a> is one of the most popular python
libraries for tabular data processing because of its diverse utilities and large community support.
However, due to its performance issue with the large-scale data processing, there is a strong need
for high-performance data frame libraries for the community. Although there are many alternatives
available at this moment, due to compatibility issues with pandas some of those either compel
a user to learn completely new APIs (incurring migration cost) or to switch to a more
efficient computational systems, like GPU etc. (incurring hardware cost).</p><p>In this article we will discuss two high-performance pandas alternatives that can help a pandas programmer
to smoothly migrate an existing application while offering promising speed. They are:</p><ul><li><a href=https://docs.rapids.ai/api/cudf/stable>cuDF</a>: GPU accelerated DataFrame library with highly compatible pandas APIs</li><li><a href=https://fireducks-dev.github.io/>FireDucks</a>: A compiler accelerated DataFrame library with highly compatible pandas APIs for speedup even on CPU only systems</li></ul><h2 id=fireducks-vs-cudf>FireDucks vs. cuDF</h2><p>Both FireDucks and cuDF offer the following:</p><ul><li>ensure zero code changes with promising speedup</li><li>highly-compatible pandas APIs for a seamless integration with an existing pandas application</li><li>import-hook feature for a seamless integration with third party library using pandas</li><li>parallel implementation of the kernel algorithms (like join, groupby etc.) to leverage all the available cores</li></ul><p>However, the key differences are:</p><ul><li>FireDucks can speedup an existing pandas application even on CPU only systems, whereas
one needs to prepare a GPU environment before trying cuDF.</li><li>FireDucks supports a lazy execution model aiming for JIT query optimization, whereas
cuDF supports only an eager execution model (similar to pandas). Therefore, if the program
is not written carefully with the right data-flow, cuDF might suffer performance issue while
FireDucks can outperform cuDF even on CPU only systems due to its efficient query optimization.</li></ul><h2 id=evaluation>Evaluation</h2><h3 id=multi-threaded-benefit>Multi-threaded Benefit</h3><p>Here is an <a href=https://developer.nvidia.com/blog/rapids-cudf-accelerates-pandas-nearly-150x-with-zero-code-changes>article</a>
explaining the key features of cuDF along with its performance. We have used the notebook provided in that article
to evaluate <code>pandas</code>, <code>fireducks.pandas</code>, and <code>cudf.pandas</code> respectively.</p><ul><li><a href=https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/pandas_nyc_demo.ipynb>test drive for native pandas</a></li><li><a href=https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/fireducks_pandas_nyc_demo.ipynb>test drive for fireducks.pandas</a></li><li><a href=https://github.com/fireducks-dev/fireducks/blob/main/notebooks/nyc_demo/cudf_pandas_nyc_demo.ipynb>test drive for cudf.pandas</a></li></ul><p>Here are some details related to the evaluation environment:</p><ul><li>CPU model: Intel(R) Xeon(R) Gold 6126 CPU @ 2.60GHz</li><li>CPU cores: 48</li><li>Main memory: 256gb</li><li>GPU model: NVIDIA Tesla V100</li></ul><p>It can be noted that, by simply enabling the extension <code>%load_ext fireducks.pandas</code>
or <code>%load_ext cudf.pandas</code>, one can successfully speedup the operations in an
existing pandas notebook using FireDucks or cuDF. For this experiment, we have
disabled FireDucks lazy-execution mode as follows for a fair comparison among these 3 libraries:</p><pre tabindex=0><code>from fireducks.core import get_fireducks_options
get_fireducks_options().set_benchmark_mode(True)
</code></pre><p>The table below summarizes the query wise execution time for these libraries:</p><table><thead><tr><th style=text-align:left></th><th style=text-align:right>pandas (sec)</th><th style=text-align:right>FireDucks (sec)</th><th style=text-align:right>cuDF (sec)</th><th style=text-align:left>speedup_from_FireDucks_over_pandas</th><th style=text-align:left>speedup_from_cuDF_over_pandas</th></tr></thead><tbody><tr><td style=text-align:left>data_loading</td><td style=text-align:right>1.85</td><td style=text-align:right>0.53</td><td style=text-align:right>0.42</td><td style=text-align:left>3.49x</td><td style=text-align:left>4.4x</td></tr><tr><td style=text-align:left>query_1</td><td style=text-align:right>2.4</td><td style=text-align:right>0.08</td><td style=text-align:right>0.35</td><td style=text-align:left>30.0x</td><td style=text-align:left>6.86x</td></tr><tr><td style=text-align:left>query_2</td><td style=text-align:right>0.75</td><td style=text-align:right>0.03</td><td style=text-align:right>0.01</td><td style=text-align:left>25.0x</td><td style=text-align:left>75.0x</td></tr><tr><td style=text-align:left>query_3</td><td style=text-align:right>6.38</td><td style=text-align:right>0.15</td><td style=text-align:right>0.08</td><td style=text-align:left>42.53x</td><td style=text-align:left>79.75x</td></tr></tbody></table><p>Due to difference in the underlined hardware, cuDF operations (that worked on GPU) definitely performed much better
when compared to pandas, but the performance gain from FireDucks over pandas even on CPU is quite promising.
In fact, the <strong>overall speedup is ~13x (11.37s -> 0.87s) when using cuDF,
whereas it is ~14x (11.37s -> 0.79s) when using FireDucks</strong> for the same pandas program.</p><h3 id=jit-optimization-benefit>JIT Optimization Benefit</h3><p>The above case shows how efficiently FireDucks can leverage the available cpu cores to speedup an existing pandas program.</p><p>Let&rsquo;s now understand how FireDucks JIT query optimization can make it even better!!</p><p>We have used a <a href="https://www.tpc.org/TPC_Documents_Current_Versions/pdf/TPC-H_v3.0.1.pdf#page=33">sample query</a>
from the <a href=https://www.tpc.org/tpch/>TPC-H benchmark</a> that deals with a couple of tables of different dimensions
for a scale-factor 10.</p><p>üëâ <strong>Purpose: To retrieve the 10 unshipped orders with the highest value.</strong></p><p>Here is the pandas implementation for this query:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>(
</span></span><span style=display:flex><span>    pd<span style=color:#f92672>.</span>read_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;customer.parquet&#34;</span>))
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>merge(pd<span style=color:#f92672>.</span>read_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;orders.parquet&#34;</span>)), 
</span></span><span style=display:flex><span>             left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;c_custkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_custkey&#34;</span>)
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>merge(pd<span style=color:#f92672>.</span>read_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;lineitem.parquet&#34;</span>)), 
</span></span><span style=display:flex><span>             left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_orderkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l_orderkey&#34;</span>)
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>pipe(<span style=color:#66d9ef>lambda</span> df: df[df[<span style=color:#e6db74>&#34;c_mktsegment&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;BUILDING&#34;</span>])
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>pipe(<span style=color:#66d9ef>lambda</span> df: df[df[<span style=color:#e6db74>&#34;o_orderdate&#34;</span>] <span style=color:#f92672>&lt;</span> datetime(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)])
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>pipe(<span style=color:#66d9ef>lambda</span> df: df[df[<span style=color:#e6db74>&#34;l_shipdate&#34;</span>] <span style=color:#f92672>&gt;</span> datetime(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)])
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>assign(revenue<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> df: df[<span style=color:#e6db74>&#34;l_extendedprice&#34;</span>] <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> df[<span style=color:#e6db74>&#34;l_discount&#34;</span>]))
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>groupby([<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>], as_index<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>agg({<span style=color:#e6db74>&#34;revenue&#34;</span>: <span style=color:#e6db74>&#34;sum&#34;</span>})[[<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>]]
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>sort_values([<span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>], ascending<span style=color:#f92672>=</span>[<span style=color:#66d9ef>False</span>, <span style=color:#66d9ef>True</span>])
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>reset_index(drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)            
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>      <span style=color:#f92672>.</span>to_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;q3_result.parquet&#34;</span>))      
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>This time we have used the default lazy-execution mode in FireDucks to demonstrate its true strength.
The execution time of this query for each DataFrame library is as follows:</p><ul><li>native pandas: 215.47 sec</li><li>fireducks.pandas: 1.69 sec</li><li>cudf.pandas: 26.79 sec</li></ul><p>üöÄüöÄ <strong>FireDucks outperformed pandas upto 127x (215.47s -> 1.69s) and cuDF upto 15x (26.79s -> 1.69s) for the avove query.</strong></p><p>ü§î You might be wondering how a CPU-based implementation in FireDucks can be
faster than a GPU-based implementation in cuDF!!</p><p>This speedup from FireDucks is due to the efficient query planning and optimization that
is performed by the internal JIT compiler. Instead of executing the input query as it is,
it attempts to optimize the same by reducing the scope of the input data for the time
consuming join, groupby etc. operations majorly using the following steps:</p><ul><li>loading only required columns from the input parquet files to reduce the data horizontally</li><li>performing early filtration to reduce the data vertically</li></ul><p>üìì In case of FireDucks lazy-execution mode, when a method like <code>to_parquet</code>, <code>plot</code>, <code>print</code>
etc. are called, it enables the compiler to start optimizing the accumulated data flow. Once
the optimization phase is completed, it is executed by a multi-threaded CPU kernel backed by
arrow memory helping you to experience superfast data processing, along with remarkable
reduction in the computational memory.</p><p>The optimized implementation for the same query could be as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>req_customer_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;c_custkey&#34;</span>, <span style=color:#e6db74>&#34;c_mktsegment&#34;</span>] <span style=color:#75715e># selecting (2/8) columns</span>
</span></span><span style=display:flex><span>req_lineitem_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;l_shipdate&#34;</span>, <span style=color:#e6db74>&#34;l_extendedprice&#34;</span>, <span style=color:#e6db74>&#34;l_discount&#34;</span>] <span style=color:#75715e># selecting (4/16) columns</span>
</span></span><span style=display:flex><span>req_orders_cols <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#34;o_custkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>] <span style=color:#75715e># selecting (4/9) columns</span>
</span></span><span style=display:flex><span>customer <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;customer.parquet&#34;</span>), columns <span style=color:#f92672>=</span> req_customer_cols)
</span></span><span style=display:flex><span>lineitem <span style=color:#f92672>=</span>  pd<span style=color:#f92672>.</span>read_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;lineitem.parquet&#34;</span>), columns <span style=color:#f92672>=</span> req_lineitem_cols)
</span></span><span style=display:flex><span>orders <span style=color:#f92672>=</span>  pd<span style=color:#f92672>.</span>read_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;orders.parquet&#34;</span>), columns <span style=color:#f92672>=</span> req_orders_cols)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span><span style=color:#75715e># advanced-filter: to reduce scope of ‚Äúcustomer‚Äù table to be processed</span>
</span></span><span style=display:flex><span>f_cust <span style=color:#f92672>=</span> customer[customer[<span style=color:#e6db74>&#34;c_mktsegment&#34;</span>] <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;BUILDING&#34;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># advanced-filter: to reduce scope of ‚Äúorders‚Äù table to be processed</span>
</span></span><span style=display:flex><span>f_ord <span style=color:#f92672>=</span> orders[orders[<span style=color:#e6db74>&#34;o_orderdate&#34;</span>] <span style=color:#f92672>&lt;</span> datetime(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># advanced-filter: to reduce scope of ‚Äúlineitem‚Äù table to be processed</span>
</span></span><span style=display:flex><span>f_litem <span style=color:#f92672>=</span> lineitem[lineitem[<span style=color:#e6db74>&#34;l_shipdate&#34;</span>] <span style=color:#f92672>&gt;</span> datetime(<span style=color:#ae81ff>1995</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>15</span>)]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>(
</span></span><span style=display:flex><span>    f_cust<span style=color:#f92672>.</span>merge(f_ord, left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;c_custkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_custkey&#34;</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>merge(f_litem, left_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;o_orderkey&#34;</span>, right_on<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;l_orderkey&#34;</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>assign(revenue<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> df: df[<span style=color:#e6db74>&#34;l_extendedprice&#34;</span>] <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> df[<span style=color:#e6db74>&#34;l_discount&#34;</span>]))
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>groupby([<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>], as_index<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>agg({<span style=color:#e6db74>&#34;revenue&#34;</span>: <span style=color:#e6db74>&#34;sum&#34;</span>})[[<span style=color:#e6db74>&#34;l_orderkey&#34;</span>, <span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>, <span style=color:#e6db74>&#34;o_shippriority&#34;</span>]]
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>sort_values([<span style=color:#e6db74>&#34;revenue&#34;</span>, <span style=color:#e6db74>&#34;o_orderdate&#34;</span>], ascending<span style=color:#f92672>=</span>[<span style=color:#66d9ef>False</span>, <span style=color:#66d9ef>True</span>])
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>reset_index(drop<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>head(<span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>          <span style=color:#f92672>.</span>to_parquet(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(datapath, <span style=color:#e6db74>&#34;opt_q3_result.parquet&#34;</span>))
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>The execution time of this optimized implementation for each DataFrame library is as follows:</p><ul><li>native pandas: 11.13 sec</li><li>fireducks.pandas: 1.72 sec</li><li>cudf.pandas: 0.76 sec</li></ul><p>It can be noted that:</p><ul><li>the native pandas could itself be optimized upto <strong>~19x (215.47 sec -> 11.13 sec)</strong></li><li>there is no visible change in the execution time of FireDucks (<strong>since the compiler does the same optimization automatically in the earlier case</strong>)</li><li>the cudf.pandas could be optimized upto <strong>~35x (26.79 sec -> 0.76 sec)</strong></li></ul><p>Most importantly there is no impact in the final result due to the optimization performed.
You can reproduce the same using this <a href=https://github.com/fireducks-dev/fireducks/blob/main/notebooks/tpch-query3-pandas-fireducks-cudf.ipynb>notebook</a> at your end.</p><h2 id=wrapping-up>Wrapping up</h2><p>Thank you for your time in reading this article. We have discussed performance benefit of FireDucks
over cuDF. While cuDF shows significant speedup without modifying an existing pandas program,
its performance relies on the underlined GPU specification and how well the program is written, whereas
FireDucks can optimize an existing pandas program efficiently like an expert programmer and
execute the same without any extra overhead, that too on CPU only systems.</p><p>Being said that, <strong>a GPU version of FireDucks is under dvelopment</strong>. It internally uses <code>cuDF.pandas</code>
for the kernel operations (like groupby, join etc.), while adding the JIT optimization for further
acceleration as explained in this article. For example, even when you write the query as in the
first implementation, it would be auto-optimized by the FireDucks compiler similar to the
optimized implementation and then it will be passed to the cuDF kernel for the execution
at the GPU side (helping you to experience the query to be finished in ~0.76 sec).
We will be talking about the GPU version of FireDucks in details in some other article.</p><p>We look forward your constant feedback to make FireDucks even better.
Please feel free to get in touch with us in any of your prefered channel mentioned below:</p><ul><li>ü¶Ügithub : <a href=https://github.com/fireducks-dev/fireducks/issues/new>https://github.com/fireducks-dev/fireducks/issues/new</a></li><li>üìßmail : <a href=mailto:contact@fireducks.jp.nec.com>contact@fireducks.jp.nec.com</a></li><li>ü§ùslack : <a href=https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w>https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w</a></li></ul><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/posts/20241217_liveness_analysis/ aria-label="Previous - Cache or Eliminate? How FireDucks increase opportunity of optimization" class="btn btn-primary"><span class=me-1>‚Üê</span>Previous</a></li><li><a href=/posts/2024-12-19-araki-en/ aria-label="Next - Ensuring compatibility with pandas in the GPU version of FireDucks" class="btn btn-primary">Next<span class=ms-1>‚Üí</span></a></li></ul></div></main></div></div><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class=td-footer__links-list><li class=td-footer__links-item data-bs-toggle=tooltip title="Post issues on GitHub issues" aria-label="Post issues on GitHub issues"><a target=_blank rel=noopener href=https://github.com/fireducks-dev/fireducks aria-label="Post issues on GitHub issues"><i class="fa-brands fa-github"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Send an e-mail to us" aria-label="Send an e-mail to us"><a target=_blank rel=noopener href=mailto:contact@fireducks.jp.nec.com aria-label="Send an e-mail to us"><i class="fa-solid fa-envelope"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Follow us in X" aria-label="Follow us in X"><a target=_blank rel=noopener href=https://x.com/fireducksdev aria-label="Follow us in X"><i class="fa-brands fa-x-twitter"></i></a></li><li class=td-footer__links-item data-bs-toggle=tooltip title="Join us on Slack" aria-label="Join us on Slack"><a target=_blank rel=noopener href=https://join.slack.com/t/fireducks/shared_invite/zt-2j4lucmtj-IGR7AWlXO62Lu605pnBJ2w aria-label="Join us on Slack"><i class="fa-brands fa-slack"></i></a></li></ul></div><div class="col-6 col-sm-4 text-end text-xs-center order-sm-3"></div><div class="td-footer__copyright-etc col-12 col-sm-4 text-center py-2 order-sm-2"><span>&copy; 2025 FireDucks Dev Team All Rights Reserved</span></div></div></div></footer></div><script src=/js/main.min.350b703200e2632331b6ab5a6c71195d176b52e89c9b70db7c43764d40b28d92.js integrity="sha256-NQtwMgDiYyMxtqtabHEZXRdrUuicm3DbfEN2TUCyjZI=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.f724d3de49218995223b7316aa2e53e2b34bf42026bf399ebb21bb02212402d1.js integrity="sha256-9yTT3kkhiZUiO3MWqi5T4rNL9CAmvzmeuyG7AiEkAtE=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>